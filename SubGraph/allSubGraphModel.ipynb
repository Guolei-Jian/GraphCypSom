{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [09:06:50] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "[09:06:50] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data\n",
    "import numpy as np\n",
    "import os\n",
    "from rdkit import Chem\n",
    "import pickle\n",
    "from rdkit.Chem.rdchem import HybridizationType, ChiralType\n",
    "from torch_geometric.utils import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../Dataset/merged.sdf'\n",
    "mols = Chem.SDMolSupplier(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol2y(mol):\n",
    "    _y = []\n",
    "    som = ['PRIMARY_SOM_1A2', 'PRIMARY_SOM_2A6','PRIMARY_SOM_2B6','PRIMARY_SOM_2C8','PRIMARY_SOM_2C9','PRIMARY_SOM_2C19','PRIMARY_SOM_2D6','PRIMARY_SOM_2E1','PRIMARY_SOM_3A4',\n",
    "           'SECONDARY_SOM_1A2', 'SECONDARY_SOM_2A6','SECONDARY_SOM_2B6','SECONDARY_SOM_2C8','SECONDARY_SOM_2C9','SECONDARY_SOM_2C19','SECONDARY_SOM_2D6','SECONDARY_SOM_2E1','SECONDARY_SOM_3A4',\n",
    "           'TERTIARY_SOM_1A2', 'TERTIARY_SOM_2A6','TERTIARY_SOM_2B6','TERTIARY_SOM_2C8','TERTIARY_SOM_2C9','TERTIARY_SOM_2C19','TERTIARY_SOM_2D6','TERTIARY_SOM_2E1','TERTIARY_SOM_3A4'\n",
    "          ]\n",
    "    result = []\n",
    "    for k in som:\n",
    "        try:\n",
    "            _res = mol.GetProp(k)\n",
    "            if ' ' in _res:\n",
    "                res = _res.split(' ')\n",
    "                for s in res:\n",
    "                    result.append(int(s))\n",
    "                # res = [int(temp) for temp in res]\n",
    "            else:\n",
    "                # res = [int(_res)]\n",
    "                result.append(int(_res))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for data in result:\n",
    "        _y.append(data)\n",
    "    _y = list(set(_y))\n",
    "\n",
    "    y = np.zeros(len(mol.GetAtoms()))\n",
    "    for i in _y:\n",
    "        y[i-1] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mol2graph(mol):\n",
    "    target = mol2y(mol)\n",
    "    g = nx.Graph()\n",
    "    identity = {\n",
    "        'C':[1,0,0,0,0,0,0,0,0,0],\n",
    "        'N':[0,1,0,0,0,0,0,0,0,0],\n",
    "        'O':[0,0,1,0,0,0,0,0,0,0],\n",
    "        'F':[0,0,0,1,0,0,0,0,0,0],\n",
    "        'P':[0,0,0,0,1,0,0,0,0,0],\n",
    "        'S':[0,0,0,0,0,1,0,0,0,0],\n",
    "        'Cl':[0,0,0,0,0,0,1,0,0,0],\n",
    "        'Br':[0,0,0,0,0,0,0,1,0,0],\n",
    "        'I':[0,0,0,0,0,0,0,0,1,0],\n",
    "        'other':[0,0,0,0,0,0,0,0,0,1],\n",
    "    }\n",
    "    for atom in mol.GetAtoms():\n",
    "        node_feats = []\n",
    "        # atom number\n",
    "        idx = atom.GetIdx()\n",
    "        # atom type one-hot 10\n",
    "        node_feats.extend(identity.get(atom.GetSymbol(),[0,0,0,0,0,0,0,0,0,1]))\n",
    "        # implicit valence\n",
    "        node_feats.append(atom.GetImplicitValence())\n",
    "        # formal charge\n",
    "        node_feats.append(atom.GetFormalCharge())\n",
    "        # radical electrons\n",
    "        node_feats.append(atom.GetNumRadicalElectrons())\n",
    "            \n",
    "        # aromatic 0 or 1\n",
    "        if atom.GetIsAromatic():\n",
    "            node_feats.append(1)\n",
    "        else:\n",
    "            node_feats.append(0)\n",
    "\n",
    "        # chirality\n",
    "        chirality = atom.GetChiralTag()\n",
    "        if chirality == ChiralType.CHI_TETRAHEDRAL_CCW: temp = [1, 0, 0, 0]\n",
    "        if chirality == ChiralType.CHI_TETRAHEDRAL_CW: temp = [0, 1, 0, 0]\n",
    "        if chirality == ChiralType.CHI_OTHER: temp = [0, 0, 1, 0]\n",
    "        if chirality == ChiralType.CHI_UNSPECIFIED: temp = [0, 0, 0, 1]\n",
    "        node_feats.extend(temp)\n",
    "        # hybridization\n",
    "        hybridization = atom.GetHybridization()\n",
    "        if hybridization == HybridizationType.S: tmp = [1, 0, 0, 0, 0, 0, 0, 0]\n",
    "        if hybridization == HybridizationType.SP: tmp = [0, 1, 0, 0, 0, 0, 0, 0]\n",
    "        if hybridization == HybridizationType.SP2: tmp = [0, 0, 1, 0, 0, 0, 0, 0]\n",
    "        if hybridization == HybridizationType.SP3: tmp = [0, 0, 0, 1, 0, 0, 0, 0]\n",
    "        if hybridization == HybridizationType.SP3D: tmp = [0, 0, 0, 0, 1, 0, 0, 0]\n",
    "        if hybridization == HybridizationType.SP3D2: tmp = [0, 0, 0, 0, 0, 1, 0, 0]\n",
    "        if hybridization == HybridizationType.OTHER: tmp = [0, 0, 0, 0, 0, 0, 1, 0]\n",
    "        if hybridization == HybridizationType.UNSPECIFIED: tmp = [0, 0, 0, 0, 0, 0, 0, 1]\n",
    "        node_feats.extend(tmp)\n",
    "        node_feats = np.asarray(node_feats)\n",
    "        g.add_node(idx, x=node_feats, y=int(target[idx]))\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            edge_feats = []\n",
    "            # Feature 1: Bond type (as double)\n",
    "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "            # Feature 2: Rings\n",
    "            edge_feats.append(bond.IsInRing())\n",
    "            edge_feats = np.asarray(edge_feats)\n",
    "            g.add_edge(bond.GetBeginAtomIdx(), bond.GetEndAtomIdx(), edge_attr = edge_feats)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors_aslist(g, node, depth=1):\n",
    "    output = {}\n",
    "    output[0] = [node]\n",
    "    layers = dict(nx.bfs_successors(g, source=node, depth_limit=depth))\n",
    "    nodes = [node]\n",
    "    for i in range(1, depth+1):\n",
    "        output[i] = []\n",
    "        for x in nodes:\n",
    "            output[i].extend(layers.get(x, []))\n",
    "        nodes = output[i]\n",
    "    res = []\n",
    "    for _, v in output.items():\n",
    "        res.extend(v)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for mol in mols:\n",
    "    g = mol2graph(mol)\n",
    "    dataset.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training set， test set， validation set\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset[:int(len(dataset) * 0.8)]\n",
    "test_set = dataset[int(len(dataset) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_set = training_set[:int(len(training_set) * 0.8)]\n",
    "val_set = training_set[int(len(training_set) * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 109, 136)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tr_set = []\n",
    "for g in tr_set:\n",
    "    tmp = []\n",
    "    for node in g.nodes(data=True):\n",
    "        out = get_neighbors_aslist(g, node[0], depth=2)\n",
    "        # subgraph\n",
    "        subgraph = g.subgraph(out)\n",
    "        # generate new y\n",
    "        y = []\n",
    "        for n in subgraph.nodes(data=True):\n",
    "            y.append(n[-1]['y'])\n",
    "        tmp.append((subgraph, np.array(y)))\n",
    "    _tr_set.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_val_set = []\n",
    "for g in val_set:\n",
    "    tmp = []\n",
    "    for node in g.nodes(data=True):\n",
    "        out = get_neighbors_aslist(g, node[0], depth=2)\n",
    "        # subgraph\n",
    "        subgraph = g.subgraph(out)\n",
    "        # generate new y\n",
    "        y = []\n",
    "        for n in subgraph.nodes(data=True):\n",
    "            y.append(n[-1]['y'])\n",
    "        tmp.append((subgraph, np.array(y)))\n",
    "    _val_set.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_set = []\n",
    "for g in test_set:\n",
    "    tmp = []\n",
    "    for node in g.nodes(data=True):\n",
    "        out = get_neighbors_aslist(g, node[0], depth=2)\n",
    "        # subgraph\n",
    "        subgraph = g.subgraph(out)\n",
    "        # generate new y\n",
    "        y = []\n",
    "        for n in subgraph.nodes(data=True):\n",
    "            y.append(n[-1]['y'])\n",
    "        tmp.append((subgraph, np.array(y)))\n",
    "    _test_set.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 109, 136)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(_tr_set), len(_val_set), len(_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.utils import from_networkx\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, f1_score, recall_score, jaccard_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tr_writer = SummaryWriter(\"./tensorboard/subgraph2/train\")\n",
    "val_writer = SummaryWriter(\"./tensorboard/subgraph2/val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Model, self).__init__()\n",
    "        num_classses = 2\n",
    "\n",
    "        conv_hidden = args['conv_hidden']\n",
    "        cls_hidden = args['cls_hidden']\n",
    "        self.n_layers = args['n_layers']\n",
    "        # cls_drop = ['cls_drop']\n",
    "\n",
    "        self.conv_layers = nn.ModuleList([])\n",
    "\n",
    "        self.conv1 = SAGEConv(26, conv_hidden)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            self.conv_layers.append(\n",
    "                SAGEConv(conv_hidden, conv_hidden)\n",
    "            )\n",
    "\n",
    "        self.linear1 = nn.Linear(conv_hidden, cls_hidden)\n",
    "        self.linear2 = nn.Linear(cls_hidden, num_classses)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "\n",
    "    \n",
    "    def forward(self, mol):\n",
    "\n",
    "        res = self.conv1(mol.x, mol.edge_index)\n",
    "        for i in range(self.n_layers):\n",
    "            res = self.conv_layers[i](res, mol.edge_index)\n",
    "\n",
    "        res = self.linear1(res)\n",
    "        res = self.relu(res)\n",
    "        res = self.drop1(res)\n",
    "        res = self.linear2(res)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "def seed_torch(seed=42):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def top2(output, label):\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    preds = sf(output)\n",
    "    preds = preds[:, 1]\n",
    "    _, indices = torch.topk(preds, 2)\n",
    "    pos_index = []\n",
    "    for i in range(label.shape[0]):\n",
    "        if label[i] == 1:\n",
    "            pos_index.append(i)  \n",
    "    for li in pos_index:\n",
    "        if li in indices:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def MCC(output, label):\n",
    "    print(output, label)\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    return up / down\n",
    "\n",
    "def metrics(output, label):\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    mcc = up / down\n",
    "    selectivity = tn / (tn + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    g_mean = (selectivity * recall) ** 0.5\n",
    "    balancedAccuracy = (recall + selectivity) / 2\n",
    "    return mcc, selectivity, recall, g_mean, balancedAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, training_set, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    total_loss = 0\n",
    "    all_acc = []\n",
    "    all_auc = []\n",
    "    all_mcc = []\n",
    "    subgraph_num = 0\n",
    "    for mol in training_set:\n",
    "        sub_mcc = []\n",
    "        sub_auc = []\n",
    "        sub_acc = []\n",
    "        for sub_mol, target in mol:\n",
    "            subgraph_num += 1\n",
    "            sub_mol = from_networkx(sub_mol)\n",
    "            sub_mol = sub_mol.to(device)\n",
    "            sub_mol.x = sub_mol.x.to(torch.float32)\n",
    "            target = torch.tensor(target, dtype=torch.int64).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output= model(sub_mol)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            # tracking\n",
    "            sub_acc.append(accuracy_score(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "            try:\n",
    "                # 验证集会出现全是0，这样子算不了auc，所以这种情况，直接跳过\n",
    "                sub_auc.append(roc_auc_score(target.cpu().detach().numpy(), sf(output)[:, 1].cpu().detach().numpy()))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            sub_mcc.append(matthews_corrcoef(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "\n",
    "        all_acc.append(np.mean(sub_acc))\n",
    "        all_auc.append(np.mean(sub_auc))\n",
    "        all_mcc.append(np.mean(sub_mcc))\n",
    "\n",
    "    tr_writer.add_scalar('Ave Loss', total_loss / subgraph_num, epoch)\n",
    "    tr_writer.add_scalar('ACC', np.mean(all_acc), epoch)\n",
    "    tr_writer.add_scalar('AUC', np.mean(all_auc), epoch)\n",
    "    tr_writer.add_scalar('MCC', np.mean(all_mcc), epoch)\n",
    "    print(f'Train Epoch: {epoch}, Ave Loss: {total_loss / subgraph_num} ACC: {np.mean(all_acc)}  AUC: {np.mean(all_auc)} MCC: {np.mean(all_mcc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(args, model, device, val_set, optimizer, criterion, epoch):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    total_loss = 0\n",
    "    all_acc = []\n",
    "    all_auc = []\n",
    "    all_mcc = []\n",
    "    subgraph_num = 0\n",
    "    for mol in val_set:\n",
    "        sub_mcc = []\n",
    "        sub_auc = []\n",
    "        sub_acc = []\n",
    "        for sub_mol, target in mol:\n",
    "            subgraph_num += 1\n",
    "            sub_mol = from_networkx(sub_mol)\n",
    "            sub_mol = sub_mol.to(device)\n",
    "            sub_mol.x = sub_mol.x.to(torch.float32)\n",
    "            target = torch.tensor(target, dtype=torch.int64).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output= model(sub_mol)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # tracking\n",
    "            sub_acc.append(accuracy_score(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "            try:\n",
    "                # 验证集会出现全是0，这样子算不了auc，所以这种情况，直接跳过\n",
    "                sub_auc.append(roc_auc_score(target.cpu().detach().numpy(), sf(output)[:, 1].cpu().detach().numpy()))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            sub_mcc.append(matthews_corrcoef(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "            \n",
    "        all_acc.append(np.mean(sub_acc))\n",
    "        all_auc.append(np.mean(sub_auc))\n",
    "        all_mcc.append(np.mean(sub_mcc))\n",
    "\n",
    "    val_writer.add_scalar('Ave Loss', total_loss / subgraph_num, epoch)\n",
    "    val_writer.add_scalar('ACC', np.mean(all_acc), epoch)\n",
    "    val_writer.add_scalar('AUC', np.mean(all_auc), epoch)\n",
    "    val_writer.add_scalar('MCC', np.mean(all_mcc), epoch)\n",
    "    print(f'validation Epoch: {epoch}, Ave Loss: {total_loss / subgraph_num} ACC: {np.mean(all_acc)}  AUC: {np.mean(all_auc)} MCC: {np.mean(all_mcc)}')\n",
    "    return np.mean(all_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    seed_torch(args['seed'])\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    torch.manual_seed(args['seed'])\n",
    "\n",
    "    model = Model(args).to(device)\n",
    "    print(model)\n",
    "    weights = torch.tensor([1, args['pos_weight']], dtype=torch.float32).to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    max_acc = 0\n",
    "    for epoch in range(1, args['epoch'] + 1):\n",
    "        train(args, model, device, _tr_set, optimizer, loss_fn, epoch)\n",
    "        acc = val(args, model, device, _val_set, optimizer, loss_fn, epoch)\n",
    "        random.shuffle(_tr_set)\n",
    "        random.shuffle(_val_set)\n",
    "        scheduler.step()\n",
    "        if acc > max_acc:\n",
    "            max_acc = acc\n",
    "            print('Saving model (epoch = {:4d}, max_acc = {:.4f})'\n",
    "                .format(epoch, max_acc))\n",
    "            torch.save(model.state_dict(), args['save_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'lr': 0.02,\n",
    "    'epoch': 400,\n",
    "    'seed': 42,\n",
    "    'save_path': './model/subgraph2hop',\n",
    "    'pos_weight': 3,\n",
    "    'conv_hidden': 1024, \n",
    "    'cls_hidden': 1024,\n",
    "    'n_layers': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): SAGEConv(1024, 1024)\n",
      "    (1): SAGEConv(1024, 1024)\n",
      "    (2): SAGEConv(1024, 1024)\n",
      "  )\n",
      "  (conv1): SAGEConv(26, 1024)\n",
      "  (linear1): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (linear2): Linear(in_features=1024, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (drop1): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Train Epoch: 1, Ave Loss: 0.28298214054242976 ACC: 0.8980744626293523  AUC: nan MCC: 0.18903074702441905\n",
      "Train Epoch: 1, Ave Loss: 0.23855979564792906 ACC: 0.9148924004477842  AUC: 0.9023518390235831 MCC: 0.21411756799963338\n",
      "Saving model (epoch =    1, max_acc = 0.9149)\n",
      "Train Epoch: 2, Ave Loss: 0.2711812774227886 ACC: 0.9036124761948415  AUC: nan MCC: 0.21500841314639962\n",
      "Train Epoch: 2, Ave Loss: 0.25346555039926527 ACC: 0.9134354784391149  AUC: 0.9093653469821021 MCC: 0.20526605699971087\n",
      "Train Epoch: 3, Ave Loss: 0.27654132011152827 ACC: 0.9007571097371871  AUC: nan MCC: 0.2056977334227321\n",
      "Train Epoch: 3, Ave Loss: 0.2501215306128879 ACC: 0.9144324179422337  AUC: 0.9121915491343753 MCC: 0.21032065197558938\n",
      "Train Epoch: 4, Ave Loss: 0.27404758534441936 ACC: 0.9024495453369467  AUC: nan MCC: 0.2054306020381724\n",
      "Train Epoch: 4, Ave Loss: 0.23366178022848305 ACC: 0.9199963876155034  AUC: 0.9217250711095958 MCC: 0.2171543422837858\n",
      "Saving model (epoch =    4, max_acc = 0.9200)\n",
      "Train Epoch: 5, Ave Loss: 0.27876591527776323 ACC: 0.9041206935989822  AUC: nan MCC: 0.2095839659975503\n",
      "Train Epoch: 5, Ave Loss: 0.2327831906871325 ACC: 0.9258886431066152  AUC: 0.9149287093706479 MCC: 0.24230491376508848\n",
      "Saving model (epoch =    5, max_acc = 0.9259)\n",
      "Train Epoch: 6, Ave Loss: 0.27919444265901694 ACC: 0.9041666013438484  AUC: nan MCC: 0.20110320523673803\n",
      "Train Epoch: 6, Ave Loss: 0.23632214562589857 ACC: 0.9219218358712377  AUC: 0.9199906076202021 MCC: 0.2164525586584733\n",
      "Train Epoch: 7, Ave Loss: 0.27768686243935137 ACC: 0.9044927157681619  AUC: nan MCC: 0.20333975741294047\n",
      "Train Epoch: 7, Ave Loss: 0.23992558948095022 ACC: 0.9245245476763578  AUC: 0.9241424731820901 MCC: 0.22239073153543587\n",
      "Train Epoch: 8, Ave Loss: 0.27886657497287837 ACC: 0.9040717671342239  AUC: nan MCC: 0.20197721296098398\n",
      "Train Epoch: 8, Ave Loss: 0.23520519732727188 ACC: 0.9241173110158966  AUC: 0.9286577315484122 MCC: 0.22572642648539176\n",
      "Train Epoch: 9, Ave Loss: 0.27989596127578553 ACC: 0.899311085911807  AUC: nan MCC: 0.20257898967198112\n",
      "Train Epoch: 9, Ave Loss: 0.24182612111498342 ACC: 0.9187703723384708  AUC: 0.9275520574117928 MCC: 0.2118707136020688\n",
      "Train Epoch: 10, Ave Loss: 0.2834626970395958 ACC: 0.9042735009349643  AUC: nan MCC: 0.19624445266117807\n",
      "Train Epoch: 10, Ave Loss: 0.2461778363835393 ACC: 0.9216374529253183  AUC: 0.9270593324442923 MCC: 0.22950487755097587\n",
      "Train Epoch: 11, Ave Loss: 0.2874846493487878 ACC: 0.896875202803346  AUC: nan MCC: 0.19336538446304782\n",
      "Train Epoch: 11, Ave Loss: 0.23699259722836172 ACC: 0.9297106671906995  AUC: 0.9282735921523468 MCC: 0.22015064595522874\n",
      "Saving model (epoch =   11, max_acc = 0.9297)\n",
      "Train Epoch: 12, Ave Loss: 0.2839729904942303 ACC: 0.8998147050978356  AUC: nan MCC: 0.19484769024034093\n",
      "Train Epoch: 12, Ave Loss: 0.24310305612727018 ACC: 0.9255020546437864  AUC: 0.9285946190377978 MCC: 0.2160450454316785\n",
      "Train Epoch: 13, Ave Loss: 0.2824659987834533 ACC: 0.9037252596030024  AUC: nan MCC: 0.20362200082069665\n",
      "Train Epoch: 13, Ave Loss: 0.24118131787059496 ACC: 0.9218860026298624  AUC: 0.9276006616244439 MCC: 0.20720156212793545\n",
      "Train Epoch: 14, Ave Loss: 0.28666500376599124 ACC: 0.9030819425908847  AUC: nan MCC: 0.19481952265248578\n",
      "Train Epoch: 14, Ave Loss: 0.24124372066653507 ACC: 0.9233693453510299  AUC: 0.926339932340309 MCC: 0.2157907716515244\n",
      "Train Epoch: 15, Ave Loss: 0.29166216655679045 ACC: 0.8980214874500584  AUC: nan MCC: 0.19050116637992387\n",
      "Train Epoch: 15, Ave Loss: 0.23745212365198265 ACC: 0.9263148369459688  AUC: 0.9209699410048996 MCC: 0.21399435783756898\n",
      "Train Epoch: 16, Ave Loss: 0.2886854666669812 ACC: 0.9036676279197661  AUC: nan MCC: 0.1942308526665381\n",
      "Train Epoch: 16, Ave Loss: 0.2375590250891237 ACC: 0.9235714862121569  AUC: 0.9268670330863632 MCC: 0.21129126458861847\n",
      "Train Epoch: 17, Ave Loss: 0.2814531592758395 ACC: 0.9066555411539845  AUC: nan MCC: 0.20424840726994153\n",
      "Train Epoch: 17, Ave Loss: 0.2326225162522936 ACC: 0.9308543738974059  AUC: 0.9290839341899599 MCC: 0.2324995751576993\n",
      "Saving model (epoch =   17, max_acc = 0.9309)\n",
      "Train Epoch: 18, Ave Loss: 0.28796985864733227 ACC: 0.9014639794780868  AUC: nan MCC: 0.1972442230742917\n",
      "Train Epoch: 18, Ave Loss: 0.24044164519902775 ACC: 0.9235181025671251  AUC: 0.924533558919491 MCC: 0.20576132716691245\n",
      "Train Epoch: 19, Ave Loss: 0.28686419130197877 ACC: 0.9022144918050471  AUC: nan MCC: 0.19430041467032447\n",
      "Train Epoch: 19, Ave Loss: 0.23342892396408602 ACC: 0.9280824155123288  AUC: 0.9329890272916306 MCC: 0.2311768333199629\n",
      "Train Epoch: 20, Ave Loss: 0.2827623416517832 ACC: 0.9023938923404837  AUC: nan MCC: 0.19782610878464138\n",
      "Train Epoch: 20, Ave Loss: 0.23433404674519417 ACC: 0.9280292074920583  AUC: 0.9288501208652828 MCC: 0.2256021372199874\n",
      "Train Epoch: 21, Ave Loss: 0.2899800842989759 ACC: 0.903204378102221  AUC: nan MCC: 0.19068252895471793\n",
      "Train Epoch: 21, Ave Loss: 0.2383553130241458 ACC: 0.9297281968605653  AUC: 0.9235512631498386 MCC: 0.22721432059707652\n",
      "Train Epoch: 22, Ave Loss: 0.29247684414924247 ACC: 0.9022829445945927  AUC: nan MCC: 0.19262674875609848\n",
      "Train Epoch: 22, Ave Loss: 0.2364618311267139 ACC: 0.921850435735662  AUC: 0.9263251634566363 MCC: 0.21335879544532638\n",
      "Train Epoch: 23, Ave Loss: 0.2916945403848723 ACC: 0.9021593147376159  AUC: nan MCC: 0.18933575824238244\n",
      "Train Epoch: 23, Ave Loss: 0.22805008713179767 ACC: 0.9264914986611904  AUC: 0.937590501505049 MCC: 0.22880015011102173\n",
      "Train Epoch: 24, Ave Loss: 0.2935847898570955 ACC: 0.9019554158051971  AUC: nan MCC: 0.18976176635022482\n",
      "Train Epoch: 24, Ave Loss: 0.23225111580914184 ACC: 0.9285109016814048  AUC: 0.9262723432948576 MCC: 0.22501779955802695\n",
      "Train Epoch: 25, Ave Loss: 0.28775726459701795 ACC: 0.9040527171346785  AUC: nan MCC: 0.19971891722244892\n",
      "Train Epoch: 25, Ave Loss: 0.23704592305966476 ACC: 0.928010259606045  AUC: 0.9315775365554161 MCC: 0.22508743476808962\n",
      "Train Epoch: 26, Ave Loss: 0.28283840234197793 ACC: 0.909166088713116  AUC: nan MCC: 0.20380320298745597\n",
      "Train Epoch: 26, Ave Loss: 0.2378715331652218 ACC: 0.9250956670812168  AUC: 0.9250093442067717 MCC: 0.21008078611934275\n",
      "Train Epoch: 27, Ave Loss: 0.29187274156479637 ACC: 0.8992787898507242  AUC: nan MCC: 0.19288738838909808\n",
      "Train Epoch: 27, Ave Loss: 0.24047455323829475 ACC: 0.9238122145263346  AUC: 0.9324574569229708 MCC: 0.21111069747020017\n",
      "Train Epoch: 28, Ave Loss: 0.28903470704386575 ACC: 0.9027656225070215  AUC: nan MCC: 0.19874245908731714\n",
      "Train Epoch: 28, Ave Loss: 0.23492027548871067 ACC: 0.9294119624285662  AUC: 0.9318731314063112 MCC: 0.2191333846217701\n",
      "Train Epoch: 29, Ave Loss: 0.29276878754071445 ACC: 0.9036406904424641  AUC: nan MCC: 0.19711036603275245\n",
      "Train Epoch: 29, Ave Loss: 0.23380311476756513 ACC: 0.9295179172663725  AUC: 0.9358848675395817 MCC: 0.22566479001438347\n",
      "Train Epoch: 30, Ave Loss: 0.2905092177118905 ACC: 0.9012779116759971  AUC: nan MCC: 0.19811147116422792\n",
      "Train Epoch: 30, Ave Loss: 0.23629315583961658 ACC: 0.9283769514554453  AUC: 0.9346030789767499 MCC: 0.21837115629974901\n",
      "Train Epoch: 31, Ave Loss: 0.28941305898401554 ACC: 0.9002972474876301  AUC: nan MCC: 0.20052497167606217\n",
      "Train Epoch: 31, Ave Loss: 0.23116447295152667 ACC: 0.9284718097850329  AUC: 0.9378035119059233 MCC: 0.2286446498571193\n",
      "Train Epoch: 32, Ave Loss: 0.2913870350291947 ACC: 0.9053935057860432  AUC: nan MCC: 0.19769143456676927\n",
      "Train Epoch: 32, Ave Loss: 0.22964888664315514 ACC: 0.9316994288046861  AUC: 0.9349205135171881 MCC: 0.23535720752055153\n",
      "Saving model (epoch =   32, max_acc = 0.9317)\n",
      "Train Epoch: 33, Ave Loss: 0.29333193041386424 ACC: 0.9011324796593302  AUC: nan MCC: 0.19760649199027125\n",
      "Train Epoch: 33, Ave Loss: 0.22495659624818903 ACC: 0.9322415588305408  AUC: 0.9348721291438593 MCC: 0.24338014268162828\n",
      "Saving model (epoch =   33, max_acc = 0.9322)\n",
      "Train Epoch: 34, Ave Loss: 0.2939689099402488 ACC: 0.8988430331314875  AUC: nan MCC: 0.19827258442576948\n",
      "Train Epoch: 34, Ave Loss: 0.23266798990447438 ACC: 0.9286393750429246  AUC: 0.9327022752140324 MCC: 0.22567392403428105\n",
      "Train Epoch: 35, Ave Loss: 0.2906508932337611 ACC: 0.903825536284729  AUC: nan MCC: 0.19857732257199637\n",
      "Train Epoch: 35, Ave Loss: 0.226254972294974 ACC: 0.9293075341029776  AUC: 0.9382740309380156 MCC: 0.23247734312478488\n",
      "Train Epoch: 36, Ave Loss: 0.2878993681781466 ACC: 0.9028879332382117  AUC: nan MCC: 0.19808993140502598\n",
      "Train Epoch: 36, Ave Loss: 0.23158260441045814 ACC: 0.928310532807053  AUC: 0.9389556955319617 MCC: 0.22987029438630233\n",
      "Train Epoch: 37, Ave Loss: 0.2958407054389534 ACC: 0.9010376784706536  AUC: nan MCC: 0.20110749436961095\n",
      "Train Epoch: 37, Ave Loss: 0.221309231014508 ACC: 0.9320398548509735  AUC: 0.941082706069537 MCC: 0.23958391156353864\n",
      "Train Epoch: 38, Ave Loss: 0.28791245040416963 ACC: 0.8996877725781778  AUC: nan MCC: 0.19823651213114754\n",
      "Train Epoch: 38, Ave Loss: 0.22834899717448792 ACC: 0.9295106005660143  AUC: 0.9404184146361985 MCC: 0.2356877003212346\n",
      "Train Epoch: 39, Ave Loss: 0.29363886305452624 ACC: 0.8988781491968908  AUC: nan MCC: 0.1980164380246542\n",
      "Train Epoch: 39, Ave Loss: 0.22716678458349773 ACC: 0.9325181916686361  AUC: 0.9414789182518326 MCC: 0.2427798744046875\n",
      "Saving model (epoch =   39, max_acc = 0.9325)\n",
      "Train Epoch: 40, Ave Loss: 0.29519240468543884 ACC: 0.897894705653454  AUC: nan MCC: 0.19482150782772262\n",
      "Train Epoch: 40, Ave Loss: 0.22918841355520542 ACC: 0.9274270929019479  AUC: 0.9393718520430346 MCC: 0.22775499076924377\n",
      "Train Epoch: 41, Ave Loss: 0.2963648204110298 ACC: 0.8986963301514592  AUC: nan MCC: 0.19644315988200248\n",
      "Train Epoch: 41, Ave Loss: 0.22393349954942826 ACC: 0.9301704312158225  AUC: 0.9369380176938424 MCC: 0.23271667750295694\n",
      "Train Epoch: 42, Ave Loss: 0.2930243383382672 ACC: 0.8994807337080744  AUC: nan MCC: 0.20138603240603664\n",
      "Train Epoch: 42, Ave Loss: 0.22834621716132117 ACC: 0.9244765930587601  AUC: 0.9388140581811979 MCC: 0.22339764784989494\n",
      "Train Epoch: 43, Ave Loss: 0.29675586878992827 ACC: 0.8982334187357518  AUC: nan MCC: 0.1957949992611669\n",
      "Train Epoch: 43, Ave Loss: 0.22905897602394332 ACC: 0.9303255564671565  AUC: 0.9356925924412717 MCC: 0.2374301654577436\n",
      "Train Epoch: 44, Ave Loss: 0.29107011472951255 ACC: 0.9001492872368609  AUC: nan MCC: 0.1958453379390015\n",
      "Train Epoch: 44, Ave Loss: 0.22527796487630186 ACC: 0.9306008948833583  AUC: 0.9419413806267791 MCC: 0.2335889189495113\n",
      "Train Epoch: 45, Ave Loss: 0.2927718103215116 ACC: 0.9019920834975678  AUC: nan MCC: 0.20219510584105094\n",
      "Train Epoch: 45, Ave Loss: 0.22773848418041037 ACC: 0.9288974644239094  AUC: 0.9422821535634677 MCC: 0.23857386328733515\n",
      "Train Epoch: 46, Ave Loss: 0.29429059960851367 ACC: 0.9003643515980329  AUC: nan MCC: 0.2024487313586714\n",
      "Train Epoch: 46, Ave Loss: 0.2309826574600163 ACC: 0.9254584654763399  AUC: 0.9393155265511148 MCC: 0.2247382498081964\n",
      "Train Epoch: 47, Ave Loss: 0.29679821142924684 ACC: 0.9003584178239459  AUC: nan MCC: 0.19712874821036094\n",
      "Train Epoch: 47, Ave Loss: 0.22457090765590063 ACC: 0.9299498390153402  AUC: 0.9394821293802321 MCC: 0.23757499876021215\n",
      "Train Epoch: 48, Ave Loss: 0.28928891885713504 ACC: 0.9037722890834256  AUC: nan MCC: 0.2085702719104527\n",
      "Train Epoch: 48, Ave Loss: 0.22507177219663263 ACC: 0.9296975183979845  AUC: 0.9385381278716101 MCC: 0.23977690543673907\n",
      "Train Epoch: 49, Ave Loss: 0.293741846681309 ACC: 0.8978671373829613  AUC: nan MCC: 0.20099430209856337\n",
      "Train Epoch: 49, Ave Loss: 0.22112018446193785 ACC: 0.9305804241127241  AUC: 0.943546056208378 MCC: 0.234869934540115\n",
      "Train Epoch: 50, Ave Loss: 0.2911723191215135 ACC: 0.8985449883975076  AUC: nan MCC: 0.19949341571583143\n",
      "Train Epoch: 50, Ave Loss: 0.22585073523091845 ACC: 0.9270234416477666  AUC: 0.9409880355379152 MCC: 0.23834208874781843\n",
      "Train Epoch: 51, Ave Loss: 0.29065317951712855 ACC: 0.9017344099394917  AUC: nan MCC: 0.20287658342793458\n",
      "Train Epoch: 51, Ave Loss: 0.22443471891599578 ACC: 0.9284576184305335  AUC: 0.937542948021567 MCC: 0.2350070135357819\n",
      "Train Epoch: 52, Ave Loss: 0.29193463967796546 ACC: 0.9030844110771882  AUC: nan MCC: 0.20930489020614398\n",
      "Train Epoch: 52, Ave Loss: 0.22785471335617544 ACC: 0.9272288109256513  AUC: 0.9410766406110259 MCC: 0.23620602050396813\n",
      "Train Epoch: 53, Ave Loss: 0.2927379563890193 ACC: 0.8998280857322847  AUC: nan MCC: 0.20785383303946742\n",
      "Train Epoch: 53, Ave Loss: 0.2282207100271631 ACC: 0.927551821454743  AUC: 0.9396143889560923 MCC: 0.22921706650051063\n",
      "Train Epoch: 54, Ave Loss: 0.2914942489294555 ACC: 0.9033863012474798  AUC: nan MCC: 0.20549643708461493\n",
      "Train Epoch: 54, Ave Loss: 0.22419617990113416 ACC: 0.925551884328705  AUC: 0.9411351682046644 MCC: 0.23680766764050254\n",
      "Train Epoch: 55, Ave Loss: 0.2890637003949748 ACC: 0.9024555946488371  AUC: nan MCC: 0.21102547183748188\n",
      "Train Epoch: 55, Ave Loss: 0.22457223874360607 ACC: 0.9305425308937385  AUC: 0.9417950216447616 MCC: 0.237070470321927\n",
      "Train Epoch: 56, Ave Loss: 0.2886526013039497 ACC: 0.9019559181680732  AUC: nan MCC: 0.21121757524718288\n",
      "Train Epoch: 56, Ave Loss: 0.22713349480938028 ACC: 0.9267774966766303  AUC: 0.9410304821346247 MCC: 0.22877932584142674\n",
      "Train Epoch: 57, Ave Loss: 0.2923555529051541 ACC: 0.8998195861170534  AUC: nan MCC: 0.2050469444655106\n",
      "Train Epoch: 57, Ave Loss: 0.22800786104142634 ACC: 0.9263181553943257  AUC: 0.9399052315442046 MCC: 0.23163862356240733\n",
      "Train Epoch: 58, Ave Loss: 0.29254785847024967 ACC: 0.898939198487705  AUC: nan MCC: 0.20710354537124973\n",
      "Train Epoch: 58, Ave Loss: 0.22749681081078382 ACC: 0.9278039356571639  AUC: 0.9409063021513285 MCC: 0.2384032896519654\n",
      "Train Epoch: 59, Ave Loss: 0.2909267607539829 ACC: 0.901457883998493  AUC: nan MCC: 0.2076975520730853\n",
      "Train Epoch: 59, Ave Loss: 0.22484504247902862 ACC: 0.9265988298714847  AUC: 0.9420241830282831 MCC: 0.2403146243033698\n",
      "Train Epoch: 60, Ave Loss: 0.2915582302905248 ACC: 0.8995818581986802  AUC: nan MCC: 0.2084376673802434\n",
      "Train Epoch: 60, Ave Loss: 0.22311641643176366 ACC: 0.9295243310194022  AUC: 0.9414651494195119 MCC: 0.2320285237413616\n",
      "Train Epoch: 61, Ave Loss: 0.2911527949558018 ACC: 0.8987667578132027  AUC: nan MCC: 0.206634473466858\n",
      "Train Epoch: 61, Ave Loss: 0.2263655008946041 ACC: 0.9289629691901549  AUC: 0.9456494549932579 MCC: 0.23850242219220444\n",
      "Train Epoch: 62, Ave Loss: 0.2917481919907686 ACC: 0.8999046798490903  AUC: nan MCC: 0.21235820123095472\n",
      "Train Epoch: 62, Ave Loss: 0.2239697962478872 ACC: 0.9261505995708443  AUC: 0.946016355235805 MCC: 0.227997352046673\n",
      "Train Epoch: 63, Ave Loss: 0.2900716105997378 ACC: 0.8996629973140297  AUC: nan MCC: 0.20701361598587098\n",
      "Train Epoch: 63, Ave Loss: 0.22516914373900285 ACC: 0.9282686269431999  AUC: 0.9437597734150729 MCC: 0.23507135357599443\n",
      "Train Epoch: 64, Ave Loss: 0.2900082836267904 ACC: 0.9010617889052814  AUC: nan MCC: 0.20623368397459257\n",
      "Train Epoch: 64, Ave Loss: 0.22407179806449454 ACC: 0.9280017909334332  AUC: 0.9436431578074472 MCC: 0.23849438005955034\n",
      "Train Epoch: 65, Ave Loss: 0.2881682710622932 ACC: 0.8997482808937832  AUC: nan MCC: 0.2097069005485037\n",
      "Train Epoch: 65, Ave Loss: 0.22517660107362072 ACC: 0.9293413927696884  AUC: 0.9432606185053461 MCC: 0.23564097869782977\n",
      "Train Epoch: 66, Ave Loss: 0.29274748707654547 ACC: 0.8992341609098347  AUC: nan MCC: 0.20558341263638824\n",
      "Train Epoch: 66, Ave Loss: 0.22239606964520323 ACC: 0.9322380465119153  AUC: 0.9396665884072813 MCC: 0.24411964890540638\n",
      "Train Epoch: 67, Ave Loss: 0.2893056104567155 ACC: 0.899231837209227  AUC: nan MCC: 0.20832634274384176\n",
      "Train Epoch: 67, Ave Loss: 0.22287398752774726 ACC: 0.9285405544494245  AUC: 0.9424916333526161 MCC: 0.23870776871508628\n",
      "Train Epoch: 68, Ave Loss: 0.2874472872087914 ACC: 0.9022323690545493  AUC: nan MCC: 0.21405622171405295\n",
      "Train Epoch: 68, Ave Loss: 0.22514451826603218 ACC: 0.9289655314248504  AUC: 0.9449926757403226 MCC: 0.24211285693066967\n",
      "Train Epoch: 69, Ave Loss: 0.2914949959969521 ACC: 0.9001105851028083  AUC: nan MCC: 0.206226854243675\n",
      "Train Epoch: 69, Ave Loss: 0.2241556616427973 ACC: 0.9270429753328149  AUC: 0.9443091311395033 MCC: 0.23325517506462196\n",
      "Train Epoch: 70, Ave Loss: 0.2869641951750165 ACC: 0.900491470517141  AUC: nan MCC: 0.2106971837477165\n",
      "Train Epoch: 70, Ave Loss: 0.22265703765359035 ACC: 0.9295378292779779  AUC: 0.9436499680743518 MCC: 0.23920208292037504\n",
      "Train Epoch: 71, Ave Loss: 0.28974134578459687 ACC: 0.8998097349600144  AUC: nan MCC: 0.21137180935710276\n",
      "Train Epoch: 71, Ave Loss: 0.22271217675906788 ACC: 0.9267633917726892  AUC: 0.9414017174698823 MCC: 0.23155903499482847\n",
      "Train Epoch: 72, Ave Loss: 0.2913392576683197 ACC: 0.900423310603333  AUC: nan MCC: 0.20828288753189694\n",
      "Train Epoch: 72, Ave Loss: 0.22044819731172877 ACC: 0.9265609691078812  AUC: 0.9445014810323735 MCC: 0.2382421222056714\n",
      "Train Epoch: 73, Ave Loss: 0.2897779845430166 ACC: 0.9008825320933328  AUC: nan MCC: 0.20747842016063472\n",
      "Train Epoch: 73, Ave Loss: 0.22322422176124596 ACC: 0.9274017304321298  AUC: 0.9468119952613996 MCC: 0.23844854418204886\n",
      "Train Epoch: 74, Ave Loss: 0.2891349684872968 ACC: 0.9014393073714744  AUC: nan MCC: 0.20842145703994552\n",
      "Train Epoch: 74, Ave Loss: 0.22455655738124924 ACC: 0.9267164088962261  AUC: 0.944736650813387 MCC: 0.2327723210237963\n",
      "Train Epoch: 75, Ave Loss: 0.2877659112411739 ACC: 0.8997333558912787  AUC: nan MCC: 0.21437985797326536\n",
      "Train Epoch: 75, Ave Loss: 0.22527993297641627 ACC: 0.930640729531955  AUC: 0.9472268056802298 MCC: 0.23253000604574658\n",
      "Train Epoch: 76, Ave Loss: 0.2869222884666317 ACC: 0.8996383002590282  AUC: nan MCC: 0.20814178681472387\n",
      "Train Epoch: 76, Ave Loss: 0.22536123470229508 ACC: 0.9268091609423734  AUC: 0.9408220941981781 MCC: 0.2397287896485545\n",
      "Train Epoch: 77, Ave Loss: 0.2864419551172021 ACC: 0.9006664707846512  AUC: nan MCC: 0.20661649799922277\n",
      "Train Epoch: 77, Ave Loss: 0.22113395239373645 ACC: 0.9289011252865897  AUC: 0.9447811950801666 MCC: 0.23607017808726732\n",
      "Train Epoch: 78, Ave Loss: 0.2865694333854997 ACC: 0.9005043009614014  AUC: nan MCC: 0.20982820814650469\n",
      "Train Epoch: 78, Ave Loss: 0.22419892475189196 ACC: 0.9293551569769478  AUC: 0.9439984824292723 MCC: 0.23179412156428697\n",
      "Train Epoch: 79, Ave Loss: 0.2883070727032719 ACC: 0.9018024361048991  AUC: nan MCC: 0.21330898151222843\n",
      "Train Epoch: 79, Ave Loss: 0.2265007827897833 ACC: 0.9283547863377042  AUC: 0.9416827772136932 MCC: 0.23945696972640002\n",
      "Train Epoch: 80, Ave Loss: 0.2890486965692365 ACC: 0.8998632040695111  AUC: nan MCC: 0.21222620466545591\n",
      "Train Epoch: 80, Ave Loss: 0.2257409132201945 ACC: 0.928543463600337  AUC: 0.9456841316443617 MCC: 0.23074664299392447\n",
      "Train Epoch: 81, Ave Loss: 0.2864606874148192 ACC: 0.9003735360916317  AUC: nan MCC: 0.21287028940684077\n",
      "Train Epoch: 81, Ave Loss: 0.2241670723036209 ACC: 0.9286273809530392  AUC: 0.9453014484886291 MCC: 0.23178598768942849\n",
      "Train Epoch: 82, Ave Loss: 0.2864034968808469 ACC: 0.8993003060625011  AUC: nan MCC: 0.21550350524466091\n",
      "Train Epoch: 82, Ave Loss: 0.2246656274171682 ACC: 0.9288526896367049  AUC: 0.9453786612027297 MCC: 0.23441203506835123\n",
      "Train Epoch: 83, Ave Loss: 0.28724188082286767 ACC: 0.8994772100132693  AUC: nan MCC: 0.208372107995437\n",
      "Train Epoch: 83, Ave Loss: 0.22428745792429958 ACC: 0.9276319712020838  AUC: 0.9435977683475287 MCC: 0.2511963051503488\n",
      "Train Epoch: 84, Ave Loss: 0.2900753968271199 ACC: 0.9015142043956638  AUC: nan MCC: 0.21372360976132318\n",
      "Train Epoch: 84, Ave Loss: 0.22347055220498943 ACC: 0.9295852722527558  AUC: 0.945646522354832 MCC: 0.23654469901936057\n",
      "Train Epoch: 85, Ave Loss: 0.28737143390576586 ACC: 0.9025900534009376  AUC: nan MCC: 0.21687801306933266\n",
      "Train Epoch: 85, Ave Loss: 0.2256133044890029 ACC: 0.9241348102689918  AUC: 0.9465845377687899 MCC: 0.24313708145153629\n",
      "Train Epoch: 86, Ave Loss: 0.28961441645560737 ACC: 0.9003215397415232  AUC: nan MCC: 0.21255728018033118\n",
      "Train Epoch: 86, Ave Loss: 0.2231813244906859 ACC: 0.9288473345852565  AUC: 0.9460312736242578 MCC: 0.2366538700313831\n",
      "Train Epoch: 87, Ave Loss: 0.28742183260349163 ACC: 0.900172185170628  AUC: nan MCC: 0.21261823010375738\n",
      "Train Epoch: 87, Ave Loss: 0.22480289391507471 ACC: 0.9262101326388872  AUC: 0.9445878012999683 MCC: 0.2416973337788198\n",
      "Train Epoch: 88, Ave Loss: 0.2883874599425781 ACC: 0.9016448934036856  AUC: nan MCC: 0.21574276367901568\n",
      "Train Epoch: 88, Ave Loss: 0.22504717095303972 ACC: 0.9280010478640054  AUC: 0.9451209586457229 MCC: 0.23502281244134138\n",
      "Train Epoch: 89, Ave Loss: 0.28831406555843275 ACC: 0.9014881399681742  AUC: nan MCC: 0.21345916036348145\n",
      "Train Epoch: 89, Ave Loss: 0.22513242000155578 ACC: 0.9285926138369959  AUC: 0.9452096428044974 MCC: 0.23739330082214388\n",
      "Train Epoch: 90, Ave Loss: 0.2869910068795459 ACC: 0.9003232834572042  AUC: nan MCC: 0.2135398354165354\n",
      "Train Epoch: 90, Ave Loss: 0.22489072049993844 ACC: 0.926845129142917  AUC: 0.943473269582642 MCC: 0.2309514043226711\n",
      "Train Epoch: 91, Ave Loss: 0.28794484747080756 ACC: 0.9002814830055923  AUC: nan MCC: 0.20962651886748507\n",
      "Train Epoch: 91, Ave Loss: 0.2257876934647087 ACC: 0.9276571435727733  AUC: 0.9472977345664048 MCC: 0.23749529144868758\n",
      "Train Epoch: 92, Ave Loss: 0.28833898888256154 ACC: 0.9003227937054827  AUC: nan MCC: 0.21634782536000868\n",
      "Train Epoch: 92, Ave Loss: 0.22412525813047826 ACC: 0.9273772002016898  AUC: 0.9452525317009955 MCC: 0.237145031046069\n",
      "Train Epoch: 93, Ave Loss: 0.2870921819392827 ACC: 0.9003819417664278  AUC: nan MCC: 0.21242578251241537\n",
      "Train Epoch: 93, Ave Loss: 0.22463544361193385 ACC: 0.9275674540029714  AUC: 0.9484166092467073 MCC: 0.23180064841827694\n",
      "Train Epoch: 94, Ave Loss: 0.2873575774295941 ACC: 0.9004266112052334  AUC: nan MCC: 0.21267461804145452\n",
      "Train Epoch: 94, Ave Loss: 0.22602421936987482 ACC: 0.9276423835292666  AUC: 0.9455842355788538 MCC: 0.2406503698611746\n",
      "Train Epoch: 95, Ave Loss: 0.28788045788261657 ACC: 0.9001051325086943  AUC: nan MCC: 0.21026996714198204\n",
      "Train Epoch: 95, Ave Loss: 0.22499203152570724 ACC: 0.925866934695314  AUC: 0.9450849824118861 MCC: 0.23920519559873776\n",
      "Train Epoch: 96, Ave Loss: 0.2878023398547572 ACC: 0.8999452111783339  AUC: nan MCC: 0.20902151509535727\n",
      "Train Epoch: 96, Ave Loss: 0.22657993978586555 ACC: 0.9285476601370736  AUC: 0.9464198219204566 MCC: 0.23599105969471854\n",
      "Train Epoch: 97, Ave Loss: 0.28827316883568505 ACC: 0.8999668862924634  AUC: nan MCC: 0.2147526300523562\n",
      "Train Epoch: 97, Ave Loss: 0.2264098600189448 ACC: 0.9287746204322689  AUC: 0.9466508897638763 MCC: 0.23740014105547427\n",
      "Train Epoch: 98, Ave Loss: 0.2881286347807011 ACC: 0.8998341419328071  AUC: nan MCC: 0.21373894701948803\n",
      "Train Epoch: 98, Ave Loss: 0.22590278335020014 ACC: 0.9264760988746727  AUC: 0.9454346980113832 MCC: 0.23388917767729436\n",
      "Train Epoch: 99, Ave Loss: 0.28851430668602435 ACC: 0.9009338655035338  AUC: nan MCC: 0.21022393673728348\n",
      "Train Epoch: 99, Ave Loss: 0.22740602681944047 ACC: 0.9285794796133572  AUC: 0.9451767012684991 MCC: 0.23544883754338194\n",
      "Train Epoch: 100, Ave Loss: 0.28602123246984035 ACC: 0.9018405251639278  AUC: nan MCC: 0.2113280353402011\n",
      "Train Epoch: 100, Ave Loss: 0.2285148030489391 ACC: 0.9246146249635651  AUC: 0.9431025535868728 MCC: 0.2403705349561191\n",
      "Train Epoch: 101, Ave Loss: 0.2883414803462661 ACC: 0.9008917550167647  AUC: nan MCC: 0.21249539487690655\n",
      "Train Epoch: 101, Ave Loss: 0.22679613544609775 ACC: 0.9256499400430067  AUC: 0.9451211967833356 MCC: 0.2291665151038046\n",
      "Train Epoch: 102, Ave Loss: 0.28800481761854635 ACC: 0.9007198263767142  AUC: nan MCC: 0.20967938948932932\n",
      "Train Epoch: 102, Ave Loss: 0.2274564584959903 ACC: 0.9226480398849511  AUC: 0.9443951578200308 MCC: 0.23703889793985486\n",
      "Train Epoch: 103, Ave Loss: 0.2855981148274468 ACC: 0.9002235536933035  AUC: nan MCC: 0.21427032714811678\n",
      "Train Epoch: 103, Ave Loss: 0.226553992855505 ACC: 0.928750713833346  AUC: 0.9436236726738843 MCC: 0.2354185692767717\n",
      "Train Epoch: 104, Ave Loss: 0.28868027951210157 ACC: 0.9003906698586405  AUC: nan MCC: 0.21311185576205738\n",
      "Train Epoch: 104, Ave Loss: 0.2270298479495912 ACC: 0.9264443990661456  AUC: 0.9466984124893733 MCC: 0.2324316276057985\n",
      "Train Epoch: 105, Ave Loss: 0.2870327974609403 ACC: 0.899849395982219  AUC: nan MCC: 0.21388323408179638\n",
      "Train Epoch: 105, Ave Loss: 0.22660837988799626 ACC: 0.9277148310616083  AUC: 0.9466115448520275 MCC: 0.2307494660612043\n",
      "Train Epoch: 106, Ave Loss: 0.28778930345638076 ACC: 0.9012296097922131  AUC: nan MCC: 0.21421305275506866\n",
      "Train Epoch: 106, Ave Loss: 0.22752037515842663 ACC: 0.9268010088983268  AUC: 0.9455297139266906 MCC: 0.23802464793910333\n",
      "Train Epoch: 107, Ave Loss: 0.2875591257545093 ACC: 0.9014238360117567  AUC: nan MCC: 0.21561345520564382\n",
      "Train Epoch: 107, Ave Loss: 0.22583185257934144 ACC: 0.9282428462305787  AUC: 0.9450438529398284 MCC: 0.2393994106895214\n",
      "Train Epoch: 108, Ave Loss: 0.2865380573199861 ACC: 0.9008483539317773  AUC: nan MCC: 0.21169524391342914\n",
      "Train Epoch: 108, Ave Loss: 0.22770756157883168 ACC: 0.9282562045927485  AUC: 0.9458226217968381 MCC: 0.2371770315782327\n",
      "Train Epoch: 109, Ave Loss: 0.2864497991126976 ACC: 0.9014147525293551  AUC: nan MCC: 0.21169335559326366\n",
      "Train Epoch: 109, Ave Loss: 0.22785224989582806 ACC: 0.9253986399371156  AUC: 0.9453177081502553 MCC: 0.24022741936308223\n",
      "Train Epoch: 110, Ave Loss: 0.2870320810155922 ACC: 0.9007875391234934  AUC: nan MCC: 0.21255162023684643\n",
      "Train Epoch: 110, Ave Loss: 0.22873210669887092 ACC: 0.9252141218264212  AUC: 0.9440481915670493 MCC: 0.23845885694303404\n",
      "Train Epoch: 111, Ave Loss: 0.28618308988777197 ACC: 0.9010735507498208  AUC: nan MCC: 0.21541570847411265\n",
      "Train Epoch: 111, Ave Loss: 0.2268567381725733 ACC: 0.9295329252499407  AUC: 0.9441510138841064 MCC: 0.23411172656236498\n",
      "Train Epoch: 112, Ave Loss: 0.2863670877627535 ACC: 0.900184397336348  AUC: nan MCC: 0.2124603629716052\n",
      "Train Epoch: 112, Ave Loss: 0.22570084118466752 ACC: 0.9298725160305203  AUC: 0.9461014101565834 MCC: 0.2359424165818295\n",
      "Train Epoch: 113, Ave Loss: 0.286668555727857 ACC: 0.9016831769728535  AUC: nan MCC: 0.21009000805248557\n",
      "Train Epoch: 113, Ave Loss: 0.22716176179303554 ACC: 0.9260326668360516  AUC: 0.9446078636709809 MCC: 0.23396704621671602\n",
      "Train Epoch: 114, Ave Loss: 0.2871079899842507 ACC: 0.9001167383507831  AUC: nan MCC: 0.21485775180108319\n",
      "Train Epoch: 114, Ave Loss: 0.2282250522534943 ACC: 0.9277662100819741  AUC: 0.9448973668029942 MCC: 0.23279577592996747\n",
      "Train Epoch: 115, Ave Loss: 0.2863526467527275 ACC: 0.901943404524833  AUC: nan MCC: 0.2189814879679395\n",
      "Train Epoch: 115, Ave Loss: 0.22729296312497846 ACC: 0.9278124629522262  AUC: 0.9441298214063623 MCC: 0.23245843531027557\n",
      "Train Epoch: 116, Ave Loss: 0.2863395359548576 ACC: 0.8998893184890716  AUC: nan MCC: 0.21629898425494767\n",
      "Train Epoch: 116, Ave Loss: 0.22735557813235724 ACC: 0.9299190866224711  AUC: 0.9438446203838432 MCC: 0.2361018140594114\n",
      "Train Epoch: 117, Ave Loss: 0.2856883221896706 ACC: 0.9013151284644358  AUC: nan MCC: 0.20970339904728497\n",
      "Train Epoch: 117, Ave Loss: 0.22784210460111082 ACC: 0.9273906720257676  AUC: 0.9462769718624429 MCC: 0.23628034108409207\n",
      "Train Epoch: 118, Ave Loss: 0.28575309604912774 ACC: 0.9012191440142979  AUC: nan MCC: 0.2173414384776979\n",
      "Train Epoch: 118, Ave Loss: 0.22821487653270017 ACC: 0.9277568142229652  AUC: 0.9451262225821756 MCC: 0.23524553689029562\n",
      "Train Epoch: 119, Ave Loss: 0.28513703451233563 ACC: 0.9014309915831361  AUC: nan MCC: 0.21885926519277146\n",
      "Train Epoch: 119, Ave Loss: 0.22761499879088218 ACC: 0.9281776685761693  AUC: 0.9441959513680475 MCC: 0.23436505194116602\n",
      "Train Epoch: 120, Ave Loss: 0.28616024440347826 ACC: 0.9011677201709509  AUC: nan MCC: 0.20568822016497\n",
      "Train Epoch: 120, Ave Loss: 0.22889811558402776 ACC: 0.9249281503601167  AUC: 0.9465266694153577 MCC: 0.23985729176208803\n",
      "Train Epoch: 121, Ave Loss: 0.28703726787629946 ACC: 0.9007968304926439  AUC: nan MCC: 0.21645806483906715\n",
      "Train Epoch: 121, Ave Loss: 0.22749440469484045 ACC: 0.9276623352010764  AUC: 0.9442005236406966 MCC: 0.23697645761597597\n",
      "Train Epoch: 122, Ave Loss: 0.2857698917663626 ACC: 0.9006637769351886  AUC: nan MCC: 0.21415249846117562\n",
      "Train Epoch: 122, Ave Loss: 0.2283392938647328 ACC: 0.9274390092414517  AUC: 0.9439093080585856 MCC: 0.23556504723539357\n",
      "Train Epoch: 123, Ave Loss: 0.2868933051393057 ACC: 0.9000327537797637  AUC: nan MCC: 0.21549196041865984\n",
      "Train Epoch: 123, Ave Loss: 0.2278085447817531 ACC: 0.9277125753957892  AUC: 0.9448769625383167 MCC: 0.23637758450138222\n",
      "Train Epoch: 124, Ave Loss: 0.28528132436771314 ACC: 0.9006201724426216  AUC: nan MCC: 0.20999167129554824\n",
      "Train Epoch: 124, Ave Loss: 0.2287251385409167 ACC: 0.9272055004472546  AUC: 0.943754217539212 MCC: 0.23739974818107235\n",
      "Train Epoch: 125, Ave Loss: 0.28574024542643434 ACC: 0.9008704368102689  AUC: nan MCC: 0.21354117719332863\n",
      "Train Epoch: 125, Ave Loss: 0.22798425420985174 ACC: 0.9273216923593048  AUC: 0.944450922462713 MCC: 0.23736060801566247\n",
      "Train Epoch: 126, Ave Loss: 0.2868294403641289 ACC: 0.9006954665924675  AUC: nan MCC: 0.21309227367473801\n",
      "Train Epoch: 126, Ave Loss: 0.22811638620994917 ACC: 0.927734006121383  AUC: 0.9444219969455767 MCC: 0.23672245367135591\n",
      "Train Epoch: 127, Ave Loss: 0.2867404966866197 ACC: 0.9003185810445866  AUC: nan MCC: 0.2156383633403494\n",
      "Train Epoch: 127, Ave Loss: 0.22825040116924772 ACC: 0.9278400515742338  AUC: 0.945200536662094 MCC: 0.2367001043695356\n",
      "Train Epoch: 128, Ave Loss: 0.2857220346798929 ACC: 0.9001082212363978  AUC: nan MCC: 0.2132373271831776\n",
      "Train Epoch: 128, Ave Loss: 0.22829591546033498 ACC: 0.9268797742848114  AUC: 0.944478653155022 MCC: 0.23660884834457982\n",
      "Train Epoch: 129, Ave Loss: 0.2846088031411241 ACC: 0.9007794226968094  AUC: nan MCC: 0.21460177939789746\n",
      "Train Epoch: 129, Ave Loss: 0.22830160169405556 ACC: 0.928285841822431  AUC: 0.9449723181672222 MCC: 0.23626982376496525\n",
      "Train Epoch: 130, Ave Loss: 0.2857670323732478 ACC: 0.9000141070035526  AUC: nan MCC: 0.21579915781898806\n",
      "Train Epoch: 130, Ave Loss: 0.22820194899116278 ACC: 0.9272955309355981  AUC: 0.9442296140997355 MCC: 0.2329120691913334\n",
      "Train Epoch: 131, Ave Loss: 0.28622463281041366 ACC: 0.9011167433368595  AUC: nan MCC: 0.21157163273812568\n",
      "Train Epoch: 131, Ave Loss: 0.22857861948268243 ACC: 0.9267555030653349  AUC: 0.9453337386120868 MCC: 0.23411323310047386\n",
      "Train Epoch: 132, Ave Loss: 0.28474646216567473 ACC: 0.9030059109308145  AUC: nan MCC: 0.2137769018378065\n",
      "Train Epoch: 132, Ave Loss: 0.22849535730158888 ACC: 0.9273986516705348  AUC: 0.9446672208893014 MCC: 0.23624756221839655\n",
      "Train Epoch: 133, Ave Loss: 0.285568039350072 ACC: 0.9008712261082842  AUC: nan MCC: 0.21504301052565566\n",
      "Train Epoch: 133, Ave Loss: 0.22872781525248248 ACC: 0.9273299945045593  AUC: 0.9451123340211763 MCC: 0.23633930533766265\n",
      "Train Epoch: 134, Ave Loss: 0.28505161568511644 ACC: 0.9011599137807941  AUC: nan MCC: 0.21656822632810255\n",
      "Train Epoch: 134, Ave Loss: 0.22857484219639018 ACC: 0.9274159186270151  AUC: 0.9466383265934096 MCC: 0.23614817383919168\n",
      "Train Epoch: 135, Ave Loss: 0.2850410844292949 ACC: 0.9008194034902022  AUC: nan MCC: 0.2148677643325939\n",
      "Train Epoch: 135, Ave Loss: 0.22855342804194168 ACC: 0.9273255893959405  AUC: 0.9453785004188915 MCC: 0.23606224532074346\n",
      "Train Epoch: 136, Ave Loss: 0.2852496768011247 ACC: 0.9023685116621566  AUC: nan MCC: 0.2161814706136595\n",
      "Train Epoch: 136, Ave Loss: 0.2280786733515499 ACC: 0.9270711002903519  AUC: 0.945304546953567 MCC: 0.23568945824286136\n",
      "Train Epoch: 137, Ave Loss: 0.28472000790335716 ACC: 0.9007824905987335  AUC: nan MCC: 0.21354354133962064\n",
      "Train Epoch: 137, Ave Loss: 0.22785765724980525 ACC: 0.9278464990839663  AUC: 0.9458248441360603 MCC: 0.2359520636333897\n",
      "Train Epoch: 138, Ave Loss: 0.28531476575054626 ACC: 0.8994031387396471  AUC: nan MCC: 0.21270316945797166\n",
      "Train Epoch: 138, Ave Loss: 0.22817793762972258 ACC: 0.9272764328097421  AUC: 0.9441309699404196 MCC: 0.2359469655202949\n",
      "Train Epoch: 139, Ave Loss: 0.28616716636267253 ACC: 0.8998052114295608  AUC: nan MCC: 0.21164703769994542\n",
      "Train Epoch: 139, Ave Loss: 0.22810445493728984 ACC: 0.92751753411752  AUC: 0.9449280994000931 MCC: 0.23645783044593016\n",
      "Train Epoch: 140, Ave Loss: 0.2850578921210535 ACC: 0.900727921956431  AUC: nan MCC: 0.2165493964505203\n",
      "Train Epoch: 140, Ave Loss: 0.22801780795121135 ACC: 0.9269891665653038  AUC: 0.9445782735309459 MCC: 0.23639865442688754\n",
      "Train Epoch: 141, Ave Loss: 0.2841328532016995 ACC: 0.9012383060750228  AUC: nan MCC: 0.21477390017597148\n",
      "Train Epoch: 141, Ave Loss: 0.22773379029709565 ACC: 0.9279108650256781  AUC: 0.9446112158758309 MCC: 0.23587950734436397\n",
      "Train Epoch: 142, Ave Loss: 0.28658754996343827 ACC: 0.9012921779562606  AUC: nan MCC: 0.21231333788520707\n",
      "Train Epoch: 142, Ave Loss: 0.22803794478951556 ACC: 0.9274942990724427  AUC: 0.9441809844776367 MCC: 0.23579632335075243\n",
      "Train Epoch: 143, Ave Loss: 0.28737877906324605 ACC: 0.9004861775161435  AUC: nan MCC: 0.2148971482609914\n",
      "Train Epoch: 143, Ave Loss: 0.22824755546913464 ACC: 0.9275297477649616  AUC: 0.9461809258474567 MCC: 0.2361740419624775\n",
      "Train Epoch: 144, Ave Loss: 0.28404928582180056 ACC: 0.9006789812640722  AUC: nan MCC: 0.21336207961024573\n",
      "Train Epoch: 144, Ave Loss: 0.22797882571727685 ACC: 0.9277852812805115  AUC: 0.9452104601552116 MCC: 0.23681430177301588\n",
      "Train Epoch: 145, Ave Loss: 0.2863216678925651 ACC: 0.8995865023183149  AUC: nan MCC: 0.2100575182579181\n",
      "Train Epoch: 145, Ave Loss: 0.2281987416891402 ACC: 0.9278384017923477  AUC: 0.9450230724503291 MCC: 0.23620341157122632\n",
      "Train Epoch: 146, Ave Loss: 0.2860507966387967 ACC: 0.9000982282522163  AUC: nan MCC: 0.21005089278746963\n",
      "Train Epoch: 146, Ave Loss: 0.22831002142037934 ACC: 0.9279820641805528  AUC: 0.9442204772363951 MCC: 0.23602175599181507\n",
      "Train Epoch: 147, Ave Loss: 0.2851908209617468 ACC: 0.9023329747996278  AUC: nan MCC: 0.215735613558398\n",
      "Train Epoch: 147, Ave Loss: 0.22810462332675763 ACC: 0.928128203194744  AUC: 0.9448659859045717 MCC: 0.23674684359708492\n",
      "Train Epoch: 148, Ave Loss: 0.28486517113138926 ACC: 0.9019114785714102  AUC: nan MCC: 0.21416652584460558\n",
      "Train Epoch: 148, Ave Loss: 0.22809389657760115 ACC: 0.9277986281693171  AUC: 0.9451303158107784 MCC: 0.2361359533952953\n",
      "Train Epoch: 149, Ave Loss: 0.2849515145017497 ACC: 0.9006179587049937  AUC: nan MCC: 0.2150824808786678\n",
      "Train Epoch: 149, Ave Loss: 0.22786669402981397 ACC: 0.9275838526506488  AUC: 0.9459703464186641 MCC: 0.23599967529311972\n",
      "Train Epoch: 150, Ave Loss: 0.2856324567254169 ACC: 0.9013636271805386  AUC: nan MCC: 0.21169122135774598\n",
      "Train Epoch: 150, Ave Loss: 0.22794408837270486 ACC: 0.9276292222528929  AUC: 0.944604007642178 MCC: 0.23607338336767156\n",
      "Train Epoch: 151, Ave Loss: 0.2841170026691136 ACC: 0.900121970913793  AUC: nan MCC: 0.21192650879524852\n",
      "Train Epoch: 151, Ave Loss: 0.22792946599774133 ACC: 0.927400024674639  AUC: 0.9442140882677882 MCC: 0.2361813308725309\n",
      "Train Epoch: 152, Ave Loss: 0.28473139034186934 ACC: 0.9006439302319427  AUC: nan MCC: 0.21411014517506044\n",
      "Train Epoch: 152, Ave Loss: 0.2278807470749621 ACC: 0.9274574995709768  AUC: 0.9444188284042623 MCC: 0.2359874548492234\n",
      "Train Epoch: 153, Ave Loss: 0.28551220091464147 ACC: 0.9009578189878529  AUC: nan MCC: 0.21404313229460403\n",
      "Train Epoch: 153, Ave Loss: 0.22801633783080286 ACC: 0.9275489916557701  AUC: 0.9458265279391632 MCC: 0.23600592519174055\n",
      "Train Epoch: 154, Ave Loss: 0.2851946803985244 ACC: 0.9010540979277095  AUC: nan MCC: 0.21325501122231558\n",
      "Train Epoch: 154, Ave Loss: 0.22813136223271568 ACC: 0.9270120541773864  AUC: 0.9447578892349069 MCC: 0.23640446902770546\n",
      "Train Epoch: 155, Ave Loss: 0.28348467408355277 ACC: 0.9012902348305245  AUC: nan MCC: 0.21535817503625873\n",
      "Train Epoch: 155, Ave Loss: 0.2280718566779217 ACC: 0.9272374972598181  AUC: 0.9441923478251264 MCC: 0.23612970349667442\n",
      "Train Epoch: 156, Ave Loss: 0.286645576645126 ACC: 0.9007772547862093  AUC: nan MCC: 0.2139919781342465\n",
      "Train Epoch: 156, Ave Loss: 0.22799867793209475 ACC: 0.9270802363213446  AUC: 0.9440691054469526 MCC: 0.2356146677713412\n",
      "Train Epoch: 157, Ave Loss: 0.28542470277567245 ACC: 0.900937241389811  AUC: nan MCC: 0.21253894370771734\n",
      "Train Epoch: 157, Ave Loss: 0.22811264763953754 ACC: 0.9277097896446377  AUC: 0.9451653751061411 MCC: 0.2367440990722484\n",
      "Train Epoch: 158, Ave Loss: 0.28463851845531174 ACC: 0.9021787525964788  AUC: nan MCC: 0.21550727088025884\n",
      "Train Epoch: 158, Ave Loss: 0.22812842008118608 ACC: 0.9276314064240526  AUC: 0.9455427114967793 MCC: 0.23662042574970835\n",
      "Train Epoch: 159, Ave Loss: 0.2845925027899753 ACC: 0.9006171902433602  AUC: nan MCC: 0.2153981938498187\n",
      "Train Epoch: 159, Ave Loss: 0.22803217369869816 ACC: 0.9279390832949317  AUC: 0.944993081061224 MCC: 0.23635558617668553\n",
      "Train Epoch: 160, Ave Loss: 0.2849707755588445 ACC: 0.899872364209353  AUC: nan MCC: 0.2112242921432607\n",
      "Train Epoch: 160, Ave Loss: 0.2280606341855741 ACC: 0.9276555268921091  AUC: 0.9445847540889504 MCC: 0.23579632335075243\n",
      "Train Epoch: 161, Ave Loss: 0.28512560129506925 ACC: 0.9013040632811243  AUC: nan MCC: 0.2184713957427612\n",
      "Train Epoch: 161, Ave Loss: 0.22802836485944195 ACC: 0.9277378186303029  AUC: 0.9474358017205192 MCC: 0.23667205312556475\n",
      "Train Epoch: 162, Ave Loss: 0.2854162620384127 ACC: 0.9016104360727255  AUC: nan MCC: 0.21517151687236455\n",
      "Train Epoch: 162, Ave Loss: 0.2280914929978235 ACC: 0.9274433402659988  AUC: 0.94537863057572 MCC: 0.23598745484922343\n",
      "Train Epoch: 163, Ave Loss: 0.2858830981444716 ACC: 0.900206632206519  AUC: nan MCC: 0.21237705184788794\n",
      "Train Epoch: 163, Ave Loss: 0.22814175144299942 ACC: 0.9271042068329495  AUC: 0.944554506664124 MCC: 0.236487653021317\n",
      "Train Epoch: 164, Ave Loss: 0.2851053101822457 ACC: 0.9006619864101041  AUC: nan MCC: 0.2141366874804648\n",
      "Train Epoch: 164, Ave Loss: 0.22810185943991734 ACC: 0.9275512733474883  AUC: 0.9470192779676384 MCC: 0.23579632335075243\n",
      "Train Epoch: 165, Ave Loss: 0.2848966415988645 ACC: 0.8992973913668632  AUC: nan MCC: 0.21082230950236866\n",
      "Train Epoch: 165, Ave Loss: 0.22802514357448234 ACC: 0.9276488106284508  AUC: 0.9476404664551779 MCC: 0.23686318462403574\n",
      "Train Epoch: 166, Ave Loss: 0.2837722714985636 ACC: 0.902514395156857  AUC: nan MCC: 0.21350403450354677\n",
      "Train Epoch: 166, Ave Loss: 0.22803929006696852 ACC: 0.9275005873814829  AUC: 0.9460561229322018 MCC: 0.23579632335075243\n",
      "Train Epoch: 167, Ave Loss: 0.2843852973068979 ACC: 0.9015999844452995  AUC: nan MCC: 0.21750920410182673\n",
      "Train Epoch: 167, Ave Loss: 0.22803856343622764 ACC: 0.9278808094360173  AUC: 0.9451195790764054 MCC: 0.23599019937405996\n",
      "Train Epoch: 168, Ave Loss: 0.28540444113436947 ACC: 0.9008191797371402  AUC: nan MCC: 0.21528052502590087\n",
      "Train Epoch: 168, Ave Loss: 0.22805383253415645 ACC: 0.9275541117493482  AUC: 0.94505564299907 MCC: 0.23644617044555366\n",
      "Train Epoch: 169, Ave Loss: 0.2842003708284816 ACC: 0.9011780716401201  AUC: nan MCC: 0.21383528265215718\n",
      "Train Epoch: 169, Ave Loss: 0.22802097128726398 ACC: 0.9273657603454006  AUC: 0.9456859873829204 MCC: 0.2359874548492234\n",
      "Train Epoch: 170, Ave Loss: 0.2848663550280843 ACC: 0.900292439692309  AUC: nan MCC: 0.2151725004144803\n",
      "Train Epoch: 170, Ave Loss: 0.22802458318312244 ACC: 0.9272741812689791  AUC: 0.9449202766570634 MCC: 0.2359874548492234\n",
      "Train Epoch: 171, Ave Loss: 0.28447801453808286 ACC: 0.9008507202665892  AUC: nan MCC: 0.21425361069778856\n",
      "Train Epoch: 171, Ave Loss: 0.22803614427333235 ACC: 0.9280880266848212  AUC: 0.9456396272164491 MCC: 0.23644617044555372\n",
      "Train Epoch: 172, Ave Loss: 0.2850009422619862 ACC: 0.9017600776635865  AUC: nan MCC: 0.21759849973788115\n",
      "Train Epoch: 172, Ave Loss: 0.22807448560679472 ACC: 0.9279850629806374  AUC: 0.9448027554048156 MCC: 0.23599019937405993\n",
      "Train Epoch: 173, Ave Loss: 0.286090248446586 ACC: 0.8994825892791285  AUC: nan MCC: 0.2129464840615408\n",
      "Train Epoch: 173, Ave Loss: 0.22809533464666112 ACC: 0.9277544153420356  AUC: 0.9445766448779394 MCC: 0.23598745484922334\n",
      "Train Epoch: 174, Ave Loss: 0.285013559698362 ACC: 0.9007421861850972  AUC: nan MCC: 0.2138876924503666\n",
      "Train Epoch: 174, Ave Loss: 0.22809331806516248 ACC: 0.9275350195492453  AUC: 0.943660950796069 MCC: 0.23625229442224616\n",
      "Train Epoch: 175, Ave Loss: 0.2866940107417339 ACC: 0.9012445925325002  AUC: nan MCC: 0.21240813863773492\n",
      "Train Epoch: 175, Ave Loss: 0.22815925480071922 ACC: 0.9276038268886948  AUC: 0.9454797735745109 MCC: 0.2359874548492234\n",
      "Train Epoch: 176, Ave Loss: 0.2850110332319991 ACC: 0.9008523847715183  AUC: nan MCC: 0.21130157264050545\n",
      "Train Epoch: 176, Ave Loss: 0.22815694669457537 ACC: 0.92744397145361  AUC: 0.9447180568137831 MCC: 0.2359874548492234\n",
      "Train Epoch: 177, Ave Loss: 0.285823677053856 ACC: 0.9009167151376488  AUC: nan MCC: 0.21286323717506908\n",
      "Train Epoch: 177, Ave Loss: 0.22814090331643164 ACC: 0.9274995733440743  AUC: 0.9468876579828285 MCC: 0.2359874548492234\n",
      "Train Epoch: 178, Ave Loss: 0.28514502295255634 ACC: 0.9005340716953564  AUC: nan MCC: 0.21347068800868663\n",
      "Train Epoch: 178, Ave Loss: 0.2281438777909569 ACC: 0.9279733477857387  AUC: 0.944650831810954 MCC: 0.23618133087253088\n",
      "Train Epoch: 179, Ave Loss: 0.2868664920422504 ACC: 0.8994186194774293  AUC: nan MCC: 0.21182140910127195\n",
      "Train Epoch: 179, Ave Loss: 0.22815365910010052 ACC: 0.9278390772785124  AUC: 0.944852252948304 MCC: 0.23644617044555366\n",
      "Train Epoch: 180, Ave Loss: 0.28496297806604665 ACC: 0.900996606169199  AUC: nan MCC: 0.21396500189623316\n",
      "Train Epoch: 180, Ave Loss: 0.22817190492093664 ACC: 0.927543692235421  AUC: 0.9455743490585243 MCC: 0.2359874548492234\n",
      "Train Epoch: 181, Ave Loss: 0.2853822787778521 ACC: 0.9013651043684261  AUC: nan MCC: 0.21512247974126156\n",
      "Train Epoch: 181, Ave Loss: 0.22816940021832688 ACC: 0.927762624679124  AUC: 0.9458211591320645 MCC: 0.23625229442224616\n",
      "Train Epoch: 182, Ave Loss: 0.2857897312839548 ACC: 0.9003443851698809  AUC: nan MCC: 0.21319500529834406\n",
      "Train Epoch: 182, Ave Loss: 0.22817739689295574 ACC: 0.9281031862582176  AUC: 0.9450889989864267 MCC: 0.23644617044555363\n",
      "Train Epoch: 183, Ave Loss: 0.2852963198225129 ACC: 0.8989298450480377  AUC: nan MCC: 0.2124721578176019\n",
      "Train Epoch: 183, Ave Loss: 0.22818108731420914 ACC: 0.9277139730249678  AUC: 0.9448368294045341 MCC: 0.23598745484922334\n",
      "Train Epoch: 184, Ave Loss: 0.28605228144934136 ACC: 0.8998497300821027  AUC: nan MCC: 0.2130539385160737\n",
      "Train Epoch: 184, Ave Loss: 0.22819511113522983 ACC: 0.9278714109865542  AUC: 0.9443348039378352 MCC: 0.23618133087253085\n",
      "Train Epoch: 185, Ave Loss: 0.2861774751158575 ACC: 0.9007880803882246  AUC: nan MCC: 0.21488958956507034\n",
      "Train Epoch: 185, Ave Loss: 0.2282138547868898 ACC: 0.9277823170153303  AUC: 0.9438732206517693 MCC: 0.23644617044555366\n",
      "Train Epoch: 186, Ave Loss: 0.2841043740056912 ACC: 0.90007026750177  AUC: nan MCC: 0.21243745077618303\n",
      "Train Epoch: 186, Ave Loss: 0.22822001505323317 ACC: 0.9277927423697921  AUC: 0.944640801450239 MCC: 0.23644617044555366\n",
      "Train Epoch: 187, Ave Loss: 0.28633656242482547 ACC: 0.900317303967545  AUC: nan MCC: 0.21339563086575902\n",
      "Train Epoch: 187, Ave Loss: 0.22824026862020133 ACC: 0.9276889852706222  AUC: 0.9458443774221313 MCC: 0.23666930860072824\n",
      "Train Epoch: 188, Ave Loss: 0.28452481054950185 ACC: 0.9006307109211075  AUC: nan MCC: 0.21357799462535365\n",
      "Train Epoch: 188, Ave Loss: 0.228231706686919 ACC: 0.9280480808132041  AUC: 0.9456884912707932 MCC: 0.23666930860072816\n",
      "Train Epoch: 189, Ave Loss: 0.28421077415566115 ACC: 0.9012978780727241  AUC: nan MCC: 0.2179860052209281\n",
      "Train Epoch: 189, Ave Loss: 0.22824592627688445 ACC: 0.9281758658721817  AUC: 0.9449109086847105 MCC: 0.23723015710109993\n",
      "Train Epoch: 190, Ave Loss: 0.2841448262789581 ACC: 0.9011009077124584  AUC: nan MCC: 0.21242152876346831\n",
      "Train Epoch: 190, Ave Loss: 0.22825779785409916 ACC: 0.9277061277478764  AUC: 0.945722267249543 MCC: 0.23681314292261788\n",
      "Train Epoch: 191, Ave Loss: 0.2846580220988116 ACC: 0.901495697883985  AUC: nan MCC: 0.21586064243968187\n",
      "Train Epoch: 191, Ave Loss: 0.22825065305751957 ACC: 0.9277911854017414  AUC: 0.9445818789212019 MCC: 0.23677144150476961\n",
      "Train Epoch: 192, Ave Loss: 0.28477909745665503 ACC: 0.899860101106361  AUC: nan MCC: 0.21334417765188884\n",
      "Train Epoch: 192, Ave Loss: 0.22825634837681646 ACC: 0.9279058643008242  AUC: 0.9446333249253972 MCC: 0.23703628107779245\n",
      "Train Epoch: 193, Ave Loss: 0.28544884269980875 ACC: 0.9012944038898353  AUC: nan MCC: 0.2164470297228341\n",
      "Train Epoch: 193, Ave Loss: 0.22825858432325025 ACC: 0.9280055850826349  AUC: 0.9453446366035442 MCC: 0.2370362810777924\n",
      "Train Epoch: 194, Ave Loss: 0.2855479019630433 ACC: 0.9026386456071022  AUC: nan MCC: 0.22085619176196022\n",
      "Train Epoch: 194, Ave Loss: 0.22827926144498326 ACC: 0.9279013315380145  AUC: 0.9450993144210007 MCC: 0.23703628107779245\n",
      "Train Epoch: 195, Ave Loss: 0.28385900707823397 ACC: 0.9012161267117821  AUC: nan MCC: 0.21609112647192794\n",
      "Train Epoch: 195, Ave Loss: 0.2282902688915045 ACC: 0.9276510223028629  AUC: 0.9453008389972944 MCC: 0.2370362810777924\n",
      "Train Epoch: 196, Ave Loss: 0.28540094734824056 ACC: 0.8992891216973771  AUC: nan MCC: 0.2134840525041042\n",
      "Train Epoch: 196, Ave Loss: 0.2283072009424916 ACC: 0.9280160104370969  AUC: 0.9461800376142478 MCC: 0.23723015710109993\n",
      "Train Epoch: 197, Ave Loss: 0.28441312357562204 ACC: 0.9005819162424321  AUC: nan MCC: 0.21451710447353353\n",
      "Train Epoch: 197, Ave Loss: 0.22831149809906753 ACC: 0.9281202639817175  AUC: 0.9457378398570008 MCC: 0.23723015710109996\n",
      "Train Epoch: 198, Ave Loss: 0.284234689228722 ACC: 0.900014543975751  AUC: nan MCC: 0.2148869578501909\n",
      "Train Epoch: 198, Ave Loss: 0.22833858804706106 ACC: 0.9281202639817175  AUC: 0.9470571524155111 MCC: 0.23723015710109993\n",
      "Train Epoch: 199, Ave Loss: 0.2856382335097983 ACC: 0.8998966582782667  AUC: nan MCC: 0.21396058329654885\n",
      "Train Epoch: 199, Ave Loss: 0.22835463669835607 ACC: 0.9281202639817175  AUC: 0.9469416388963331 MCC: 0.2372301571010999\n",
      "Train Epoch: 200, Ave Loss: 0.2852608069191535 ACC: 0.9000201373173067  AUC: nan MCC: 0.21342206249370063\n",
      "Train Epoch: 200, Ave Loss: 0.22837419683150903 ACC: 0.9281202639817174  AUC: 0.9450598393739988 MCC: 0.23723015710109993\n",
      "Train Epoch: 201, Ave Loss: 0.28568327564212614 ACC: 0.900499327549183  AUC: nan MCC: 0.21372605111742693\n",
      "Train Epoch: 201, Ave Loss: 0.22839543305773496 ACC: 0.9280892696846682  AUC: 0.9453727409491849 MCC: 0.2372301571010999\n",
      "Train Epoch: 202, Ave Loss: 0.2842292176568257 ACC: 0.9009255213809482  AUC: nan MCC: 0.21696987894469152\n",
      "Train Epoch: 202, Ave Loss: 0.22841638479629814 ACC: 0.9280892696846682  AUC: 0.9456770732559776 MCC: 0.23723015710109996\n",
      "Train Epoch: 203, Ave Loss: 0.2860579445252196 ACC: 0.8997940802721529  AUC: nan MCC: 0.21529205770116916\n",
      "Train Epoch: 203, Ave Loss: 0.22846015314904095 ACC: 0.9280451624157903  AUC: 0.9444685403095622 MCC: 0.23723015710109996\n",
      "Train Epoch: 204, Ave Loss: 0.2861962982512971 ACC: 0.8996852089456864  AUC: nan MCC: 0.2138699916696884\n",
      "Train Epoch: 204, Ave Loss: 0.22848725358126473 ACC: 0.927881920968145  AUC: 0.9450282045019736 MCC: 0.23696531752807715\n",
      "Train Epoch: 205, Ave Loss: 0.2860483955490456 ACC: 0.9015159276368098  AUC: nan MCC: 0.21555068925563278\n",
      "Train Epoch: 205, Ave Loss: 0.22851482907684068 ACC: 0.9279524925983499  AUC: 0.9448120886433272 MCC: 0.23723015710109996\n",
      "Train Epoch: 206, Ave Loss: 0.28545127629792805 ACC: 0.9015529043827729  AUC: nan MCC: 0.2179977641808914\n",
      "Train Epoch: 206, Ave Loss: 0.2285417786176848 ACC: 0.9279524925983497  AUC: 0.9451356220538089 MCC: 0.23723015710109993\n",
      "Train Epoch: 207, Ave Loss: 0.28533808805477534 ACC: 0.9008530521868747  AUC: nan MCC: 0.2161394793142672\n",
      "Train Epoch: 207, Ave Loss: 0.22856768703699448 ACC: 0.9277941264996167  AUC: 0.9454772836002737 MCC: 0.2370362810777924\n",
      "Train Epoch: 208, Ave Loss: 0.28503916284648023 ACC: 0.9007778395855995  AUC: nan MCC: 0.21528078193234568\n",
      "Train Epoch: 208, Ave Loss: 0.22860405991155477 ACC: 0.9271974638217814  AUC: 0.945658237646803 MCC: 0.23645042384049964\n",
      "Train Epoch: 209, Ave Loss: 0.2857698884865633 ACC: 0.900111430941822  AUC: nan MCC: 0.21458883650725474\n",
      "Train Epoch: 209, Ave Loss: 0.2286420926900997 ACC: 0.9271570215047136  AUC: 0.9454901105160068 MCC: 0.23671526341352245\n",
      "Train Epoch: 210, Ave Loss: 0.28469027510646966 ACC: 0.900174973809369  AUC: nan MCC: 0.21465485427138917\n",
      "Train Epoch: 210, Ave Loss: 0.22866663345279226 ACC: 0.9269256323572892  AUC: 0.9447590310101809 MCC: 0.23645042384049964\n",
      "Train Epoch: 211, Ave Loss: 0.2840815814333255 ACC: 0.9008767712157825  AUC: nan MCC: 0.218782091114205\n",
      "Train Epoch: 211, Ave Loss: 0.2286967749598384 ACC: 0.9269256323572894  AUC: 0.9454291727591387 MCC: 0.23645042384049964\n",
      "Train Epoch: 212, Ave Loss: 0.28525866893304774 ACC: 0.8997090495864507  AUC: nan MCC: 0.2154307961805747\n",
      "Train Epoch: 212, Ave Loss: 0.2287201901292661 ACC: 0.9269256323572894  AUC: 0.9444308031694288 MCC: 0.2364504238404996\n",
      "Train Epoch: 213, Ave Loss: 0.2858437484440428 ACC: 0.8988497052276534  AUC: nan MCC: 0.2142300177869154\n",
      "Train Epoch: 213, Ave Loss: 0.22874515861182024 ACC: 0.9269256323572893  AUC: 0.9456418628387497 MCC: 0.2364504238404996\n",
      "Train Epoch: 214, Ave Loss: 0.28517189288846123 ACC: 0.9000078054660691  AUC: nan MCC: 0.21544046748750495\n",
      "Train Epoch: 214, Ave Loss: 0.22878364256660308 ACC: 0.9270710264234946  AUC: 0.9466401677234532 MCC: 0.23694097379029125\n",
      "Train Epoch: 215, Ave Loss: 0.2849309356884425 ACC: 0.8996842709151768  AUC: nan MCC: 0.2163630225002928\n",
      "Train Epoch: 215, Ave Loss: 0.2288111905785929 ACC: 0.9270710264234945  AUC: 0.944459774411804 MCC: 0.23694097379029125\n",
      "Train Epoch: 216, Ave Loss: 0.28495879983057 ACC: 0.8999802823406249  AUC: nan MCC: 0.21534470661169094\n",
      "Train Epoch: 216, Ave Loss: 0.2288423614301426 ACC: 0.9269912497980459  AUC: 0.9451585992444748 MCC: 0.23694097379029125\n",
      "Train Epoch: 217, Ave Loss: 0.2856977059752521 ACC: 0.9003448896422535  AUC: nan MCC: 0.21686995200816353\n",
      "Train Epoch: 217, Ave Loss: 0.2288765988839369 ACC: 0.9269912497980459  AUC: 0.9466660010488968 MCC: 0.23694097379029125\n",
      "Train Epoch: 218, Ave Loss: 0.2837993263204371 ACC: 0.9002155225650684  AUC: nan MCC: 0.21891667690654343\n",
      "Train Epoch: 218, Ave Loss: 0.22890403235808696 ACC: 0.9269912497980457  AUC: 0.9449066288811719 MCC: 0.23694097379029122\n",
      "Train Epoch: 219, Ave Loss: 0.28424631431338404 ACC: 0.8993980011941424  AUC: nan MCC: 0.217584085113248\n",
      "Train Epoch: 219, Ave Loss: 0.22893644385669307 ACC: 0.9270279470457523  AUC: 0.9467808090545362 MCC: 0.2373079462673555\n",
      "Train Epoch: 220, Ave Loss: 0.2856929757614145 ACC: 0.8990657670080036  AUC: nan MCC: 0.21332400278645428\n",
      "Train Epoch: 220, Ave Loss: 0.22896651466347281 ACC: 0.9270279470457525  AUC: 0.9457890417134455 MCC: 0.23730794626735546\n",
      "Train Epoch: 221, Ave Loss: 0.285371631846325 ACC: 0.9011368197117968  AUC: nan MCC: 0.21992409794744608\n",
      "Train Epoch: 221, Ave Loss: 0.22899487087676193 ACC: 0.9270279470457523  AUC: 0.9450151605150038 MCC: 0.23730794626735555\n",
      "Train Epoch: 222, Ave Loss: 0.28503548487503627 ACC: 0.8993829471157841  AUC: nan MCC: 0.21650757419271022\n",
      "Train Epoch: 222, Ave Loss: 0.22902903530254773 ACC: 0.926989720746058  AUC: 0.9456469464990812 MCC: 0.23730794626735546\n",
      "Train Epoch: 223, Ave Loss: 0.2847565137924833 ACC: 0.9004597562382471  AUC: nan MCC: 0.22010886802514734\n",
      "Train Epoch: 223, Ave Loss: 0.22905521897860134 ACC: 0.9269897207460582  AUC: 0.9459428327266537 MCC: 0.2373079462673555\n",
      "Train Epoch: 224, Ave Loss: 0.28522728587178964 ACC: 0.900413743853554  AUC: nan MCC: 0.2206951569088612\n",
      "Train Epoch: 224, Ave Loss: 0.22908879759971182 ACC: 0.9269897207460579  AUC: 0.9473685795650493 MCC: 0.23730794626735557\n",
      "Train Epoch: 225, Ave Loss: 0.2845148295815436 ACC: 0.899905535813456  AUC: nan MCC: 0.2204011923125882\n",
      "Train Epoch: 225, Ave Loss: 0.22911673680566888 ACC: 0.926989720746058  AUC: 0.9457459671039139 MCC: 0.23730794626735555\n",
      "Train Epoch: 226, Ave Loss: 0.2863642132887469 ACC: 0.9001070037788512  AUC: nan MCC: 0.2193808234034676\n",
      "Train Epoch: 226, Ave Loss: 0.22915167335000625 ACC: 0.9266868650383361  AUC: 0.944694849568317 MCC: 0.2373079462673555\n",
      "Train Epoch: 227, Ave Loss: 0.285034693702808 ACC: 0.901232352397106  AUC: nan MCC: 0.21700802125332114\n",
      "Train Epoch: 227, Ave Loss: 0.2291832832655161 ACC: 0.926686865038336  AUC: 0.9459256479266842 MCC: 0.23730794626735546\n",
      "Train Epoch: 228, Ave Loss: 0.28513176824691117 ACC: 0.8997971612270426  AUC: nan MCC: 0.21864106957635981\n",
      "Train Epoch: 228, Ave Loss: 0.22921073662416575 ACC: 0.9266302334832336  AUC: 0.9443347257458048 MCC: 0.23730794626735546\n",
      "Train Epoch: 229, Ave Loss: 0.2858961066950849 ACC: 0.8995568321745199  AUC: nan MCC: 0.21818121809841617\n",
      "Train Epoch: 229, Ave Loss: 0.2292416817351719 ACC: 0.9266302334832335  AUC: 0.9459195273793184 MCC: 0.2373079462673555\n",
      "Train Epoch: 230, Ave Loss: 0.2841228015429649 ACC: 0.9002582806956156  AUC: nan MCC: 0.21875320270080348\n",
      "Train Epoch: 230, Ave Loss: 0.22926963989649476 ACC: 0.9266302334832335  AUC: 0.9442266789788195 MCC: 0.23730794626735544\n",
      "Train Epoch: 231, Ave Loss: 0.2861841928951831 ACC: 0.8995280650546075  AUC: nan MCC: 0.22131478742596286\n",
      "Train Epoch: 231, Ave Loss: 0.22929955739692098 ACC: 0.9266302334832335  AUC: 0.944173404323699 MCC: 0.23730794626735546\n",
      "Train Epoch: 232, Ave Loss: 0.28640990176760805 ACC: 0.8983803526079699  AUC: nan MCC: 0.21613950001584034\n",
      "Train Epoch: 232, Ave Loss: 0.22932988207197355 ACC: 0.9265194187297341  AUC: 0.9446803621091541 MCC: 0.23756278826531677\n",
      "Train Epoch: 233, Ave Loss: 0.2837040400149683 ACC: 0.9009201994318072  AUC: nan MCC: 0.22015303327088157\n",
      "Train Epoch: 233, Ave Loss: 0.229355292038318 ACC: 0.9267421827139659  AUC: 0.9448560276283503 MCC: 0.23889937217070797\n",
      "Train Epoch: 234, Ave Loss: 0.2853094996904266 ACC: 0.9003362404820626  AUC: nan MCC: 0.21867062771771598\n",
      "Train Epoch: 234, Ave Loss: 0.22938392291893298 ACC: 0.9267421827139662  AUC: 0.946382782326323 MCC: 0.23889937217070803\n",
      "Train Epoch: 235, Ave Loss: 0.2856534673323769 ACC: 0.9005329670580126  AUC: nan MCC: 0.21831920153982973\n",
      "Train Epoch: 235, Ave Loss: 0.22941122952140924 ACC: 0.9267614564785176  AUC: 0.9443294417909954 MCC: 0.2390342885225698\n",
      "Train Epoch: 236, Ave Loss: 0.2852676194936964 ACC: 0.9003969721499206  AUC: nan MCC: 0.22128207234162442\n",
      "Train Epoch: 236, Ave Loss: 0.22943456211191568 ACC: 0.9267614564785176  AUC: 0.9449051183344573 MCC: 0.23903428852256983\n",
      "Train Epoch: 237, Ave Loss: 0.2841841826411533 ACC: 0.8993846190877051  AUC: nan MCC: 0.21955061924737226\n",
      "Train Epoch: 237, Ave Loss: 0.22946263132924902 ACC: 0.9267614564785175  AUC: 0.9442739167368639 MCC: 0.23903428852256983\n",
      "Train Epoch: 238, Ave Loss: 0.28352269432095933 ACC: 0.9022894942236015  AUC: nan MCC: 0.2246615111910062\n",
      "Train Epoch: 238, Ave Loss: 0.22948524898152692 ACC: 0.9267614564785175  AUC: 0.94475850690101 MCC: 0.23903428852256986\n",
      "Train Epoch: 239, Ave Loss: 0.2838405550860818 ACC: 0.901333986947891  AUC: nan MCC: 0.22552682224437295\n",
      "Train Epoch: 239, Ave Loss: 0.22951042313458098 ACC: 0.9267614564785176  AUC: 0.944553777882045 MCC: 0.2390342885225699\n",
      "Train Epoch: 240, Ave Loss: 0.28539675062575287 ACC: 0.9005124516223945  AUC: nan MCC: 0.21948752204858338\n",
      "Train Epoch: 240, Ave Loss: 0.22953187041593154 ACC: 0.9268888774774985  AUC: 0.9439414167863549 MCC: 0.23944457622486337\n",
      "Train Epoch: 241, Ave Loss: 0.28478617111146076 ACC: 0.8992326614397731  AUC: nan MCC: 0.21812523938265285\n",
      "Train Epoch: 241, Ave Loss: 0.22955529947404799 ACC: 0.9268888774774982  AUC: 0.9443152403387189 MCC: 0.2394445762248634\n",
      "Train Epoch: 242, Ave Loss: 0.2840799946513947 ACC: 0.9004508351802218  AUC: nan MCC: 0.21870098632645615\n",
      "Train Epoch: 242, Ave Loss: 0.2295786951343163 ACC: 0.9268888774774982  AUC: 0.9441649819140139 MCC: 0.23944457622486334\n",
      "Train Epoch: 243, Ave Loss: 0.2841917000583736 ACC: 0.9001800998211115  AUC: nan MCC: 0.22177803012319267\n",
      "Train Epoch: 243, Ave Loss: 0.2295973210196747 ACC: 0.9268888774774982  AUC: 0.94480011319243 MCC: 0.2394445762248634\n",
      "Train Epoch: 244, Ave Loss: 0.2848601435127452 ACC: 0.8993939238103289  AUC: nan MCC: 0.21859589158233\n",
      "Train Epoch: 244, Ave Loss: 0.22961749398062045 ACC: 0.926905866944029  AUC: 0.9453142021426875 MCC: 0.23959748142364012\n",
      "Train Epoch: 245, Ave Loss: 0.28698213199545763 ACC: 0.9002338779832296  AUC: nan MCC: 0.22051281393297362\n",
      "Train Epoch: 245, Ave Loss: 0.22963739909276168 ACC: 0.926956835343621  AUC: 0.9461861580611186 MCC: 0.2400561970199704\n",
      "Train Epoch: 246, Ave Loss: 0.2856863160734361 ACC: 0.8993274538888933  AUC: nan MCC: 0.216863723433672\n",
      "Train Epoch: 246, Ave Loss: 0.22965503276745938 ACC: 0.9269568353436213  AUC: 0.944770962456078 MCC: 0.24005619701997044\n",
      "Train Epoch: 247, Ave Loss: 0.2847484677419827 ACC: 0.9002244703901722  AUC: nan MCC: 0.2201445094164826\n",
      "Train Epoch: 247, Ave Loss: 0.2296717147117554 ACC: 0.926956835343621  AUC: 0.9444754463339684 MCC: 0.2400561970199704\n",
      "Train Epoch: 248, Ave Loss: 0.2849584778585923 ACC: 0.898947794394643  AUC: nan MCC: 0.21930542432344471\n",
      "Train Epoch: 248, Ave Loss: 0.22968800246594 ACC: 0.9269568353436213  AUC: 0.9455879391542094 MCC: 0.24005619701997044\n",
      "Train Epoch: 249, Ave Loss: 0.28391410426603886 ACC: 0.900463522164571  AUC: nan MCC: 0.22298581246510496\n",
      "Train Epoch: 249, Ave Loss: 0.22970250735742095 ACC: 0.9269568353436214  AUC: 0.9454406482975072 MCC: 0.2400561970199704\n",
      "Train Epoch: 250, Ave Loss: 0.28573558454920783 ACC: 0.8993073352622758  AUC: nan MCC: 0.22074966710574268\n",
      "Train Epoch: 250, Ave Loss: 0.22971819780073147 ACC: 0.9269568353436214  AUC: 0.9462564144423535 MCC: 0.24005619701997044\n",
      "Train Epoch: 251, Ave Loss: 0.284881182891678 ACC: 0.9000528150364511  AUC: nan MCC: 0.22141733732045102\n",
      "Train Epoch: 251, Ave Loss: 0.22973065934171047 ACC: 0.9269568353436213  AUC: 0.9455060240922654 MCC: 0.24005619701997044\n",
      "Train Epoch: 252, Ave Loss: 0.2843590297754175 ACC: 0.8990427687410192  AUC: nan MCC: 0.21838838107360925\n",
      "Train Epoch: 252, Ave Loss: 0.22974376567878854 ACC: 0.9269568353436213  AUC: 0.9451519836989837 MCC: 0.2400561970199704\n",
      "Train Epoch: 253, Ave Loss: 0.28569161408993415 ACC: 0.898591150332351  AUC: nan MCC: 0.21857013884019\n",
      "Train Epoch: 253, Ave Loss: 0.22975562767770236 ACC: 0.9269568353436213  AUC: 0.9462070875788368 MCC: 0.2400561970199704\n",
      "Train Epoch: 254, Ave Loss: 0.2852560980550977 ACC: 0.8991387721869408  AUC: nan MCC: 0.21775951060727905\n",
      "Train Epoch: 254, Ave Loss: 0.22976697859075887 ACC: 0.9269568353436213  AUC: 0.9452106228211969 MCC: 0.2400561970199704\n",
      "Train Epoch: 255, Ave Loss: 0.28614302932233504 ACC: 0.8987393345095174  AUC: nan MCC: 0.2198671319019022\n",
      "Train Epoch: 255, Ave Loss: 0.22977781532436223 ACC: 0.9269069749527157  AUC: 0.9460767764757875 MCC: 0.2399184441961603\n",
      "Train Epoch: 256, Ave Loss: 0.28619981930280064 ACC: 0.899048962572257  AUC: nan MCC: 0.2197825495524866\n",
      "Train Epoch: 256, Ave Loss: 0.22978732809496447 ACC: 0.9269069749527157  AUC: 0.9450969119523185 MCC: 0.23991844419616026\n",
      "Train Epoch: 257, Ave Loss: 0.2838520950073605 ACC: 0.9002927747709183  AUC: nan MCC: 0.22105379425741165\n",
      "Train Epoch: 257, Ave Loss: 0.22979742618147322 ACC: 0.9269069749527157  AUC: 0.9458414638170045 MCC: 0.2399184441961603\n",
      "Train Epoch: 258, Ave Loss: 0.2857949588832146 ACC: 0.8986844846995011  AUC: nan MCC: 0.21840598235265515\n",
      "Train Epoch: 258, Ave Loss: 0.22980545529899574 ACC: 0.9269069749527156  AUC: 0.943578199785919 MCC: 0.2399184441961603\n",
      "Train Epoch: 259, Ave Loss: 0.2871831609884116 ACC: 0.8997095631599205  AUC: nan MCC: 0.2233904207237754\n",
      "Train Epoch: 259, Ave Loss: 0.2298135895510392 ACC: 0.9269069749527156  AUC: 0.9450122298858216 MCC: 0.2399184441961603\n",
      "Train Epoch: 260, Ave Loss: 0.2854988555823715 ACC: 0.9001161828407866  AUC: nan MCC: 0.22284851889195056\n",
      "Train Epoch: 260, Ave Loss: 0.22982182215650804 ACC: 0.9269069749527157  AUC: 0.9456308951470916 MCC: 0.2399184441961603\n",
      "Train Epoch: 261, Ave Loss: 0.28473635105450285 ACC: 0.8998182434049989  AUC: nan MCC: 0.21950164087766094\n",
      "Train Epoch: 261, Ave Loss: 0.22982870166796807 ACC: 0.9269069749527158  AUC: 0.9443546804193619 MCC: 0.23991844419616032\n",
      "Train Epoch: 262, Ave Loss: 0.28537952913731024 ACC: 0.8998279779178852  AUC: nan MCC: 0.21948936956713952\n",
      "Train Epoch: 262, Ave Loss: 0.22983563091656334 ACC: 0.9269069749527158  AUC: 0.9459014529993094 MCC: 0.23991844419616026\n",
      "Train Epoch: 263, Ave Loss: 0.28496893257510575 ACC: 0.8986805719041131  AUC: nan MCC: 0.21794897830721083\n",
      "Train Epoch: 263, Ave Loss: 0.2298418599000372 ACC: 0.9269797869521333  AUC: 0.9457894105637058 MCC: 0.2403553161926653\n",
      "Train Epoch: 264, Ave Loss: 0.2842645928295213 ACC: 0.9004336523795607  AUC: nan MCC: 0.2216360865677476\n",
      "Train Epoch: 264, Ave Loss: 0.2298477263472409 ACC: 0.9269797869521332  AUC: 0.9453508373833838 MCC: 0.2403553161926653\n",
      "Train Epoch: 265, Ave Loss: 0.2853614965852742 ACC: 0.8997481161952812  AUC: nan MCC: 0.22035055324588862\n",
      "Train Epoch: 265, Ave Loss: 0.22985345149880762 ACC: 0.9269797869521332  AUC: 0.9446443338485895 MCC: 0.24035531619266534\n",
      "Train Epoch: 266, Ave Loss: 0.2851755498878417 ACC: 0.8997439174538208  AUC: nan MCC: 0.22148602393730707\n",
      "Train Epoch: 266, Ave Loss: 0.22985842859654096 ACC: 0.9269797869521333  AUC: 0.9456707497135763 MCC: 0.24035531619266534\n",
      "Train Epoch: 267, Ave Loss: 0.2868414646123744 ACC: 0.8982205038883382  AUC: nan MCC: 0.21887400833977738\n",
      "Train Epoch: 267, Ave Loss: 0.22986347944877852 ACC: 0.9269797869521333  AUC: 0.9448260929282951 MCC: 0.24035531619266529\n",
      "Train Epoch: 268, Ave Loss: 0.2856327985574498 ACC: 0.8984207522786195  AUC: nan MCC: 0.21887872385810833\n",
      "Train Epoch: 268, Ave Loss: 0.22986794837368235 ACC: 0.9269797869521332  AUC: 0.9454855173088635 MCC: 0.2403553161926653\n",
      "Train Epoch: 269, Ave Loss: 0.2850744016845396 ACC: 0.8988883889194963  AUC: nan MCC: 0.2182963220974883\n",
      "Train Epoch: 269, Ave Loss: 0.22987217783689182 ACC: 0.9269797869521333  AUC: 0.9458130021868992 MCC: 0.2403553161926653\n",
      "Train Epoch: 270, Ave Loss: 0.28631621395748086 ACC: 0.8988296339719013  AUC: nan MCC: 0.21799524305530837\n",
      "Train Epoch: 270, Ave Loss: 0.22987601785302506 ACC: 0.9269797869521333  AUC: 0.9454113494472437 MCC: 0.24035531619266534\n",
      "Train Epoch: 271, Ave Loss: 0.2852679208668207 ACC: 0.8998464495126375  AUC: nan MCC: 0.21988808764596024\n",
      "Train Epoch: 271, Ave Loss: 0.22987992441175498 ACC: 0.9269797869521333  AUC: 0.9442798204928033 MCC: 0.24035531619266534\n",
      "Train Epoch: 272, Ave Loss: 0.2852911547262825 ACC: 0.8982931449785088  AUC: nan MCC: 0.21928895009694782\n",
      "Train Epoch: 272, Ave Loss: 0.22988323116849732 ACC: 0.9269797869521333  AUC: 0.94423934809765 MCC: 0.24035531619266529\n",
      "Train Epoch: 273, Ave Loss: 0.28469390329438155 ACC: 0.8986667461998514  AUC: nan MCC: 0.2173573452935262\n",
      "Train Epoch: 273, Ave Loss: 0.22988655757038795 ACC: 0.9267844794713429  AUC: 0.945400275421991 MCC: 0.2403553161926653\n",
      "Train Epoch: 274, Ave Loss: 0.2842482008214598 ACC: 0.8990306361764085  AUC: nan MCC: 0.2193792789932934\n",
      "Train Epoch: 274, Ave Loss: 0.2298894040135607 ACC: 0.9267844794713428  AUC: 0.9444889645973819 MCC: 0.24035531619266529\n",
      "Train Epoch: 275, Ave Loss: 0.28476663308400274 ACC: 0.8996645323013788  AUC: nan MCC: 0.21980407359113038\n",
      "Train Epoch: 275, Ave Loss: 0.22989204653789538 ACC: 0.9267844794713428  AUC: 0.944709863674643 MCC: 0.2403553161926653\n",
      "Train Epoch: 276, Ave Loss: 0.28488653156032784 ACC: 0.8989799258262716  AUC: nan MCC: 0.21839328352269727\n",
      "Train Epoch: 276, Ave Loss: 0.22989463842423832 ACC: 0.9267844794713428  AUC: 0.9456707632518334 MCC: 0.24035531619266534\n",
      "Train Epoch: 277, Ave Loss: 0.28586965972296036 ACC: 0.8993028114516852  AUC: nan MCC: 0.21907944595620565\n",
      "Train Epoch: 277, Ave Loss: 0.22989719797708635 ACC: 0.9267844794713428  AUC: 0.9447893538644095 MCC: 0.2403553161926653\n",
      "Train Epoch: 278, Ave Loss: 0.288037522235766 ACC: 0.8986376326590435  AUC: nan MCC: 0.22072453821130433\n",
      "Train Epoch: 278, Ave Loss: 0.22989945786861968 ACC: 0.9267844794713427  AUC: 0.9458380667007285 MCC: 0.2403553161926653\n",
      "Train Epoch: 279, Ave Loss: 0.28607078404548975 ACC: 0.8995904629554293  AUC: nan MCC: 0.22220827134972843\n",
      "Train Epoch: 279, Ave Loss: 0.22990157297177133 ACC: 0.9267844794713428  AUC: 0.9445873935534866 MCC: 0.24035531619266534\n",
      "Train Epoch: 280, Ave Loss: 0.2855632848487506 ACC: 0.89895571030738  AUC: nan MCC: 0.22096130094809074\n",
      "Train Epoch: 280, Ave Loss: 0.22990345771852103 ACC: 0.9267844794713427  AUC: 0.943809940048344 MCC: 0.24035531619266529\n",
      "Train Epoch: 281, Ave Loss: 0.28480719984905817 ACC: 0.8986798812938827  AUC: nan MCC: 0.21933353296536126\n",
      "Train Epoch: 281, Ave Loss: 0.22990516322945626 ACC: 0.9267844794713427  AUC: 0.9441821600793409 MCC: 0.2403553161926653\n",
      "Train Epoch: 282, Ave Loss: 0.2856780669294302 ACC: 0.8981980859006347  AUC: nan MCC: 0.21959931171016286\n",
      "Train Epoch: 282, Ave Loss: 0.22990680241345726 ACC: 0.9267844794713427  AUC: 0.9451842996080962 MCC: 0.24035531619266529\n",
      "Train Epoch: 283, Ave Loss: 0.2838030706549491 ACC: 0.900013033047081  AUC: nan MCC: 0.22030691223654478\n",
      "Train Epoch: 283, Ave Loss: 0.22990822199517816 ACC: 0.9267844794713429  AUC: 0.9456271539259791 MCC: 0.2403553161926653\n",
      "Train Epoch: 284, Ave Loss: 0.28685594895085464 ACC: 0.8979994961476121  AUC: nan MCC: 0.21820044495787477\n",
      "Train Epoch: 284, Ave Loss: 0.22990962176990706 ACC: 0.9267844794713429  AUC: 0.9456214229397166 MCC: 0.24035531619266534\n",
      "Train Epoch: 285, Ave Loss: 0.28592419383940826 ACC: 0.9001657491463299  AUC: nan MCC: 0.22019946648491973\n",
      "Train Epoch: 285, Ave Loss: 0.22991088820927846 ACC: 0.9267844794713429  AUC: 0.9455202196271582 MCC: 0.24035531619266529\n",
      "Train Epoch: 286, Ave Loss: 0.28485301891003295 ACC: 0.8995475143458933  AUC: nan MCC: 0.2204207820249292\n",
      "Train Epoch: 286, Ave Loss: 0.2299120304931968 ACC: 0.9267844794713427  AUC: 0.9441207067928186 MCC: 0.24035531619266529\n",
      "Train Epoch: 287, Ave Loss: 0.2862684833736322 ACC: 0.8989579951362958  AUC: nan MCC: 0.2225099667198493\n",
      "Train Epoch: 287, Ave Loss: 0.22991312732060273 ACC: 0.9267844794713428  AUC: 0.9451137177707494 MCC: 0.2403553161926653\n",
      "Train Epoch: 288, Ave Loss: 0.28305747916012186 ACC: 0.8999814637230616  AUC: nan MCC: 0.22211243182088097\n",
      "Train Epoch: 288, Ave Loss: 0.2299140927230902 ACC: 0.9267844794713428  AUC: 0.9449800316967851 MCC: 0.24035531619266529\n",
      "Train Epoch: 289, Ave Loss: 0.28517119461274376 ACC: 0.9001332585485549  AUC: nan MCC: 0.22056370309413273\n",
      "Train Epoch: 289, Ave Loss: 0.2299149718720157 ACC: 0.9267844794713427  AUC: 0.9437843828674802 MCC: 0.24035531619266529\n",
      "Train Epoch: 290, Ave Loss: 0.2848021760301653 ACC: 0.8997403230863206  AUC: nan MCC: 0.22179644637564513\n",
      "Train Epoch: 290, Ave Loss: 0.2299157978048437 ACC: 0.9267844794713428  AUC: 0.9443298202345902 MCC: 0.24035531619266534\n",
      "Train Epoch: 291, Ave Loss: 0.2837342897825631 ACC: 0.9015384281012504  AUC: nan MCC: 0.22402471890002051\n",
      "Train Epoch: 291, Ave Loss: 0.22991655087873442 ACC: 0.9267844794713427  AUC: 0.9439123319481411 MCC: 0.2403553161926653\n",
      "Train Epoch: 292, Ave Loss: 0.28524465196953613 ACC: 0.8981511063207662  AUC: nan MCC: 0.21757293110923573\n",
      "Train Epoch: 292, Ave Loss: 0.22991725302162863 ACC: 0.9267844794713429  AUC: 0.9445288075084135 MCC: 0.2403553161926653\n",
      "Train Epoch: 293, Ave Loss: 0.28439690467915446 ACC: 0.90001713830141  AUC: nan MCC: 0.2206682158333794\n",
      "Train Epoch: 293, Ave Loss: 0.22991789434602147 ACC: 0.9267844794713428  AUC: 0.9451610396273704 MCC: 0.2403553161926653\n",
      "Train Epoch: 294, Ave Loss: 0.2844716935459184 ACC: 0.9001299944334982  AUC: nan MCC: 0.2228339756171446\n",
      "Train Epoch: 294, Ave Loss: 0.22991843975659787 ACC: 0.9267844794713429  AUC: 0.944301135178416 MCC: 0.24035531619266529\n",
      "Train Epoch: 295, Ave Loss: 0.28578054954802556 ACC: 0.899391111963096  AUC: nan MCC: 0.21987811369059077\n",
      "Train Epoch: 295, Ave Loss: 0.22991899091005083 ACC: 0.9267844794713428  AUC: 0.9450201099583108 MCC: 0.24035531619266534\n",
      "Train Epoch: 296, Ave Loss: 0.2843739449835199 ACC: 0.8986922403685128  AUC: nan MCC: 0.21719531226932443\n",
      "Train Epoch: 296, Ave Loss: 0.22991948082877095 ACC: 0.9267844794713428  AUC: 0.946350665277171 MCC: 0.2403553161926653\n",
      "Train Epoch: 297, Ave Loss: 0.2841270475345841 ACC: 0.9001344523574548  AUC: nan MCC: 0.22141885187722504\n",
      "Train Epoch: 297, Ave Loss: 0.22991991701012376 ACC: 0.9267844794713428  AUC: 0.9453427333468817 MCC: 0.2403553161926653\n",
      "Train Epoch: 298, Ave Loss: 0.2857292171848803 ACC: 0.8994860441486373  AUC: nan MCC: 0.2203618156933984\n",
      "Train Epoch: 298, Ave Loss: 0.2299203111281995 ACC: 0.9267844794713427  AUC: 0.9448880930348796 MCC: 0.24035531619266534\n",
      "Train Epoch: 299, Ave Loss: 0.2856951233967059 ACC: 0.8998775077597571  AUC: nan MCC: 0.22364243789226299\n",
      "Train Epoch: 299, Ave Loss: 0.22992066115569915 ACC: 0.9267844794713428  AUC: 0.9452058780655769 MCC: 0.24035531619266529\n",
      "Train Epoch: 300, Ave Loss: 0.28395708885403237 ACC: 0.8986697513401257  AUC: nan MCC: 0.22115540992489327\n",
      "Train Epoch: 300, Ave Loss: 0.2299209822242092 ACC: 0.9267844794713428  AUC: 0.9447586431801535 MCC: 0.2403553161926653\n",
      "Train Epoch: 301, Ave Loss: 0.2847915218547864 ACC: 0.899567761878809  AUC: nan MCC: 0.2215176613966169\n",
      "Train Epoch: 301, Ave Loss: 0.22992127376109783 ACC: 0.9267844794713428  AUC: 0.9437257619457055 MCC: 0.2403553161926653\n",
      "Train Epoch: 302, Ave Loss: 0.28518852281765217 ACC: 0.8987523301481024  AUC: nan MCC: 0.21861800252019908\n",
      "Train Epoch: 302, Ave Loss: 0.22992154491951403 ACC: 0.9267844794713427  AUC: 0.9453815434951159 MCC: 0.24035531619266529\n",
      "Train Epoch: 303, Ave Loss: 0.28577910758150654 ACC: 0.8984027845442363  AUC: nan MCC: 0.2175498488226383\n",
      "Train Epoch: 303, Ave Loss: 0.22992179475755614 ACC: 0.9267844794713428  AUC: 0.9450899101630449 MCC: 0.2403553161926653\n",
      "Train Epoch: 304, Ave Loss: 0.28538252451040885 ACC: 0.8979164633334341  AUC: nan MCC: 0.21647132002786185\n",
      "Train Epoch: 304, Ave Loss: 0.22992201829512898 ACC: 0.9267844794713428  AUC: 0.9453347311611076 MCC: 0.24035531619266534\n",
      "Train Epoch: 305, Ave Loss: 0.2855174452830623 ACC: 0.9000613368763242  AUC: nan MCC: 0.22001828275906068\n",
      "Train Epoch: 305, Ave Loss: 0.22992221477829175 ACC: 0.9267844794713428  AUC: 0.9454665331759159 MCC: 0.24035531619266537\n",
      "Train Epoch: 306, Ave Loss: 0.2853332042852802 ACC: 0.899049095631004  AUC: nan MCC: 0.22397810477575694\n",
      "Train Epoch: 306, Ave Loss: 0.22992239729040753 ACC: 0.9267844794713428  AUC: 0.9456865126379317 MCC: 0.24035531619266534\n",
      "Train Epoch: 307, Ave Loss: 0.2873266081054531 ACC: 0.8987890160225623  AUC: nan MCC: 0.21869485627231827\n",
      "Train Epoch: 307, Ave Loss: 0.22992255976898768 ACC: 0.9267844794713428  AUC: 0.944837940337686 MCC: 0.2403553161926653\n",
      "Train Epoch: 308, Ave Loss: 0.2861994625725744 ACC: 0.8985817060907394  AUC: nan MCC: 0.21889465520447166\n",
      "Train Epoch: 308, Ave Loss: 0.22992271484869697 ACC: 0.9267844794713428  AUC: 0.946120245039632 MCC: 0.2403553161926653\n",
      "Train Epoch: 309, Ave Loss: 0.2860914171193728 ACC: 0.8971521517455543  AUC: nan MCC: 0.21723989067349211\n",
      "Train Epoch: 309, Ave Loss: 0.22992284387116432 ACC: 0.9267844794713428  AUC: 0.9454960567074508 MCC: 0.24035531619266534\n",
      "Train Epoch: 310, Ave Loss: 0.2851927193638178 ACC: 0.8995620402327569  AUC: nan MCC: 0.2195496017010449\n",
      "Train Epoch: 310, Ave Loss: 0.229922971559575 ACC: 0.9267844794713427  AUC: 0.9459102032858544 MCC: 0.24035531619266529\n",
      "Train Epoch: 311, Ave Loss: 0.2844917509390256 ACC: 0.8999709436005522  AUC: nan MCC: 0.21934990862545212\n",
      "Train Epoch: 311, Ave Loss: 0.22992307402484835 ACC: 0.9267844794713428  AUC: 0.9458964518237223 MCC: 0.2403553161926653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2412/1730160679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2412/4228087785.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmax_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_tr_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_val_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tr_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2412/3253167080.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, training_set, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_mol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2412/547834143.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mol)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;34m\"\"\"\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    sf = nn.Softmax(dim=1)\n",
    "    all_acc = []\n",
    "    all_auc = []\n",
    "    all_mcc = []\n",
    "    all_recall = []\n",
    "    all_precision = []\n",
    "    all_jaccard = []\n",
    "    subgraph_num = 0\n",
    "    with torch.no_grad():\n",
    "        for mol in test_set:\n",
    "            sub_acc = []\n",
    "            sub_auc = []\n",
    "            sub_mcc = []\n",
    "            sub_recall = []\n",
    "            sub_precision = []\n",
    "            sub_jaccard = []\n",
    "            for sub_mol, target in mol:\n",
    "                subgraph_num += 1\n",
    "                sub_mol = from_networkx(sub_mol)\n",
    "                sub_mol = sub_mol.to(device)\n",
    "                sub_mol.x = sub_mol.x.to(torch.float32)\n",
    "                target = torch.tensor(target, dtype=torch.int64).to(device)\n",
    "                output= model(sub_mol)\n",
    "            # squeeze\n",
    "            # output = torch.squeeze(output)\n",
    "            # tracking\n",
    "            sub_acc.append(accuracy_score(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "            try:\n",
    "                # 验证集会出现全是0，这样子算不了auc，所以这种情况，直接跳过\n",
    "                sub_auc.append(roc_auc_score(target.cpu().detach().numpy(), sf(output)[:, 1].cpu().detach().numpy()))\n",
    "            except ValueError:\n",
    "                pass\n",
    "            sub_mcc.append(matthews_corrcoef(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "            sub_precision.append(precision_score(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "            sub_recall.append(recall_score(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "            sub_jaccard.append(jaccard_score(target.cpu().detach().numpy(), np.argmax(output.cpu().detach().numpy(), axis=1)))\n",
    "\n",
    "            print(f'sub graph average metrics: ACC : {np.mean(sub_acc)} AUC : {np.mean(sub_auc)}\\\n",
    "                    MCC : {np.mean(sub_mcc)} Recall : {np.mean(sub_recall)}\\\n",
    "                    Precision : {np.mean(sub_precision)} Jaccard : {np.mean(sub_jaccard)}')\n",
    "        all_acc.append(np.mean(sub_acc))\n",
    "        all_auc.append(np.mean(sub_auc))\n",
    "        all_mcc.append(np.mean(sub_mcc))\n",
    "        all_recall.append(np.mean(sub_recall))\n",
    "        all_precision.append(np.mean(sub_precision))\n",
    "        all_jaccard.append(np.mean(sub_jaccard))\n",
    "\n",
    "    # all_pred = np.concatenate(all_pred).ravel()\n",
    "    # all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    # all_labels = np.concatenate(all_labels).ravel()\n",
    "    # mcc, selectivity, recall, g_mean, balancedAcc = metrics(all_pred, all_labels)\n",
    "    print(f'ACC: {np.mean(all_acc)} AUC: {np.mean(all_auc)}\\\n",
    "        MCC: {np.mean(all_mcc)}  recall {np.mean(all_recall)} \\\n",
    "        precision score {np.mean(all_precision)} jaccard score {np.mean(all_jaccard)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(args).to(\"cuda\")\n",
    "model.load_state_dict(torch.load(args['save_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6 AUC : 0.8333333333333334                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 0.6666666666666667                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.2 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.3333333333333333 AUC : 0.0                    MCC : -0.5 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 0.6666666666666666                    MCC : 0.4472135954999579 Recall : 0.3333333333333333                    Precision : 1.0 Jaccard : 0.3333333333333333\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 0.6666666666666667                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8333333333333334 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.5 AUC : 0.5                    MCC : 0.0 Recall : 0.5                    Precision : 0.5 Jaccard : 0.3333333333333333\n",
      "sub graph average metrics: ACC : 0.4 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.2 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.4 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.8571428571428571 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8333333333333334 AUC : 1.0                    MCC : 0.6324555320336759 Recall : 0.5                    Precision : 1.0 Jaccard : 0.5\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.4 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 0.75                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 0.75                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.5 AUC : 0.33333333333333337                    MCC : -0.3333333333333333 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8333333333333334 AUC : 0.625                    MCC : 0.6324555320336759 Recall : 0.5                    Precision : 1.0 Jaccard : 0.5\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.8333333333333334 AUC : 0.6                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.6 AUC : 0.5                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.2 AUC : nan                    MCC : 0.0 Recall : 0.2                    Precision : 1.0 Jaccard : 0.2\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : 1.0                    MCC : 1.0 Recall : 1.0                    Precision : 1.0 Jaccard : 1.0\n",
      "sub graph average metrics: ACC : 0.6666666666666666 AUC : 1.0                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 0.75 AUC : 0.6666666666666667                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "sub graph average metrics: ACC : 1.0 AUC : nan                    MCC : 0.0 Recall : 0.0                    Precision : 0.0 Jaccard : 0.0\n",
      "ACC: 1.0 AUC: nan        MCC: 0.0  recall 0.0         precision score 0.0 jaccard score 0.0\n"
     ]
    }
   ],
   "source": [
    "test(model, \"cuda\", _test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae2bdcb5ffd42edc58b1d6fb8428ae1d2700e79a4fc0c0139ea5d98047639f54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
