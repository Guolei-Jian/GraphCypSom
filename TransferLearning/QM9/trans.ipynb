{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from rdkit.Chem.rdchem import HybridizationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QM9GraphDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root, filename, test=False,transform=None, pre_transform=None, pre_filter=None):\n",
    "        self.filename = filename\n",
    "        self.test = test\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filename\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        self.mols = Chem.SDMolSupplier(self.raw_paths[0])\n",
    "        if self.test:\n",
    "            return [f'data_test_{i}' for i in range(len(self.mols))]\n",
    "        else:\n",
    "            return [f'data_{i}.pt' for i in range(len(self.mols))]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.mols = Chem.SDMolSupplier(self.raw_paths[0])\n",
    "        for idx, mol in enumerate(self.mols):\n",
    "            # Get node features\n",
    "            node_feats = self._get_node_features(mol)\n",
    "            # Get edge features\n",
    "            edge_feats = self._get_edge_features(mol)\n",
    "            # Get adjacency info\n",
    "            edge_index = self._get_adjacency_info(mol)\n",
    "            # Get labels info\n",
    "            label = self._get_labels(mol)\n",
    "            # create data object\n",
    "            data = Data(x=node_feats, \n",
    "                        edge_index=edge_index,\n",
    "                        edge_attr=edge_feats,\n",
    "                        y=label,\n",
    "                        )\n",
    "            if self.test:\n",
    "                torch.save(data, os.path.join(self.processed_dir, \\\n",
    "                f'data_test_{idx}.pt'))\n",
    "            else:\n",
    "                torch.save(data, os.path.join(self.processed_dir, \\\n",
    "                f'data_{idx}.pt'))\n",
    "        \n",
    "    def _get_node_features(self, mol):\n",
    "        all_node_feats = []\n",
    "        # 我们包含更多类型，需要改这里，只留下H C N O， F 改为other\n",
    "        types = {'H': [1,0,0,0,0], 'C': [0,1,0,0,0], 'N': [0,0,1,0,0], 'O': [0,0,0,1,0]}\n",
    "        for atom in mol.GetAtoms():\n",
    "            node_feats = []\n",
    "            node_feats.extend(types.get(atom.GetSymbol(), [0,0,0,0,1]))\n",
    "            node_feats.append(atom.GetAtomicNum())\n",
    "            node_feats.append(atom.GetIsAromatic())\n",
    "            sp = []\n",
    "            sp2 = []\n",
    "            sp3 = []\n",
    "            hybridization = atom.GetHybridization()\n",
    "            sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
    "            sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
    "            sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
    "            node_feats.extend(sp)\n",
    "            node_feats.extend(sp2)\n",
    "            node_feats.extend(sp3)\n",
    "            node_feats.append(atom.GetTotalNumHs())\n",
    "            # Append node features to matrix\n",
    "            all_node_feats.append(node_feats)\n",
    "\n",
    "        all_node_feats = np.asarray(all_node_feats)\n",
    "        return torch.tensor(all_node_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_edge_features(self, mol):\n",
    "        \"\"\" \n",
    "        This will return a matrix / 2d array of the shape\n",
    "        [Number of edges, Edge Feature size]\n",
    "        \"\"\"\n",
    "        all_edge_feats = []\n",
    "\n",
    "        for bond in mol.GetBonds():\n",
    "            edge_feats = []\n",
    "            # Feature 1: Bond type (as double)\n",
    "            edge_feats.append(bond.GetBondTypeAsDouble())\n",
    "            # Feature 2: Rings\n",
    "            edge_feats.append(bond.IsInRing())\n",
    "            # Append node features to matrix (twice, per direction)\n",
    "            all_edge_feats += [edge_feats, edge_feats]\n",
    "\n",
    "        all_edge_feats = np.asarray(all_edge_feats)\n",
    "        return torch.tensor(all_edge_feats, dtype=torch.float)\n",
    "\n",
    "    def _get_adjacency_info(self, mol):\n",
    "        \"\"\"\n",
    "        We could also use rdmolops.GetAdjacencyMatrix(mol)\n",
    "        but we want to be sure that the order of the indices\n",
    "        matches the order of the edge features\n",
    "        \"\"\"\n",
    "        edge_indices = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "            edge_indices += [[i, j], [j, i]]\n",
    "\n",
    "        edge_indices = torch.tensor(edge_indices)\n",
    "        edge_indices = edge_indices.t().to(torch.long).view(2, -1)\n",
    "        return edge_indices\n",
    "\n",
    "    def _get_labels(self, mol):\n",
    "        _y = []\n",
    "        som = ['PRIMARY_SOM_1A2', 'PRIMARY_SOM_2A6','PRIMARY_SOM_2B6','PRIMARY_SOM_2C8','PRIMARY_SOM_2C9','PRIMARY_SOM_2C19','PRIMARY_SOM_2D6','PRIMARY_SOM_2E1','PRIMARY_SOM_3A4',\n",
    "            'SECONDARY_SOM_1A2', 'SECONDARY_SOM_2A6','SECONDARY_SOM_2B6','SECONDARY_SOM_2C8','SECONDARY_SOM_2C9','SECONDARY_SOM_2C19','SECONDARY_SOM_2D6','SECONDARY_SOM_2E1','SECONDARY_SOM_3A4',\n",
    "            'TERTIARY_SOM_1A2', 'TERTIARY_SOM_2A6','TERTIARY_SOM_2B6','TERTIARY_SOM_2C8','TERTIARY_SOM_2C9','TERTIARY_SOM_2C19','TERTIARY_SOM_2D6','TERTIARY_SOM_2E1','TERTIARY_SOM_3A4'\n",
    "            ]\n",
    "        result = []\n",
    "        for k in som:\n",
    "            try:\n",
    "                _res = mol.GetProp(k)\n",
    "                if ' ' in _res:\n",
    "                    res = _res.split(' ')\n",
    "                    for s in res:\n",
    "                        result.append(int(s))\n",
    "                else:\n",
    "                    result.append(int(_res))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        for data in result:\n",
    "            _y.append(data)\n",
    "        _y = list(set(_y))\n",
    "\n",
    "        y = np.zeros(len(mol.GetAtoms()))\n",
    "        for i in _y:\n",
    "            y[i-1] = 1\n",
    "        # int64 or float32? past is float32\n",
    "        return torch.tensor(y, dtype=torch.int64)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.mols)\n",
    "\n",
    "    def get(self, idx):\n",
    "        if self.test:\n",
    "            data = torch.load(os.path.join(self.processed_dir, f'data_test_{idx}.pt'))\n",
    "        else:\n",
    "            data = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = QM9GraphDataset('../../Dataset/qm9featuredataset/', 'train.sdf')\n",
    "test_set = QM9GraphDataset('../../Dataset/qm9featuredataset/', 'test.sdf', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[35, 11], edge_index=[2, 74], edge_attr=[74, 2], y=[35])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "def seed_torch(seed=42):\n",
    "\trandom.seed(seed)\n",
    "\tos.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "\tnp.random.seed(seed)\n",
    "\ttorch.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed(seed)\n",
    "\ttorch.cuda.manual_seed_all(seed) # if you are using multi-GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, f1_score, recall_score,jaccard_score\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv, global_mean_pool\n",
    "from torch.utils.data import random_split\n",
    "import pickle\n",
    "from torch_geometric.utils import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Model, self).__init__()\n",
    "        num_classses = 1\n",
    "\n",
    "        conv_hidden = args['conv_hidden']\n",
    "        cls_hidden = args['cls_hidden']\n",
    "        self.n_layers = args['n_layers']\n",
    "\n",
    "        self.conv_layers = nn.ModuleList([])\n",
    "\n",
    "        self.conv1 = SAGEConv(11, conv_hidden)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            self.conv_layers.append(\n",
    "                SAGEConv(conv_hidden, conv_hidden)\n",
    "            )\n",
    "\n",
    "        self.linear1 = nn.Linear(conv_hidden, cls_hidden)\n",
    "        self.linear2 = nn.Linear(cls_hidden, num_classses)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, mol):\n",
    "\n",
    "        res = self.conv1(mol.x, mol.edge_index)\n",
    "        res = self.relu(res)\n",
    "        for i in range(self.n_layers):\n",
    "            res = self.relu(self.conv_layers[i](res, mol.edge_index))\n",
    "\n",
    "        # res = global_mean_pool(res, mol.batch)\n",
    "        res = self.linear1(res)\n",
    "        res = self.relu(res)\n",
    "        res = self.drop1(res)\n",
    "        res = self.linear2(res)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgl/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "training_set, validation_set  = random_split(train_dataset, [int(len(train_dataset) * 0.8), len(train_dataset) - int(len(train_dataset) * 0.8)], generator=torch.Generator().manual_seed(42))\n",
    "batch_size = 1\n",
    "tune_train_loader = DataLoader(training_set, batch_size, shuffle=True)\n",
    "tune_val_loader = DataLoader(validation_set, batch_size, shuffle=True)\n",
    "tune_test_loader = DataLoader(test_set, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def top2(output, label):\n",
    "    preds = torch.nn.functional.softmax(output)\n",
    "    # print('top2 after softmax preds', preds)\n",
    "    preds = preds[:, 1]\n",
    "    # print('get single col', preds)\n",
    "    _, indices = torch.topk(preds, 2)\n",
    "    # print('indices', indices)\n",
    "    pos_index = []\n",
    "    for i in range(label.shape[0]):\n",
    "        if label[i] == 1:\n",
    "            pos_index.append(i)\n",
    "    # print(pos_index)      \n",
    "    for li in pos_index:\n",
    "        if li in indices:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def MCC(output, label):\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    # print(f\"TN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    return up / down\n",
    "\n",
    "def metrics(output, label):\n",
    "    tn,fp,fn,tp=confusion_matrix(label, output).ravel()\n",
    "    up = (tp * tn) - (fp * fn)\n",
    "    down = ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)) ** 0.5\n",
    "    mcc = up / down\n",
    "    selectivity = tn / (tn + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    g_mean = (selectivity * recall) ** 0.5\n",
    "    balancedAccuracy = (recall + selectivity) / 2\n",
    "    return mcc, selectivity, recall, g_mean, balancedAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, training_set, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    for mol in training_set:\n",
    "        mol = mol.to(device)\n",
    "        mol.edge_attr = mol.edge_attr.to(torch.float32)\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        \n",
    "        target = mol.y\n",
    "        optimizer.zero_grad()\n",
    "        output= model(mol)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "        all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "        all_pred_raw.append(torch.nn.functional.softmax(output)[:, 1].cpu().detach().numpy())\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "\n",
    "    mcc = MCC(all_pred, all_labels)\n",
    "    # tr_writer.add_scalar('Ave Loss', total_loss / len(training_set), epoch)\n",
    "    # tr_writer.add_scalar('ACC', accuracy_score(all_labels, all_pred), epoch)\n",
    "    # tr_writer.add_scalar('Top2', top2n / len(training_set), epoch)\n",
    "    # tr_writer.add_scalar('AUC', roc_auc_score(all_labels, all_pred_raw), epoch)\n",
    "    # tr_writer.add_scalar('MCC', mcc, epoch)\n",
    "    print(f'Train Epoch: {epoch}, Ave Loss: {total_loss / len(training_set)} ACC: {accuracy_score(all_labels, all_pred)} Top2: {top2n / len(training_set)} AUC: {roc_auc_score(all_labels, all_pred_raw)} MCC: {mcc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(args, model, device, val_set, optimizer, criterion, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    for mol in val_set:\n",
    "        mol = mol.to(device)\n",
    "        mol.edge_attr = mol.edge_attr.to(torch.float32)\n",
    "        mol.x = mol.x.to(torch.float32)\n",
    "        target = mol.y\n",
    "        optimizer.zero_grad()\n",
    "        output = model(mol)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # tracking\n",
    "        top2n += top2(output, target)\n",
    "        all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "        all_pred_raw.append(torch.nn.functional.softmax(output)[:, 1].cpu().detach().numpy())\n",
    "        all_labels.append(target.cpu().detach().numpy())\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc = MCC(all_pred, all_labels)\n",
    "    # val_writer.add_scalar('Ave Loss', total_loss / len(val_set), epoch)\n",
    "    # val_writer.add_scalar('ACC', accuracy_score(all_labels, all_pred), epoch)\n",
    "    # val_writer.add_scalar('Top2', top2n / len(val_set), epoch)\n",
    "    # val_writer.add_scalar('AUC', roc_auc_score(all_labels, all_pred_raw), epoch)\n",
    "    # val_writer.add_scalar('MCC', mcc, epoch)\n",
    "    print(f'Val Epoch: {epoch}, Ave Loss: {total_loss / len(val_set)} ACC: {accuracy_score(all_labels, all_pred)} Top2: {top2n / len(val_set)} AUC: {roc_auc_score(all_labels, all_pred_raw)} MCC: {mcc}')\n",
    "    return top2n / len(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_set):\n",
    "    model.eval()\n",
    "    all_pred = []\n",
    "    all_pred_raw = []\n",
    "    all_labels = []\n",
    "    top2n = 0\n",
    "    with torch.no_grad():\n",
    "        for mol in test_set:\n",
    "            mol = mol.to(device)\n",
    "            mol.x = mol.x.to(torch.float32)\n",
    "            mol.edge_attr = mol.edge_attr.to(torch.float32)\n",
    "            target = mol.y\n",
    "            output = model(mol)\n",
    "            # squeeze\n",
    "            output = torch.squeeze(output)\n",
    "            print(f'outpu is  {output}')\n",
    "            # tracking\n",
    "            top2n += top2(output, target)\n",
    "            all_pred.append(np.argmax(output.cpu().detach().numpy(), axis=1))\n",
    "            all_pred_raw.append(torch.nn.functional.softmax(output)[:, 1].cpu().detach().numpy())\n",
    "            all_labels.append(target.cpu().detach().numpy())\n",
    "    all_pred = np.concatenate(all_pred).ravel()\n",
    "    all_pred_raw = np.concatenate(all_pred_raw).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    mcc, selectivity, recall, g_mean, balancedAcc = metrics(all_pred, all_labels)\n",
    "    print(all_pred)\n",
    "    print(all_pred_raw)\n",
    "    print(f'ACC: {accuracy_score(all_labels, all_pred)} \\\n",
    "        Top2: {top2n / len(test_set)} \\\n",
    "        AUC: {roc_auc_score(all_labels, all_pred_raw)}\\\n",
    "        MCC: {mcc} selectivity {selectivity} recall {recall} \\\n",
    "        g_mean {g_mean} balanced acc {balancedAcc} f1score {f1_score(all_labels, all_pred)} \\\n",
    "        precision score {precision_score(all_labels, all_pred)} jaccard score {jaccard_score(all_labels, all_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune(args):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seed_torch(args['seed'])\n",
    "    # 创建模型，加载预训练参数\n",
    "    tune_model = Model(args).to(device)\n",
    "    tune_model.load_state_dict(torch.load('./model/model'))\n",
    "\n",
    "    in_fea = tune_model.linear1.in_features\n",
    "    out_fea = tune_model.linear1.out_features\n",
    "    # 替换原来的卷积层，参数也变成新的，需要从新训练\n",
    "    tune_model.linear1 = nn.Linear(in_fea, out_fea, bias=True).to(device)\n",
    "    tune_model.linear2 = nn.Linear(out_fea, 2, bias=True).to(device)\n",
    "    # freeze model 只冻结了所有的卷积层\n",
    "    for name, para in tune_model.named_parameters():\n",
    "        if \"linear\" not in name:\n",
    "            para.requires_grad_(False)\n",
    "    print(tune_model)\n",
    "\n",
    "    weights = torch.tensor([1, 7], dtype=torch.float32).to(device)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "    optimizer = torch.optim.SGD(filter(lambda p:p.requires_grad, tune_model.parameters()), lr=args['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    max_top2 = 0\n",
    "    for epoch in range(1, args['epoch']):\n",
    "        train(args, tune_model, device, tune_train_loader, optimizer, loss_fn, epoch)\n",
    "        top2acc = val(args, tune_model, device, tune_val_loader, optimizer, loss_fn, epoch)\n",
    "        scheduler.step()\n",
    "        if top2acc > max_top2:\n",
    "            max_top2 = top2acc\n",
    "            print('Saving model (epoch = {:4d}, top2acc = {:.4f})'\n",
    "                .format(epoch, max_top2))\n",
    "            torch.save(tune_model.state_dict(), args['save_path'])\n",
    "    test(tune_model, \"cuda\", tune_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'lr': 0.0001,\n",
    "    'epoch': 200,\n",
    "    'seed': 42,\n",
    "    'save_path': './model/tune',\n",
    "    'conv_hidden':1024,\n",
    "    'cls_hidden':512,\n",
    "    'n_layers':3,\n",
    "    'batch_size':128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_model = Model(args).to('cuda')\n",
    "in_fea = tune_model.linear1.in_features\n",
    "out_fea = tune_model.linear1.out_features\n",
    "tune_model.linear1 = nn.Linear(in_fea, out_fea, bias=True).to('cuda')\n",
    "tune_model.linear2 = nn.Linear(out_fea, 2, bias=True).to('cuda')\n",
    "tune_model.load_state_dict(torch.load('./model/tune'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outpu is  tensor([[-1.5487e-02, -3.2846e-01],\n",
      "        [-1.6872e-02, -2.8103e-01],\n",
      "        [-1.6872e-02, -2.8103e-01],\n",
      "        [-4.9071e-02, -3.1584e-01],\n",
      "        [-1.3949e-02, -2.7962e-01],\n",
      "        [-1.3949e-02, -2.7962e-01],\n",
      "        [-1.3949e-02, -2.7962e-01],\n",
      "        [-1.3949e-02, -2.7962e-01],\n",
      "        [-5.1122e-05, -4.1075e-01],\n",
      "        [-5.1122e-05, -4.1075e-01],\n",
      "        [-5.1122e-05, -4.1075e-01],\n",
      "        [-1.0292e-02, -2.8427e-01],\n",
      "        [-1.0292e-02, -2.8427e-01],\n",
      "        [-1.0292e-02, -2.8427e-01],\n",
      "        [-1.0292e-02, -2.8427e-01],\n",
      "        [-1.5162e-02, -2.7124e-01],\n",
      "        [-1.5162e-02, -2.7124e-01],\n",
      "        [-9.6260e-03, -2.7527e-01],\n",
      "        [-9.6260e-03, -2.7527e-01],\n",
      "        [-2.5218e-02, -2.4701e-01],\n",
      "        [-2.5218e-02, -2.4701e-01]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0104, -0.3038],\n",
      "        [-0.0134, -0.2894],\n",
      "        [-0.0110, -0.2956],\n",
      "        [-0.0158, -0.2880],\n",
      "        [-0.0098, -0.2974],\n",
      "        [-0.0154, -0.2863],\n",
      "        [-0.0142, -0.3108],\n",
      "        [-0.0108, -0.3273],\n",
      "        [-0.0229, -0.2786],\n",
      "        [-0.0130, -0.2924],\n",
      "        [-0.0168, -0.2795],\n",
      "        [-0.0266, -0.2342],\n",
      "        [-0.0129, -0.2856],\n",
      "        [-0.0127, -0.2874],\n",
      "        [-0.0127, -0.2874],\n",
      "        [-0.0104, -0.2977],\n",
      "        [-0.0104, -0.2977],\n",
      "        [-0.0137, -0.2952],\n",
      "        [-0.0338, -0.2021],\n",
      "        [-0.0353, -0.1774],\n",
      "        [-0.0318, -0.1922],\n",
      "        [-0.0391, -0.1720],\n",
      "        [-0.0038, -0.3267]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0321, -0.2366],\n",
      "        [-0.0204, -0.2455],\n",
      "        [-0.0280, -0.2229],\n",
      "        [-0.0298, -0.2131],\n",
      "        [-0.0265, -0.2404],\n",
      "        [-0.0259, -0.2257],\n",
      "        [-0.0307, -0.2159],\n",
      "        [-0.0298, -0.2105],\n",
      "        [-0.0304, -0.2148],\n",
      "        [-0.0228, -0.2461],\n",
      "        [-0.0272, -0.2378],\n",
      "        [-0.0276, -0.2275],\n",
      "        [-0.0311, -0.2085],\n",
      "        [-0.0310, -0.2053],\n",
      "        [-0.0378, -0.1884],\n",
      "        [-0.0221, -0.2353],\n",
      "        [-0.0307, -0.2075],\n",
      "        [-0.0262, -0.2343],\n",
      "        [-0.0342, -0.2244],\n",
      "        [-0.0273, -0.2170],\n",
      "        [-0.0309, -0.2126],\n",
      "        [-0.0106, -0.2856],\n",
      "        [-0.0303, -0.2129],\n",
      "        [-0.0307, -0.2121],\n",
      "        [-0.0166, -0.2769],\n",
      "        [-0.0167, -0.2776],\n",
      "        [-0.0271, -0.2205],\n",
      "        [-0.0293, -0.2135]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0212, -0.2716],\n",
      "        [-0.0093, -0.2917],\n",
      "        [-0.0128, -0.2917],\n",
      "        [-0.0285, -0.2537],\n",
      "        [-0.0256, -0.2622],\n",
      "        [-0.0169, -0.2802],\n",
      "        [-0.0080, -0.2966],\n",
      "        [-0.0125, -0.2902],\n",
      "        [-0.0091, -0.2953],\n",
      "        [-0.0141, -0.2811],\n",
      "        [-0.0192, -0.2757],\n",
      "        [-0.0086, -0.2883],\n",
      "        [-0.0117, -0.2883],\n",
      "        [-0.0158, -0.2651],\n",
      "        [-0.0135, -0.2626],\n",
      "        [-0.0142, -0.2642],\n",
      "        [-0.0108, -0.2821]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0039, -0.3381],\n",
      "        [-0.0047, -0.3285],\n",
      "        [-0.0111, -0.3080],\n",
      "        [-0.0081, -0.3093],\n",
      "        [-0.0087, -0.3059],\n",
      "        [-0.0118, -0.2890],\n",
      "        [-0.0068, -0.3065],\n",
      "        [-0.0111, -0.2845],\n",
      "        [-0.0209, -0.2746],\n",
      "        [-0.0144, -0.2963],\n",
      "        [-0.0100, -0.2790],\n",
      "        [-0.0111, -0.2817],\n",
      "        [-0.0117, -0.2839],\n",
      "        [-0.0142, -0.2647],\n",
      "        [-0.0224, -0.2548],\n",
      "        [-0.0168, -0.2567],\n",
      "        [-0.0141, -0.2640],\n",
      "        [-0.0139, -0.2649],\n",
      "        [-0.0135, -0.2613]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0083, -0.3022],\n",
      "        [-0.0104, -0.2979],\n",
      "        [-0.0113, -0.2984],\n",
      "        [-0.0109, -0.2970],\n",
      "        [-0.0078, -0.3071],\n",
      "        [-0.0094, -0.2966],\n",
      "        [-0.0102, -0.3088],\n",
      "        [-0.0083, -0.2927],\n",
      "        [-0.0106, -0.2912],\n",
      "        [-0.0101, -0.2970],\n",
      "        [-0.0115, -0.2876],\n",
      "        [-0.0167, -0.2765],\n",
      "        [-0.0202, -0.2700],\n",
      "        [-0.0136, -0.2802],\n",
      "        [-0.0101, -0.2768],\n",
      "        [-0.0252, -0.2473]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0092, -0.2950],\n",
      "        [-0.0081, -0.3023],\n",
      "        [-0.0103, -0.2891],\n",
      "        [-0.0110, -0.2828],\n",
      "        [-0.0081, -0.3152],\n",
      "        [-0.0110, -0.2835],\n",
      "        [-0.0104, -0.2860],\n",
      "        [-0.0104, -0.2860],\n",
      "        [-0.0141, -0.2647],\n",
      "        [-0.0102, -0.3157],\n",
      "        [-0.0068, -0.3254],\n",
      "        [-0.0142, -0.2647],\n",
      "        [-0.0154, -0.2702],\n",
      "        [-0.0154, -0.2702],\n",
      "        [-0.0098, -0.3189],\n",
      "        [-0.0094, -0.3199],\n",
      "        [-0.0107, -0.2750],\n",
      "        [-0.0226, -0.2639],\n",
      "        [-0.0128, -0.2816],\n",
      "        [-0.0250, -0.2527],\n",
      "        [-0.0163, -0.2771],\n",
      "        [-0.0282, -0.2166],\n",
      "        [-0.0091, -0.3047],\n",
      "        [-0.0258, -0.2292],\n",
      "        [-0.0131, -0.2890],\n",
      "        [-0.0423, -0.1791],\n",
      "        [-0.0423, -0.1791],\n",
      "        [-0.0136, -0.2991],\n",
      "        [-0.0133, -0.2984],\n",
      "        [-0.0325, -0.1853],\n",
      "        [-0.0363, -0.1660],\n",
      "        [-0.0390, -0.1503]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0192, -0.2701],\n",
      "        [-0.0175, -0.2640],\n",
      "        [-0.0278, -0.2424],\n",
      "        [-0.0250, -0.2376],\n",
      "        [-0.0275, -0.2364],\n",
      "        [-0.0169, -0.2542],\n",
      "        [-0.0317, -0.2422],\n",
      "        [-0.0221, -0.2826],\n",
      "        [-0.0252, -0.2379],\n",
      "        [-0.0197, -0.2673],\n",
      "        [-0.0217, -0.2624],\n",
      "        [-0.0200, -0.2745],\n",
      "        [-0.0152, -0.2990],\n",
      "        [-0.0302, -0.2197],\n",
      "        [-0.0219, -0.2910],\n",
      "        [-0.0289, -0.2265],\n",
      "        [-0.0295, -0.2252],\n",
      "        [-0.0109, -0.2845],\n",
      "        [-0.0296, -0.2396],\n",
      "        [-0.0191, -0.2750],\n",
      "        [-0.0282, -0.2360],\n",
      "        [-0.0163, -0.2996],\n",
      "        [-0.0348, -0.2422]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0211, -0.2759],\n",
      "        [-0.0145, -0.2987],\n",
      "        [-0.0238, -0.2377],\n",
      "        [-0.0182, -0.2545],\n",
      "        [-0.0059, -0.3215],\n",
      "        [-0.0169, -0.2506],\n",
      "        [-0.0159, -0.2570],\n",
      "        [-0.0059, -0.3215],\n",
      "        [-0.0208, -0.2523],\n",
      "        [-0.0269, -0.2327],\n",
      "        [-0.0303, -0.2357],\n",
      "        [-0.0237, -0.2439],\n",
      "        [-0.0320, -0.2170],\n",
      "        [-0.0281, -0.2268],\n",
      "        [-0.0299, -0.2388],\n",
      "        [-0.0233, -0.2548],\n",
      "        [-0.0286, -0.2272],\n",
      "        [-0.0365, -0.2282],\n",
      "        [-0.0163, -0.2762],\n",
      "        [-0.0183, -0.2661],\n",
      "        [-0.0113, -0.2906],\n",
      "        [-0.0399, -0.1929],\n",
      "        [-0.0288, -0.2349],\n",
      "        [-0.0170, -0.2673],\n",
      "        [-0.0266, -0.2634],\n",
      "        [-0.0278, -0.2475],\n",
      "        [-0.0189, -0.2767],\n",
      "        [-0.0177, -0.2831],\n",
      "        [-0.0171, -0.2864],\n",
      "        [-0.0097, -0.3064],\n",
      "        [-0.0285, -0.2214],\n",
      "        [-0.0285, -0.2214],\n",
      "        [-0.0264, -0.2348],\n",
      "        [-0.0264, -0.2348],\n",
      "        [-0.0123, -0.2977],\n",
      "        [-0.0071, -0.3132],\n",
      "        [-0.0123, -0.2974],\n",
      "        [-0.0114, -0.3041],\n",
      "        [-0.0286, -0.2118],\n",
      "        [-0.0286, -0.2118],\n",
      "        [-0.0289, -0.2123],\n",
      "        [-0.0289, -0.2123],\n",
      "        [-0.0324, -0.1917],\n",
      "        [-0.0324, -0.1917],\n",
      "        [-0.0324, -0.1918],\n",
      "        [-0.0324, -0.1918]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0226, -0.2644],\n",
      "        [-0.0141, -0.2837],\n",
      "        [-0.0122, -0.2957],\n",
      "        [-0.0255, -0.2411],\n",
      "        [-0.0158, -0.2898],\n",
      "        [-0.0286, -0.2522],\n",
      "        [-0.0199, -0.2689],\n",
      "        [-0.0152, -0.2935],\n",
      "        [-0.0288, -0.2172],\n",
      "        [-0.0232, -0.2450],\n",
      "        [-0.0250, -0.2512],\n",
      "        [-0.0093, -0.3097],\n",
      "        [-0.0215, -0.2533],\n",
      "        [-0.0318, -0.2011],\n",
      "        [-0.0388, -0.1898],\n",
      "        [-0.0135, -0.2820],\n",
      "        [-0.0283, -0.2165],\n",
      "        [-0.0203, -0.2736],\n",
      "        [-0.0324, -0.2017],\n",
      "        [-0.0255, -0.2056],\n",
      "        [-0.0179, -0.2850],\n",
      "        [-0.0286, -0.2519],\n",
      "        [-0.0424, -0.1792],\n",
      "        [-0.0424, -0.1792],\n",
      "        [-0.0157, -0.2754],\n",
      "        [-0.0072, -0.3062],\n",
      "        [-0.0382, -0.1720],\n",
      "        [-0.0258, -0.2049],\n",
      "        [-0.0205, -0.2625],\n",
      "        [-0.0084, -0.3089],\n",
      "        [-0.0247, -0.2629],\n",
      "        [-0.0332, -0.2366],\n",
      "        [-0.0352, -0.1871],\n",
      "        [-0.0144, -0.2787],\n",
      "        [-0.0312, -0.2123],\n",
      "        [-0.0123, -0.2908],\n",
      "        [-0.0176, -0.2847],\n",
      "        [-0.0278, -0.2510],\n",
      "        [-0.0314, -0.1956],\n",
      "        [-0.0146, -0.2737],\n",
      "        [-0.0148, -0.2909],\n",
      "        [-0.0205, -0.2624],\n",
      "        [-0.0084, -0.3087],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0219, -0.2567],\n",
      "        [-0.0270, -0.2500],\n",
      "        [-0.0142, -0.2783],\n",
      "        [-0.0312, -0.2123],\n",
      "        [-0.0142, -0.2898],\n",
      "        [-0.0309, -0.2118],\n",
      "        [-0.0195, -0.2803],\n",
      "        [-0.0278, -0.2509],\n",
      "        [-0.0314, -0.1956],\n",
      "        [-0.0179, -0.2768],\n",
      "        [-0.0145, -0.2925],\n",
      "        [-0.0314, -0.1955],\n",
      "        [-0.0209, -0.2735],\n",
      "        [-0.0076, -0.3079],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0228, -0.2557],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0203, -0.2700],\n",
      "        [-0.0303, -0.2349],\n",
      "        [-0.0173, -0.2842],\n",
      "        [-0.0293, -0.2129],\n",
      "        [-0.0168, -0.2791],\n",
      "        [-0.0192, -0.2368],\n",
      "        [-0.0142, -0.2782],\n",
      "        [-0.0084, -0.3086],\n",
      "        [-0.0418, -0.1783],\n",
      "        [-0.0418, -0.1783],\n",
      "        [-0.0247, -0.2561],\n",
      "        [-0.0132, -0.2903],\n",
      "        [-0.0305, -0.2116],\n",
      "        [-0.0221, -0.2569],\n",
      "        [-0.0278, -0.2509],\n",
      "        [-0.0219, -0.2615],\n",
      "        [-0.0326, -0.2210],\n",
      "        [-0.0283, -0.2065],\n",
      "        [-0.0136, -0.2889],\n",
      "        [-0.0309, -0.2119],\n",
      "        [-0.0259, -0.2020],\n",
      "        [-0.0145, -0.2920],\n",
      "        [-0.0314, -0.1955],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0428, -0.1636]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0252, -0.3003],\n",
      "        [-0.0095, -0.3127],\n",
      "        [-0.0163, -0.2771],\n",
      "        [-0.0130, -0.2857],\n",
      "        [-0.0119, -0.3084],\n",
      "        [-0.0039, -0.3391],\n",
      "        [-0.0211, -0.3864],\n",
      "        [-0.0057, -0.3463],\n",
      "        [-0.0268, -0.3088],\n",
      "        [-0.0028, -0.3434],\n",
      "        [-0.0159, -0.3156],\n",
      "        [-0.0202, -0.2912],\n",
      "        [-0.0158, -0.2928],\n",
      "        [-0.0229, -0.2668],\n",
      "        [-0.0233, -0.2662],\n",
      "        [-0.0121, -0.3198],\n",
      "        [-0.0118, -0.3295]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0102, -0.3037],\n",
      "        [-0.0085, -0.3117],\n",
      "        [-0.0120, -0.2867],\n",
      "        [-0.0066, -0.3189],\n",
      "        [-0.0057, -0.3175],\n",
      "        [-0.0079, -0.3067],\n",
      "        [-0.0138, -0.2905],\n",
      "        [-0.0247, -0.2475],\n",
      "        [-0.0088, -0.3050],\n",
      "        [-0.0111, -0.3029],\n",
      "        [-0.0142, -0.2995],\n",
      "        [-0.0351, -0.2217],\n",
      "        [-0.0272, -0.2741],\n",
      "        [-0.0415, -0.2681],\n",
      "        [-0.0180, -0.3848],\n",
      "        [-0.0374, -0.2963],\n",
      "        [-0.0403, -0.2821],\n",
      "        [-0.0465, -0.3276],\n",
      "        [-0.0173, -0.2925],\n",
      "        [-0.0240, -0.2754],\n",
      "        [-0.0348, -0.2431],\n",
      "        [-0.0162, -0.2784],\n",
      "        [-0.0159, -0.2673],\n",
      "        [-0.0156, -0.2735],\n",
      "        [-0.0098, -0.3098],\n",
      "        [-0.0271, -0.2955],\n",
      "        [-0.0051, -0.3255],\n",
      "        [-0.0167, -0.3831]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0074, -0.3024],\n",
      "        [-0.0109, -0.2843],\n",
      "        [-0.0140, -0.2644],\n",
      "        [-0.0138, -0.2633],\n",
      "        [-0.0120, -0.2741],\n",
      "        [-0.0098, -0.2892],\n",
      "        [-0.0111, -0.2887],\n",
      "        [-0.0100, -0.3002],\n",
      "        [-0.0059, -0.3170],\n",
      "        [-0.0047, -0.3220],\n",
      "        [-0.0057, -0.3190]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0053, -0.3192],\n",
      "        [-0.0081, -0.3069],\n",
      "        [-0.0139, -0.2809],\n",
      "        [-0.0101, -0.2769],\n",
      "        [-0.0252, -0.2473],\n",
      "        [-0.0114, -0.2878],\n",
      "        [-0.0098, -0.2979],\n",
      "        [-0.0121, -0.3047],\n",
      "        [-0.0045, -0.3351],\n",
      "        [-0.0324, -0.3183],\n",
      "        [-0.0066, -0.3681],\n",
      "        [-0.0066, -0.3681],\n",
      "        [-0.0066, -0.3681],\n",
      "        [-0.0113, -0.3194],\n",
      "        [-0.0046, -0.3274],\n",
      "        [-0.0056, -0.3246],\n",
      "        [-0.0070, -0.3226]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0111, -0.2877],\n",
      "        [-0.0165, -0.2815],\n",
      "        [-0.0110, -0.2837],\n",
      "        [-0.0110, -0.2837],\n",
      "        [-0.0260, -0.2461],\n",
      "        [-0.0076, -0.3087],\n",
      "        [-0.0167, -0.2621],\n",
      "        [-0.0167, -0.2621],\n",
      "        [-0.0331, -0.2160],\n",
      "        [-0.0377, -0.2064],\n",
      "        [-0.0129, -0.2641],\n",
      "        [-0.0236, -0.2247],\n",
      "        [-0.0247, -0.2381],\n",
      "        [-0.0323, -0.1976],\n",
      "        [-0.0323, -0.1976],\n",
      "        [-0.0334, -0.1889],\n",
      "        [-0.0334, -0.1889],\n",
      "        [-0.0344, -0.1723]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0149, -0.2760],\n",
      "        [-0.0124, -0.2744],\n",
      "        [-0.0152, -0.2679],\n",
      "        [-0.0079, -0.2935],\n",
      "        [-0.0141, -0.2883],\n",
      "        [-0.0095, -0.2987],\n",
      "        [-0.0110, -0.2895],\n",
      "        [-0.0138, -0.2730],\n",
      "        [-0.0133, -0.2619],\n",
      "        [-0.0152, -0.2510],\n",
      "        [-0.0133, -0.2619],\n",
      "        [-0.0138, -0.2730],\n",
      "        [-0.0139, -0.3026],\n",
      "        [-0.0143, -0.3095],\n",
      "        [-0.0112, -0.3160],\n",
      "        [-0.0147, -0.3095],\n",
      "        [-0.0102, -0.3202],\n",
      "        [-0.0122, -0.3167],\n",
      "        [-0.0145, -0.3022],\n",
      "        [-0.0141, -0.2835]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0221, -0.2543],\n",
      "        [-0.0145, -0.2798],\n",
      "        [-0.0234, -0.2424],\n",
      "        [-0.0285, -0.2296],\n",
      "        [-0.0139, -0.2735],\n",
      "        [-0.0090, -0.3020],\n",
      "        [-0.0302, -0.2210],\n",
      "        [-0.0279, -0.2303],\n",
      "        [-0.0281, -0.2175],\n",
      "        [-0.0107, -0.2935],\n",
      "        [-0.0253, -0.2467],\n",
      "        [-0.0125, -0.2917],\n",
      "        [-0.0280, -0.2095],\n",
      "        [-0.0301, -0.2208],\n",
      "        [-0.0123, -0.2909],\n",
      "        [-0.0102, -0.2838],\n",
      "        [-0.0343, -0.1846],\n",
      "        [-0.0221, -0.2472],\n",
      "        [-0.0102, -0.2836],\n",
      "        [-0.0261, -0.2497],\n",
      "        [-0.0368, -0.1686],\n",
      "        [-0.0157, -0.2736],\n",
      "        [-0.0293, -0.2207],\n",
      "        [-0.0261, -0.2497],\n",
      "        [-0.0132, -0.2720],\n",
      "        [-0.0086, -0.3013],\n",
      "        [-0.0295, -0.2183],\n",
      "        [-0.0107, -0.2933],\n",
      "        [-0.0261, -0.2361],\n",
      "        [-0.0125, -0.2916],\n",
      "        [-0.0123, -0.2909],\n",
      "        [-0.0102, -0.2838],\n",
      "        [-0.0102, -0.2836],\n",
      "        [-0.0261, -0.2497],\n",
      "        [-0.0261, -0.2497]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0330, -0.1881],\n",
      "        [-0.0295, -0.2128],\n",
      "        [-0.0147, -0.2559],\n",
      "        [-0.0128, -0.2790],\n",
      "        [-0.0124, -0.2841],\n",
      "        [-0.0138, -0.2675],\n",
      "        [-0.0131, -0.2734],\n",
      "        [-0.0140, -0.2667],\n",
      "        [-0.0237, -0.2460],\n",
      "        [-0.0224, -0.2459],\n",
      "        [-0.0144, -0.2612],\n",
      "        [-0.0126, -0.2778],\n",
      "        [-0.0104, -0.2836],\n",
      "        [-0.0148, -0.2694],\n",
      "        [-0.0156, -0.2652],\n",
      "        [-0.0148, -0.2694],\n",
      "        [-0.0104, -0.2836],\n",
      "        [-0.0181, -0.2870],\n",
      "        [-0.0340, -0.2753],\n",
      "        [-0.0113, -0.3273],\n",
      "        [-0.0213, -0.2941],\n",
      "        [-0.0095, -0.3390],\n",
      "        [-0.0290, -0.3028],\n",
      "        [-0.0055, -0.3646],\n",
      "        [-0.0228, -0.3651]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0090, -0.3030],\n",
      "        [-0.0123, -0.2855],\n",
      "        [-0.0092, -0.2997],\n",
      "        [-0.0078, -0.3044],\n",
      "        [-0.0224, -0.2629],\n",
      "        [-0.0135, -0.2866],\n",
      "        [-0.0099, -0.2965],\n",
      "        [-0.0112, -0.2949],\n",
      "        [-0.0140, -0.2809],\n",
      "        [-0.0245, -0.2417],\n",
      "        [-0.0196, -0.2639],\n",
      "        [-0.0107, -0.2920],\n",
      "        [-0.0112, -0.2878],\n",
      "        [-0.0101, -0.2770],\n",
      "        [-0.0246, -0.2365],\n",
      "        [-0.0302, -0.2209],\n",
      "        [-0.0252, -0.2473],\n",
      "        [-0.0288, -0.2276],\n",
      "        [-0.0294, -0.2170],\n",
      "        [-0.0276, -0.2141],\n",
      "        [-0.0263, -0.2240],\n",
      "        [-0.0311, -0.2110],\n",
      "        [-0.0227, -0.2231],\n",
      "        [-0.0265, -0.2152]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0143, -0.3188],\n",
      "        [-0.0240, -0.3102],\n",
      "        [-0.0328, -0.2751],\n",
      "        [-0.0245, -0.3646],\n",
      "        [-0.0258, -0.2982],\n",
      "        [ 0.0007, -0.3533],\n",
      "        [-0.0080, -0.3258],\n",
      "        [-0.0101, -0.3357],\n",
      "        [-0.0111, -0.3128],\n",
      "        [-0.0085, -0.3198],\n",
      "        [-0.0082, -0.3183],\n",
      "        [-0.0082, -0.3166],\n",
      "        [-0.0094, -0.3026],\n",
      "        [-0.0082, -0.2964],\n",
      "        [-0.0108, -0.2975],\n",
      "        [-0.0112, -0.2941],\n",
      "        [-0.0097, -0.3061],\n",
      "        [-0.0115, -0.2860],\n",
      "        [-0.0140, -0.2656],\n",
      "        [-0.0194, -0.2438],\n",
      "        [-0.0286, -0.2144],\n",
      "        [-0.0147, -0.2646],\n",
      "        [-0.0125, -0.2738],\n",
      "        [-0.0131, -0.2769]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0109, -0.2946],\n",
      "        [-0.0135, -0.2822],\n",
      "        [-0.0120, -0.2952],\n",
      "        [-0.0030, -0.3305],\n",
      "        [-0.0264, -0.3017],\n",
      "        [-0.0040, -0.3314],\n",
      "        [-0.0158, -0.2991],\n",
      "        [-0.0108, -0.3115],\n",
      "        [-0.0317, -0.2817],\n",
      "        [-0.0216, -0.3688],\n",
      "        [-0.0142, -0.2846],\n",
      "        [-0.0143, -0.2785],\n",
      "        [-0.0094, -0.3011],\n",
      "        [-0.0156, -0.2760],\n",
      "        [-0.0126, -0.2785],\n",
      "        [-0.0094, -0.2857],\n",
      "        [-0.0126, -0.2785],\n",
      "        [-0.0156, -0.2760],\n",
      "        [-0.0136, -0.2782],\n",
      "        [-0.0106, -0.2849],\n",
      "        [-0.0126, -0.2781],\n",
      "        [-0.0106, -0.2849],\n",
      "        [-0.0136, -0.2782],\n",
      "        [-0.0134, -0.2813],\n",
      "        [-0.0143, -0.2607],\n",
      "        [-0.0234, -0.2442],\n",
      "        [-0.0268, -0.2217],\n",
      "        [-0.0254, -0.2174],\n",
      "        [-0.0317, -0.1967],\n",
      "        [-0.0334, -0.1888],\n",
      "        [-0.0344, -0.1723],\n",
      "        [-0.0334, -0.1888],\n",
      "        [-0.0317, -0.1967]], device='cuda:0')\n",
      "outpu is  tensor([[-1.0341e-02, -2.9363e-01],\n",
      "        [-2.4998e-02, -2.4967e-01],\n",
      "        [-2.5917e-02, -2.3557e-01],\n",
      "        [-3.2280e-02, -2.1552e-01],\n",
      "        [-1.2505e-02, -2.9434e-01],\n",
      "        [-2.0546e-02, -2.6075e-01],\n",
      "        [-2.3599e-02, -2.3995e-01],\n",
      "        [-3.1571e-02, -2.1655e-01],\n",
      "        [-3.0896e-02, -2.0826e-01],\n",
      "        [-3.1024e-02, -2.0775e-01],\n",
      "        [-2.6809e-02, -2.2141e-01],\n",
      "        [-2.7765e-02, -2.2436e-01],\n",
      "        [-2.4034e-02, -2.4629e-01],\n",
      "        [-2.1372e-02, -2.4304e-01],\n",
      "        [-1.4778e-02, -2.6724e-01],\n",
      "        [-2.0133e-02, -2.5731e-01],\n",
      "        [-3.5413e-02, -2.0152e-01],\n",
      "        [-2.1363e-02, -2.6107e-01],\n",
      "        [-3.2145e-02, -2.1793e-01],\n",
      "        [-2.8723e-02, -2.2456e-01],\n",
      "        [-2.5994e-02, -2.3543e-01],\n",
      "        [-3.9503e-02, -1.9012e-01],\n",
      "        [-1.2752e-02, -2.8836e-01],\n",
      "        [-2.0610e-02, -2.8510e-01],\n",
      "        [-2.1969e-02, -2.5152e-01],\n",
      "        [-3.4486e-02, -1.9720e-01],\n",
      "        [-3.9068e-02, -2.1673e-01],\n",
      "        [-3.9068e-02, -2.1673e-01],\n",
      "        [-3.4523e-02, -1.8886e-01],\n",
      "        [-1.4387e-05, -3.2922e-01]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0084, -0.3193],\n",
      "        [-0.0042, -0.3260],\n",
      "        [-0.0056, -0.3314],\n",
      "        [-0.0057, -0.3156],\n",
      "        [-0.0050, -0.3295],\n",
      "        [-0.0117, -0.3028],\n",
      "        [-0.0056, -0.3289],\n",
      "        [-0.0032, -0.3386],\n",
      "        [-0.0141, -0.2922],\n",
      "        [-0.0118, -0.3040],\n",
      "        [-0.0073, -0.3175],\n",
      "        [-0.0079, -0.3037],\n",
      "        [-0.0084, -0.3219],\n",
      "        [-0.0083, -0.2947],\n",
      "        [-0.0150, -0.2863],\n",
      "        [-0.0123, -0.2744],\n",
      "        [-0.0123, -0.2744],\n",
      "        [-0.0133, -0.2616],\n",
      "        [-0.0133, -0.2616],\n",
      "        [-0.0151, -0.2509]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0088, -0.3149],\n",
      "        [-0.0136, -0.3020],\n",
      "        [-0.0140, -0.2913],\n",
      "        [-0.0043, -0.3398],\n",
      "        [-0.0088, -0.2936],\n",
      "        [-0.0076, -0.3166],\n",
      "        [-0.0103, -0.2929],\n",
      "        [-0.0136, -0.2945],\n",
      "        [-0.0280, -0.2987],\n",
      "        [-0.0133, -0.2734],\n",
      "        [-0.0133, -0.2734],\n",
      "        [-0.0193, -0.2902],\n",
      "        [-0.0176, -0.2975],\n",
      "        [-0.0115, -0.2991],\n",
      "        [-0.0216, -0.2678],\n",
      "        [-0.0099, -0.3196],\n",
      "        [-0.0169, -0.3841],\n",
      "        [-0.0132, -0.2618],\n",
      "        [-0.0132, -0.2618],\n",
      "        [-0.0158, -0.2935],\n",
      "        [-0.0154, -0.2509]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0071, -0.3134],\n",
      "        [-0.0069, -0.3150],\n",
      "        [-0.0050, -0.3301],\n",
      "        [-0.0035, -0.3386],\n",
      "        [-0.0083, -0.3184],\n",
      "        [-0.0057, -0.3155],\n",
      "        [-0.0141, -0.2922],\n",
      "        [-0.0079, -0.3036],\n",
      "        [-0.0114, -0.3015],\n",
      "        [-0.0055, -0.3168],\n",
      "        [-0.0076, -0.3161],\n",
      "        [-0.0108, -0.2903],\n",
      "        [-0.0103, -0.2872],\n",
      "        [-0.0129, -0.2792],\n",
      "        [-0.0093, -0.2859],\n",
      "        [-0.0129, -0.2792],\n",
      "        [-0.0103, -0.2872],\n",
      "        [-0.0150, -0.2863],\n",
      "        [-0.0118, -0.3040],\n",
      "        [-0.0134, -0.2813]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0069, -0.3152],\n",
      "        [-0.0077, -0.3085],\n",
      "        [-0.0075, -0.3089],\n",
      "        [-0.0081, -0.3053],\n",
      "        [-0.0098, -0.2966],\n",
      "        [-0.0089, -0.2952],\n",
      "        [-0.0089, -0.2950],\n",
      "        [-0.0084, -0.2970],\n",
      "        [-0.0102, -0.2997],\n",
      "        [-0.0104, -0.2986],\n",
      "        [-0.0117, -0.2906],\n",
      "        [-0.0116, -0.2905],\n",
      "        [-0.0112, -0.2893],\n",
      "        [-0.0128, -0.2769],\n",
      "        [-0.0128, -0.2769],\n",
      "        [-0.0109, -0.2831],\n",
      "        [-0.0125, -0.2754],\n",
      "        [-0.0128, -0.2753],\n",
      "        [-0.0141, -0.2645],\n",
      "        [-0.0138, -0.2636]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0135, -0.2846],\n",
      "        [-0.0224, -0.2551],\n",
      "        [-0.0134, -0.2768],\n",
      "        [-0.0127, -0.2965],\n",
      "        [-0.0234, -0.2427],\n",
      "        [-0.0278, -0.2380],\n",
      "        [-0.0115, -0.2876],\n",
      "        [-0.0248, -0.2527],\n",
      "        [-0.0086, -0.2962],\n",
      "        [-0.0307, -0.2227],\n",
      "        [-0.0283, -0.2312],\n",
      "        [-0.0266, -0.2311],\n",
      "        [-0.0107, -0.2820],\n",
      "        [-0.0126, -0.2751],\n",
      "        [-0.0279, -0.2213],\n",
      "        [-0.0216, -0.2533],\n",
      "        [-0.0142, -0.2642],\n",
      "        [-0.0136, -0.2636],\n",
      "        [-0.0319, -0.2011],\n",
      "        [-0.0249, -0.2344],\n",
      "        [-0.0179, -0.2814],\n",
      "        [-0.0308, -0.2088],\n",
      "        [-0.0264, -0.2298],\n",
      "        [-0.0117, -0.2821],\n",
      "        [-0.0052, -0.3100],\n",
      "        [-0.0290, -0.2474]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0239, -0.2440],\n",
      "        [-0.0203, -0.2609],\n",
      "        [-0.0166, -0.2832],\n",
      "        [-0.0175, -0.2937]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0129, -0.2881],\n",
      "        [-0.0141, -0.2836],\n",
      "        [-0.0194, -0.2534],\n",
      "        [-0.0289, -0.2239],\n",
      "        [-0.0264, -0.2262],\n",
      "        [-0.0234, -0.2394],\n",
      "        [-0.0188, -0.2674],\n",
      "        [-0.0313, -0.2207],\n",
      "        [-0.0295, -0.2268],\n",
      "        [-0.0300, -0.2259],\n",
      "        [-0.0266, -0.2423],\n",
      "        [-0.0303, -0.2190],\n",
      "        [-0.0325, -0.2364],\n",
      "        [-0.0165, -0.2643],\n",
      "        [-0.0258, -0.2360],\n",
      "        [-0.0122, -0.2700],\n",
      "        [-0.0114, -0.2835],\n",
      "        [-0.0151, -0.2774],\n",
      "        [-0.0133, -0.2801],\n",
      "        [-0.0081, -0.2937]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0087, -0.3209],\n",
      "        [-0.0327, -0.2800],\n",
      "        [-0.0193, -0.2967],\n",
      "        [-0.0202, -0.2974],\n",
      "        [-0.0164, -0.3070],\n",
      "        [-0.0129, -0.3466],\n",
      "        [-0.0271, -0.2761],\n",
      "        [-0.0099, -0.3126],\n",
      "        [-0.0092, -0.3132],\n",
      "        [-0.0203, -0.2918],\n",
      "        [-0.0241, -0.2865],\n",
      "        [-0.0241, -0.2865],\n",
      "        [-0.0143, -0.3011],\n",
      "        [-0.0139, -0.3003],\n",
      "        [-0.0095, -0.3165],\n",
      "        [-0.0107, -0.3120],\n",
      "        [-0.0093, -0.3175],\n",
      "        [-0.0063, -0.3334],\n",
      "        [-0.0076, -0.3102],\n",
      "        [ 0.0014, -0.3550],\n",
      "        [-0.0051, -0.3359],\n",
      "        [-0.0113, -0.3132],\n",
      "        [-0.0195, -0.2773],\n",
      "        [-0.0140, -0.3134],\n",
      "        [-0.0259, -0.3076],\n",
      "        [-0.0113, -0.2975],\n",
      "        [-0.0034, -0.3462],\n",
      "        [-0.0101, -0.3167],\n",
      "        [-0.0201, -0.3930],\n",
      "        [-0.0171, -0.2773]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0331, -0.2209],\n",
      "        [-0.0149, -0.2563],\n",
      "        [-0.0331, -0.2209],\n",
      "        [-0.0182, -0.2617],\n",
      "        [-0.0105, -0.2826],\n",
      "        [-0.0135, -0.2774],\n",
      "        [-0.0140, -0.2725],\n",
      "        [-0.0135, -0.2774],\n",
      "        [-0.0105, -0.2826],\n",
      "        [-0.0181, -0.2717],\n",
      "        [-0.0190, -0.2644],\n",
      "        [-0.0240, -0.2441],\n",
      "        [-0.0278, -0.2300],\n",
      "        [-0.0210, -0.2531],\n",
      "        [-0.0271, -0.2506],\n",
      "        [-0.0194, -0.2626],\n",
      "        [-0.0136, -0.2715],\n",
      "        [-0.0285, -0.2351],\n",
      "        [-0.0289, -0.2273],\n",
      "        [-0.0247, -0.2515],\n",
      "        [-0.0261, -0.2476],\n",
      "        [-0.0117, -0.2865],\n",
      "        [-0.0197, -0.2717],\n",
      "        [-0.0190, -0.2754],\n",
      "        [-0.0218, -0.2480],\n",
      "        [-0.0293, -0.2264],\n",
      "        [-0.0304, -0.2270],\n",
      "        [-0.0325, -0.2384],\n",
      "        [-0.0299, -0.2140],\n",
      "        [-0.0243, -0.2581],\n",
      "        [-0.0321, -0.2016],\n",
      "        [-0.0339, -0.1853],\n",
      "        [-0.0250, -0.1970]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0117, -0.2887],\n",
      "        [-0.0076, -0.3074],\n",
      "        [-0.0107, -0.3123],\n",
      "        [-0.0135, -0.2981],\n",
      "        [-0.0118, -0.2861],\n",
      "        [-0.0141, -0.2797],\n",
      "        [-0.0107, -0.3017],\n",
      "        [-0.0059, -0.3186],\n",
      "        [-0.0165, -0.2802],\n",
      "        [-0.0224, -0.2661],\n",
      "        [-0.0250, -0.2512],\n",
      "        [-0.0222, -0.2568],\n",
      "        [-0.0208, -0.2869],\n",
      "        [-0.0217, -0.2631],\n",
      "        [-0.0263, -0.2565],\n",
      "        [-0.0236, -0.2602],\n",
      "        [-0.0213, -0.2617],\n",
      "        [-0.0256, -0.2611],\n",
      "        [-0.0298, -0.2502],\n",
      "        [-0.0241, -0.2449],\n",
      "        [-0.0414, -0.2090],\n",
      "        [-0.0414, -0.2090],\n",
      "        [-0.0414, -0.2090],\n",
      "        [-0.0275, -0.2451],\n",
      "        [-0.0159, -0.2736],\n",
      "        [-0.0317, -0.2490],\n",
      "        [-0.0283, -0.2404],\n",
      "        [-0.0278, -0.2500],\n",
      "        [-0.0235, -0.2429],\n",
      "        [-0.0286, -0.2335],\n",
      "        [-0.0317, -0.2150],\n",
      "        [-0.0291, -0.2078],\n",
      "        [-0.0326, -0.1910],\n",
      "        [-0.0326, -0.1910]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0027, -0.3307],\n",
      "        [-0.0117, -0.3183],\n",
      "        [-0.0279, -0.3042],\n",
      "        [-0.0091, -0.3118],\n",
      "        [-0.0174, -0.2637],\n",
      "        [-0.0144, -0.2658],\n",
      "        [-0.0140, -0.2823],\n",
      "        [-0.0181, -0.4149],\n",
      "        [-0.0056, -0.3340],\n",
      "        [-0.0323, -0.3108],\n",
      "        [-0.0477, -0.3477],\n",
      "        [-0.0477, -0.3477],\n",
      "        [-0.0109, -0.3196],\n",
      "        [-0.0131, -0.3234],\n",
      "        [-0.0072, -0.3437],\n",
      "        [-0.0262, -0.3012],\n",
      "        [-0.0106, -0.3200],\n",
      "        [-0.0065, -0.3377],\n",
      "        [-0.0170, -0.3746],\n",
      "        [-0.0083, -0.3260],\n",
      "        [-0.0306, -0.2870],\n",
      "        [-0.0164, -0.3128],\n",
      "        [-0.0168, -0.3304]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0074, -0.3099],\n",
      "        [-0.0101, -0.3081],\n",
      "        [-0.0110, -0.3026],\n",
      "        [-0.0170, -0.2892],\n",
      "        [-0.0094, -0.2955],\n",
      "        [-0.0057, -0.3226],\n",
      "        [-0.0086, -0.3080],\n",
      "        [-0.0149, -0.2801],\n",
      "        [-0.0155, -0.2828],\n",
      "        [-0.0105, -0.2855],\n",
      "        [-0.0105, -0.2855],\n",
      "        [-0.0099, -0.2949],\n",
      "        [-0.0140, -0.2713],\n",
      "        [-0.0170, -0.2585],\n",
      "        [-0.0145, -0.2897],\n",
      "        [-0.0167, -0.2621],\n",
      "        [-0.0167, -0.2621],\n",
      "        [-0.0169, -0.2642],\n",
      "        [-0.0252, -0.2402],\n",
      "        [-0.0343, -0.2210],\n",
      "        [-0.0343, -0.2210],\n",
      "        [-0.0129, -0.2641],\n",
      "        [-0.0247, -0.2381]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0283, -0.2527],\n",
      "        [-0.0209, -0.2919],\n",
      "        [-0.0158, -0.2939],\n",
      "        [-0.0116, -0.2975],\n",
      "        [-0.0397, -0.2645],\n",
      "        [-0.0232, -0.3559],\n",
      "        [-0.0119, -0.2984],\n",
      "        [-0.0140, -0.2847],\n",
      "        [-0.0244, -0.2601],\n",
      "        [-0.0318, -0.3044],\n",
      "        [-0.0152, -0.3734],\n",
      "        [-0.0049, -0.3397],\n",
      "        [-0.0377, -0.2839],\n",
      "        [-0.0136, -0.3275],\n",
      "        [-0.0136, -0.3275],\n",
      "        [-0.0122, -0.3071],\n",
      "        [-0.0366, -0.2489],\n",
      "        [-0.0205, -0.2850],\n",
      "        [-0.0275, -0.2520]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0099, -0.3201],\n",
      "        [-0.0141, -0.2968],\n",
      "        [-0.0080, -0.3092],\n",
      "        [-0.0096, -0.3166],\n",
      "        [-0.0043, -0.3404],\n",
      "        [-0.0281, -0.2987],\n",
      "        [-0.0169, -0.3842],\n",
      "        [-0.0152, -0.3041],\n",
      "        [-0.0148, -0.2965],\n",
      "        [-0.0088, -0.3052],\n",
      "        [-0.0131, -0.3051],\n",
      "        [-0.0205, -0.2749],\n",
      "        [-0.0111, -0.3123],\n",
      "        [-0.0063, -0.3132],\n",
      "        [-0.0207, -0.2850],\n",
      "        [-0.0111, -0.3054],\n",
      "        [-0.0020, -0.3326],\n",
      "        [-0.0145, -0.2829],\n",
      "        [-0.0259, -0.3018],\n",
      "        [-0.0144, -0.2661],\n",
      "        [-0.0092, -0.3126],\n",
      "        [-0.0177, -0.2637],\n",
      "        [-0.0196, -0.3895]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0079, -0.3209],\n",
      "        [-0.0054, -0.3191],\n",
      "        [-0.0113, -0.2933],\n",
      "        [-0.0091, -0.3041],\n",
      "        [-0.0090, -0.3201],\n",
      "        [-0.0054, -0.3163],\n",
      "        [-0.0111, -0.3034],\n",
      "        [-0.0105, -0.3035],\n",
      "        [-0.0047, -0.3250],\n",
      "        [-0.0107, -0.3061],\n",
      "        [-0.0157, -0.2837],\n",
      "        [-0.0191, -0.2695],\n",
      "        [-0.0219, -0.2542]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0348, -0.2251],\n",
      "        [-0.0216, -0.2382],\n",
      "        [-0.0279, -0.2247],\n",
      "        [-0.0307, -0.2091],\n",
      "        [-0.0323, -0.2148],\n",
      "        [-0.0253, -0.2350],\n",
      "        [-0.0308, -0.2161],\n",
      "        [-0.0298, -0.2101],\n",
      "        [-0.0303, -0.2143],\n",
      "        [-0.0300, -0.2250],\n",
      "        [-0.0282, -0.2253],\n",
      "        [-0.0252, -0.2371],\n",
      "        [-0.0266, -0.2307],\n",
      "        [-0.0310, -0.2053],\n",
      "        [-0.0378, -0.1883],\n",
      "        [-0.0222, -0.2357],\n",
      "        [-0.0298, -0.2227],\n",
      "        [-0.0262, -0.2343],\n",
      "        [-0.0342, -0.2245],\n",
      "        [-0.0263, -0.2255],\n",
      "        [-0.0309, -0.2127],\n",
      "        [-0.0106, -0.2856],\n",
      "        [-0.0308, -0.2138],\n",
      "        [-0.0307, -0.2121],\n",
      "        [-0.0166, -0.2769],\n",
      "        [-0.0167, -0.2776],\n",
      "        [-0.0271, -0.2206],\n",
      "        [-0.0293, -0.2135]], device='cuda:0')\n",
      "outpu is  tensor([[ 0.0195, -0.4351],\n",
      "        [ 0.0195, -0.4351],\n",
      "        [-0.0095, -0.5080],\n",
      "        [-0.0095, -0.5080]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0078, -0.3051],\n",
      "        [-0.0123, -0.2909],\n",
      "        [-0.0102, -0.2836],\n",
      "        [-0.0261, -0.2497],\n",
      "        [-0.0141, -0.2832],\n",
      "        [-0.0097, -0.2821],\n",
      "        [-0.0261, -0.2494],\n",
      "        [-0.0094, -0.2947],\n",
      "        [-0.0116, -0.2902],\n",
      "        [-0.0091, -0.3008],\n",
      "        [-0.0068, -0.3150],\n",
      "        [-0.0082, -0.3202],\n",
      "        [-0.0047, -0.3280],\n",
      "        [-0.0081, -0.3215],\n",
      "        [-0.0089, -0.3194],\n",
      "        [-0.0042, -0.3263],\n",
      "        [-0.0073, -0.3212],\n",
      "        [-0.0039, -0.3250],\n",
      "        [-0.0087, -0.3208],\n",
      "        [-0.0158, -0.2921],\n",
      "        [-0.0097, -0.2887],\n",
      "        [-0.0270, -0.2512],\n",
      "        [-0.0058, -0.3149],\n",
      "        [-0.0116, -0.3032],\n",
      "        [-0.0100, -0.3115]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0252, -0.2470],\n",
      "        [-0.0096, -0.2753],\n",
      "        [-0.0152, -0.2710],\n",
      "        [-0.0101, -0.2828],\n",
      "        [-0.0149, -0.2685],\n",
      "        [-0.0125, -0.2632],\n",
      "        [-0.0149, -0.2685],\n",
      "        [-0.0101, -0.2828],\n",
      "        [-0.0286, -0.2239],\n",
      "        [-0.0286, -0.2119],\n",
      "        [-0.0401, -0.1868],\n",
      "        [-0.0316, -0.2020],\n",
      "        [-0.0337, -0.1906]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0080, -0.3191],\n",
      "        [-0.0191, -0.3102],\n",
      "        [-0.0174, -0.3437],\n",
      "        [-0.0478, -0.3059],\n",
      "        [-0.0174, -0.3437],\n",
      "        [-0.0191, -0.3102],\n",
      "        [ 0.0203, -0.4510],\n",
      "        [-0.0035, -0.3251],\n",
      "        [-0.0122, -0.2944],\n",
      "        [-0.0095, -0.2954],\n",
      "        [-0.0140, -0.2811],\n",
      "        [-0.0099, -0.2920],\n",
      "        [-0.0179, -0.2721],\n",
      "        [-0.0105, -0.2874],\n",
      "        [-0.0234, -0.2572],\n",
      "        [-0.0160, -0.2920],\n",
      "        [-0.0091, -0.3148],\n",
      "        [-0.0145, -0.3016],\n",
      "        [-0.0143, -0.3099],\n",
      "        [-0.0082, -0.3194],\n",
      "        [-0.0102, -0.3182],\n",
      "        [-0.0095, -0.2995],\n",
      "        [-0.0113, -0.2829],\n",
      "        [-0.0144, -0.2648],\n",
      "        [-0.0141, -0.2643],\n",
      "        [-0.0109, -0.2793],\n",
      "        [-0.0166, -0.2729],\n",
      "        [-0.0148, -0.2608],\n",
      "        [-0.0336, -0.2225],\n",
      "        [-0.0336, -0.2225]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0117, -0.2754],\n",
      "        [-0.0152, -0.2638],\n",
      "        [-0.0130, -0.2606],\n",
      "        [-0.0152, -0.2507],\n",
      "        [-0.0130, -0.2606],\n",
      "        [-0.0152, -0.2638],\n",
      "        [-0.0184, -0.2703],\n",
      "        [-0.0117, -0.2754],\n",
      "        [-0.0152, -0.2638],\n",
      "        [-0.0130, -0.2606],\n",
      "        [-0.0152, -0.2507],\n",
      "        [-0.0130, -0.2606],\n",
      "        [-0.0152, -0.2638],\n",
      "        [-0.0231, -0.2527],\n",
      "        [-0.0277, -0.2317],\n",
      "        [-0.0283, -0.2121],\n",
      "        [-0.0306, -0.2107],\n",
      "        [-0.0293, -0.2168],\n",
      "        [-0.0252, -0.2344],\n",
      "        [-0.0306, -0.2107],\n",
      "        [-0.0293, -0.2168],\n",
      "        [-0.0249, -0.2426],\n",
      "        [-0.0246, -0.2505],\n",
      "        [-0.0097, -0.2850],\n",
      "        [-0.0128, -0.2844],\n",
      "        [-0.0152, -0.2742],\n",
      "        [-0.0115, -0.2863],\n",
      "        [-0.0091, -0.2931],\n",
      "        [-0.0174, -0.2721],\n",
      "        [-0.0094, -0.2804],\n",
      "        [-0.0262, -0.2491],\n",
      "        [-0.0150, -0.2690],\n",
      "        [-0.0302, -0.2363],\n",
      "        [-0.0271, -0.2403]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0102, -0.3201],\n",
      "        [-0.0147, -0.3095],\n",
      "        [-0.0136, -0.3020],\n",
      "        [-0.0112, -0.3160],\n",
      "        [-0.0143, -0.3094],\n",
      "        [-0.0122, -0.3167],\n",
      "        [-0.0145, -0.3022],\n",
      "        [-0.0110, -0.2895],\n",
      "        [-0.0110, -0.2895],\n",
      "        [-0.0138, -0.2730],\n",
      "        [-0.0138, -0.2730],\n",
      "        [-0.0138, -0.2730],\n",
      "        [-0.0138, -0.2730],\n",
      "        [-0.0133, -0.2619],\n",
      "        [-0.0133, -0.2619],\n",
      "        [-0.0133, -0.2619],\n",
      "        [-0.0133, -0.2619],\n",
      "        [-0.0152, -0.2510],\n",
      "        [-0.0152, -0.2510]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0165, -0.2545],\n",
      "        [-0.0119, -0.2613],\n",
      "        [-0.0275, -0.2313],\n",
      "        [-0.0281, -0.2260],\n",
      "        [-0.0230, -0.2438],\n",
      "        [-0.0349, -0.2205],\n",
      "        [-0.0265, -0.2415],\n",
      "        [-0.0107, -0.2698],\n",
      "        [-0.0374, -0.2018],\n",
      "        [-0.0165, -0.2545],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0153, -0.2503],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0167, -0.2555],\n",
      "        [-0.0129, -0.2594],\n",
      "        [-0.0153, -0.2503],\n",
      "        [-0.0129, -0.2594],\n",
      "        [-0.0167, -0.2555]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0156, -0.2806],\n",
      "        [-0.0136, -0.2779],\n",
      "        [-0.0216, -0.2682],\n",
      "        [-0.0272, -0.2404],\n",
      "        [-0.0161, -0.2892],\n",
      "        [-0.0132, -0.2721],\n",
      "        [-0.0132, -0.2721],\n",
      "        [-0.0111, -0.2724],\n",
      "        [-0.0364, -0.2071],\n",
      "        [-0.0369, -0.2074],\n",
      "        [-0.0127, -0.2877],\n",
      "        [-0.0134, -0.2617],\n",
      "        [-0.0134, -0.2617],\n",
      "        [-0.0168, -0.2558],\n",
      "        [-0.0168, -0.2558],\n",
      "        [-0.0226, -0.2325],\n",
      "        [-0.0299, -0.2289],\n",
      "        [-0.0113, -0.2935],\n",
      "        [-0.0152, -0.2510],\n",
      "        [-0.0129, -0.2594],\n",
      "        [-0.0129, -0.2594],\n",
      "        [-0.0410, -0.1961],\n",
      "        [-0.0410, -0.1961],\n",
      "        [-0.0335, -0.1925],\n",
      "        [-0.0153, -0.2503]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0090, -0.2944],\n",
      "        [-0.0090, -0.2944],\n",
      "        [-0.0098, -0.2881],\n",
      "        [-0.0109, -0.2880],\n",
      "        [-0.0109, -0.2880],\n",
      "        [-0.0098, -0.2881],\n",
      "        [-0.0120, -0.2742],\n",
      "        [-0.0138, -0.2634],\n",
      "        [-0.0141, -0.2645],\n",
      "        [-0.0110, -0.2827],\n",
      "        [-0.0110, -0.2827],\n",
      "        [-0.0141, -0.2645],\n",
      "        [-0.0138, -0.2634],\n",
      "        [-0.0120, -0.2742]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0119, -0.3007],\n",
      "        [-0.0115, -0.2922],\n",
      "        [-0.0088, -0.3075],\n",
      "        [-0.0067, -0.3163],\n",
      "        [-0.0089, -0.3169],\n",
      "        [-0.0073, -0.3146],\n",
      "        [-0.0138, -0.3038],\n",
      "        [-0.0083, -0.3162],\n",
      "        [-0.0108, -0.3099],\n",
      "        [-0.0072, -0.3044],\n",
      "        [-0.0068, -0.3153],\n",
      "        [-0.0209, -0.2686],\n",
      "        [-0.0099, -0.2722],\n",
      "        [-0.0168, -0.2552],\n",
      "        [-0.0128, -0.2593],\n",
      "        [-0.0153, -0.2503],\n",
      "        [-0.0128, -0.2593],\n",
      "        [-0.0168, -0.2552]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0274, -0.3075],\n",
      "        [-0.0205, -0.3926],\n",
      "        [-0.0025, -0.3613],\n",
      "        [-0.0274, -0.3075],\n",
      "        [-0.0205, -0.3926],\n",
      "        [-0.0103, -0.3171],\n",
      "        [-0.0202, -0.2759],\n",
      "        [-0.0103, -0.3171],\n",
      "        [-0.0163, -0.3277],\n",
      "        [-0.0133, -0.3334]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0106, -0.2966],\n",
      "        [-0.0098, -0.3069],\n",
      "        [-0.0106, -0.2868],\n",
      "        [-0.0131, -0.2957],\n",
      "        [-0.0119, -0.2962],\n",
      "        [-0.0039, -0.3382],\n",
      "        [-0.0126, -0.2870],\n",
      "        [-0.0227, -0.2459],\n",
      "        [-0.0102, -0.3200],\n",
      "        [-0.0104, -0.2922],\n",
      "        [-0.0279, -0.2985],\n",
      "        [-0.0289, -0.2166],\n",
      "        [-0.0170, -0.3841],\n",
      "        [-0.0359, -0.1826],\n",
      "        [-0.0393, -0.1861],\n",
      "        [-0.0331, -0.1974],\n",
      "        [-0.0312, -0.1959],\n",
      "        [-0.0277, -0.2019],\n",
      "        [-0.0300, -0.1936],\n",
      "        [-0.0300, -0.1936],\n",
      "        [-0.0350, -0.1865],\n",
      "        [-0.0350, -0.1865]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0340, -0.1941],\n",
      "        [-0.0301, -0.2095],\n",
      "        [-0.0181, -0.2436],\n",
      "        [-0.0295, -0.2471],\n",
      "        [-0.0120, -0.2937],\n",
      "        [-0.0271, -0.2391],\n",
      "        [-0.0275, -0.2331],\n",
      "        [-0.0370, -0.2061],\n",
      "        [-0.0232, -0.2875],\n",
      "        [-0.0181, -0.2797],\n",
      "        [-0.0303, -0.2142],\n",
      "        [-0.0171, -0.2883],\n",
      "        [-0.0271, -0.2262],\n",
      "        [-0.0161, -0.3123],\n",
      "        [-0.0341, -0.1948],\n",
      "        [-0.0294, -0.2107],\n",
      "        [-0.0196, -0.3033],\n",
      "        [-0.0379, -0.1885],\n",
      "        [-0.0313, -0.2062],\n",
      "        [-0.0185, -0.2804],\n",
      "        [-0.0311, -0.2197],\n",
      "        [-0.0334, -0.2043],\n",
      "        [-0.0295, -0.2569]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0061, -0.3124],\n",
      "        [-0.0081, -0.3068],\n",
      "        [-0.0114, -0.2874],\n",
      "        [-0.0139, -0.2590],\n",
      "        [-0.0247, -0.2218],\n",
      "        [-0.0321, -0.1851],\n",
      "        [-0.0356, -0.1657],\n",
      "        [-0.0389, -0.1503],\n",
      "        [-0.0113, -0.2873],\n",
      "        [-0.0106, -0.2881],\n",
      "        [-0.0106, -0.2915],\n",
      "        [-0.0110, -0.2890],\n",
      "        [-0.0100, -0.3002],\n",
      "        [-0.0058, -0.3171],\n",
      "        [-0.0047, -0.3220],\n",
      "        [-0.0063, -0.3203]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0147, -0.2630],\n",
      "        [-0.0249, -0.2438],\n",
      "        [-0.0116, -0.2835],\n",
      "        [-0.0109, -0.2898],\n",
      "        [-0.0139, -0.2751],\n",
      "        [-0.0125, -0.2738],\n",
      "        [-0.0153, -0.2642],\n",
      "        [-0.0190, -0.2811],\n",
      "        [-0.0174, -0.2876],\n",
      "        [-0.0282, -0.2200],\n",
      "        [-0.0250, -0.2167],\n",
      "        [-0.0337, -0.1895],\n",
      "        [-0.0337, -0.1895],\n",
      "        [-0.0343, -0.1810],\n",
      "        [-0.0394, -0.1540],\n",
      "        [-0.0343, -0.1810],\n",
      "        [-0.0394, -0.1540],\n",
      "        [-0.0106, -0.3049],\n",
      "        [-0.0210, -0.2794]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0079, -0.3068],\n",
      "        [-0.0157, -0.2849],\n",
      "        [-0.0121, -0.2919],\n",
      "        [-0.0145, -0.2979],\n",
      "        [-0.0047, -0.3256],\n",
      "        [-0.0047, -0.3258],\n",
      "        [-0.0117, -0.2972],\n",
      "        [-0.0102, -0.2981],\n",
      "        [-0.0106, -0.2991],\n",
      "        [-0.0092, -0.3076],\n",
      "        [-0.0111, -0.2969],\n",
      "        [-0.0084, -0.3157],\n",
      "        [-0.0091, -0.2939],\n",
      "        [-0.0239, -0.2566],\n",
      "        [-0.0178, -0.2674],\n",
      "        [-0.0125, -0.2997]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0259, -0.3018],\n",
      "        [-0.0196, -0.3895],\n",
      "        [-0.0021, -0.3329],\n",
      "        [-0.0173, -0.3040],\n",
      "        [-0.0145, -0.2829],\n",
      "        [-0.0144, -0.2661],\n",
      "        [-0.0177, -0.2637],\n",
      "        [-0.0092, -0.3126],\n",
      "        [-0.0040, -0.3449],\n",
      "        [-0.0226, -0.3126],\n",
      "        [-0.0019, -0.3369],\n",
      "        [-0.0084, -0.3129],\n",
      "        [-0.0207, -0.2852],\n",
      "        [-0.0112, -0.3057],\n",
      "        [-0.0060, -0.3336],\n",
      "        [-0.0306, -0.2725],\n",
      "        [-0.0309, -0.2447],\n",
      "        [-0.0378, -0.1915],\n",
      "        [-0.0200, -0.3782],\n",
      "        [-0.0103, -0.3059],\n",
      "        [-0.0205, -0.2754],\n",
      "        [-0.0131, -0.3054],\n",
      "        [-0.0111, -0.3125]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0169, -0.2613],\n",
      "        [-0.0275, -0.2255],\n",
      "        [-0.0396, -0.1895],\n",
      "        [-0.0396, -0.1895],\n",
      "        [-0.0095, -0.2953],\n",
      "        [-0.0063, -0.3146],\n",
      "        [-0.0169, -0.2613],\n",
      "        [-0.0275, -0.2255],\n",
      "        [-0.0396, -0.1895],\n",
      "        [-0.0396, -0.1895],\n",
      "        [-0.0132, -0.2718],\n",
      "        [-0.0130, -0.2745],\n",
      "        [-0.0132, -0.2718]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0116, -0.2956],\n",
      "        [-0.0111, -0.2971],\n",
      "        [-0.0114, -0.3003],\n",
      "        [-0.0099, -0.3061],\n",
      "        [-0.0087, -0.3070],\n",
      "        [-0.0109, -0.2853],\n",
      "        [-0.0106, -0.2847],\n",
      "        [-0.0260, -0.2499],\n",
      "        [-0.0102, -0.2901],\n",
      "        [-0.0270, -0.2516],\n",
      "        [-0.0108, -0.2915],\n",
      "        [-0.0270, -0.2520],\n",
      "        [-0.0270, -0.2389],\n",
      "        [-0.0286, -0.2281],\n",
      "        [-0.0216, -0.2568],\n",
      "        [-0.0123, -0.2884],\n",
      "        [-0.0096, -0.3018],\n",
      "        [-0.0103, -0.3064],\n",
      "        [-0.0104, -0.2984],\n",
      "        [-0.0098, -0.2964],\n",
      "        [-0.0052, -0.3186],\n",
      "        [-0.0150, -0.2856],\n",
      "        [-0.0070, -0.3188],\n",
      "        [-0.0098, -0.2826],\n",
      "        [-0.0261, -0.2494],\n",
      "        [-0.0241, -0.2527],\n",
      "        [-0.0140, -0.2843],\n",
      "        [-0.0275, -0.2520],\n",
      "        [-0.0244, -0.2601]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0058, -0.3199],\n",
      "        [-0.0073, -0.3197],\n",
      "        [-0.0069, -0.3108],\n",
      "        [-0.0071, -0.3084],\n",
      "        [-0.0128, -0.2961],\n",
      "        [-0.0074, -0.3097],\n",
      "        [-0.0105, -0.2988],\n",
      "        [-0.0104, -0.3016],\n",
      "        [-0.0058, -0.3173],\n",
      "        [-0.0047, -0.3220],\n",
      "        [-0.0066, -0.3214],\n",
      "        [-0.0091, -0.3017],\n",
      "        [-0.0090, -0.2961],\n",
      "        [-0.0099, -0.3001],\n",
      "        [-0.0102, -0.2897],\n",
      "        [-0.0271, -0.2516]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0261, -0.2496],\n",
      "        [-0.0101, -0.2829],\n",
      "        [-0.0122, -0.2886],\n",
      "        [-0.0183, -0.2855],\n",
      "        [-0.0065, -0.3245],\n",
      "        [-0.0199, -0.2828],\n",
      "        [-0.0105, -0.2925],\n",
      "        [-0.0106, -0.2948],\n",
      "        [-0.0351, -0.2943],\n",
      "        [-0.0176, -0.3851],\n",
      "        [-0.0507, -0.3209],\n",
      "        [-0.0281, -0.3061],\n",
      "        [ 0.0013, -0.3488],\n",
      "        [-0.0126, -0.3024],\n",
      "        [-0.0111, -0.3065],\n",
      "        [-0.0059, -0.3382],\n",
      "        [-0.0105, -0.3001],\n",
      "        [-0.0125, -0.2969],\n",
      "        [-0.0119, -0.2904],\n",
      "        [-0.0099, -0.2979],\n",
      "        [-0.0024, -0.3217],\n",
      "        [-0.0364, -0.2787],\n",
      "        [-0.0144, -0.3257],\n",
      "        [-0.0144, -0.3257],\n",
      "        [-0.0096, -0.2882],\n",
      "        [-0.0271, -0.2513]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0127, -0.2896],\n",
      "        [-0.0094, -0.3066],\n",
      "        [-0.0093, -0.2802],\n",
      "        [-0.0109, -0.2820],\n",
      "        [-0.0123, -0.2824],\n",
      "        [-0.0120, -0.3191],\n",
      "        [-0.0257, -0.2439],\n",
      "        [-0.0141, -0.2644],\n",
      "        [-0.0142, -0.2649],\n",
      "        [-0.0119, -0.3294],\n",
      "        [-0.0256, -0.2352],\n",
      "        [-0.0287, -0.2238],\n",
      "        [-0.0307, -0.2161],\n",
      "        [-0.0322, -0.2147],\n",
      "        [-0.0238, -0.2331],\n",
      "        [-0.0436, -0.1972],\n",
      "        [-0.0436, -0.1972],\n",
      "        [-0.0436, -0.1972]], device='cuda:0')\n",
      "outpu is  tensor([[-1.1381e-02, -2.9981e-01],\n",
      "        [-6.3157e-03, -3.1359e-01],\n",
      "        [-1.1023e-02, -2.8917e-01],\n",
      "        [-1.1079e-02, -2.8938e-01],\n",
      "        [-6.4750e-03, -3.2225e-01],\n",
      "        [-1.2081e-02, -2.8710e-01],\n",
      "        [-1.3135e-02, -2.9042e-01],\n",
      "        [-2.4340e-02, -2.5665e-01],\n",
      "        [-1.5835e-02, -2.7895e-01],\n",
      "        [-2.5328e-02, -2.5513e-01],\n",
      "        [-1.0862e-02, -3.1571e-01],\n",
      "        [-5.9741e-03, -3.2192e-01],\n",
      "        [-1.3388e-02, -2.7827e-01],\n",
      "        [-1.8278e-02, -2.5674e-01],\n",
      "        [-1.0122e-02, -2.8602e-01],\n",
      "        [-9.4895e-03, -2.9361e-01],\n",
      "        [-1.2233e-02, -2.8799e-01],\n",
      "        [-4.5009e-05, -3.5206e-01],\n",
      "        [-2.9399e-02, -2.1837e-01],\n",
      "        [-1.4765e-02, -2.7822e-01],\n",
      "        [-2.3048e-02, -2.5737e-01],\n",
      "        [-1.1360e-02, -2.8705e-01],\n",
      "        [-3.4630e-02, -3.1693e-01],\n",
      "        [-3.0957e-02, -1.9440e-01],\n",
      "        [-1.3270e-02, -2.7874e-01],\n",
      "        [-7.4157e-03, -3.6926e-01],\n",
      "        [-7.4157e-03, -3.6926e-01],\n",
      "        [-7.4157e-03, -3.6926e-01],\n",
      "        [-2.5977e-02, -1.9907e-01],\n",
      "        [-1.0068e-02, -2.7662e-01],\n",
      "        [-2.5182e-02, -2.4735e-01]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0230, -0.2563],\n",
      "        [-0.0251, -0.2451],\n",
      "        [-0.0195, -0.2749],\n",
      "        [-0.0265, -0.2322],\n",
      "        [-0.0312, -0.2268],\n",
      "        [-0.0228, -0.2465],\n",
      "        [-0.0193, -0.2886],\n",
      "        [-0.0325, -0.2090],\n",
      "        [-0.0178, -0.2519],\n",
      "        [-0.0279, -0.2416],\n",
      "        [-0.0100, -0.3231],\n",
      "        [-0.0142, -0.3021],\n",
      "        [-0.0286, -0.2103],\n",
      "        [-0.0356, -0.2235],\n",
      "        [-0.0370, -0.2065],\n",
      "        [-0.0133, -0.3132],\n",
      "        [-0.0068, -0.3345],\n",
      "        [-0.0367, -0.2018],\n",
      "        [-0.0424, -0.1774],\n",
      "        [-0.0160, -0.2723],\n",
      "        [-0.0042, -0.3342],\n",
      "        [-0.0191, -0.2452],\n",
      "        [-0.0206, -0.2621],\n",
      "        [-0.0285, -0.2217],\n",
      "        [-0.0268, -0.2353],\n",
      "        [-0.0355, -0.2187],\n",
      "        [-0.0142, -0.2983],\n",
      "        [-0.0291, -0.2133],\n",
      "        [-0.0320, -0.1923],\n",
      "        [-0.0212, -0.2512],\n",
      "        [-0.0094, -0.2956],\n",
      "        [-0.0067, -0.3145],\n",
      "        [-0.0346, -0.1838],\n",
      "        [-0.0138, -0.2743],\n",
      "        [-0.0304, -0.2164],\n",
      "        [-0.0262, -0.2523],\n",
      "        [-0.0261, -0.2454],\n",
      "        [-0.0195, -0.2722],\n",
      "        [-0.0254, -0.2140],\n",
      "        [-0.0165, -0.2614],\n",
      "        [-0.0269, -0.2344],\n",
      "        [-0.0250, -0.2358],\n",
      "        [-0.0325, -0.1932],\n",
      "        [-0.0292, -0.2261],\n",
      "        [-0.0321, -0.2348],\n",
      "        [-0.0366, -0.2045],\n",
      "        [-0.0272, -0.2295],\n",
      "        [-0.0268, -0.2253],\n",
      "        [-0.0292, -0.2207],\n",
      "        [-0.0322, -0.2004],\n",
      "        [-0.0278, -0.2270],\n",
      "        [-0.0307, -0.2078],\n",
      "        [-0.0254, -0.2279],\n",
      "        [-0.0175, -0.2511],\n",
      "        [-0.0258, -0.2280],\n",
      "        [-0.0356, -0.2233]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2616487/721503128.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  preds = torch.nn.functional.softmax(output)\n",
      "/tmp/ipykernel_2616487/118834433.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  all_pred_raw.append(torch.nn.functional.softmax(output)[:, 1].cpu().detach().numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outpu is  tensor([[-0.0292, -0.2255],\n",
      "        [-0.0257, -0.2324],\n",
      "        [-0.0199, -0.2577],\n",
      "        [-0.0306, -0.2282],\n",
      "        [-0.0289, -0.2329],\n",
      "        [-0.0300, -0.2202],\n",
      "        [-0.0214, -0.2680],\n",
      "        [-0.0309, -0.2354],\n",
      "        [-0.0334, -0.2396],\n",
      "        [-0.0277, -0.2395],\n",
      "        [-0.0202, -0.2541],\n",
      "        [-0.0244, -0.2493],\n",
      "        [-0.0280, -0.2330],\n",
      "        [-0.0125, -0.2885],\n",
      "        [-0.0184, -0.2835],\n",
      "        [-0.0189, -0.2572],\n",
      "        [-0.0286, -0.2320],\n",
      "        [-0.0324, -0.2366],\n",
      "        [-0.0278, -0.2337],\n",
      "        [-0.0274, -0.2464],\n",
      "        [-0.0150, -0.2914],\n",
      "        [-0.0195, -0.2706],\n",
      "        [-0.0265, -0.2472],\n",
      "        [-0.0248, -0.2467],\n",
      "        [-0.0115, -0.2863],\n",
      "        [-0.0190, -0.2756]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0154, -0.2680],\n",
      "        [-0.0152, -0.2800],\n",
      "        [-0.0152, -0.2800],\n",
      "        [-0.0292, -0.2343],\n",
      "        [-0.0286, -0.2207],\n",
      "        [-0.0116, -0.2822],\n",
      "        [-0.0118, -0.2809],\n",
      "        [-0.0116, -0.2822],\n",
      "        [-0.0118, -0.2809],\n",
      "        [-0.0300, -0.2374],\n",
      "        [-0.0337, -0.2004],\n",
      "        [-0.0196, -0.2638],\n",
      "        [-0.0138, -0.2726],\n",
      "        [-0.0142, -0.2646],\n",
      "        [-0.0138, -0.2726],\n",
      "        [-0.0142, -0.2646],\n",
      "        [-0.0352, -0.1772],\n",
      "        [-0.0137, -0.2637],\n",
      "        [-0.0137, -0.2637],\n",
      "        [-0.0318, -0.1922],\n",
      "        [-0.0391, -0.1720]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0119, -0.2724],\n",
      "        [-0.0169, -0.2559],\n",
      "        [-0.0128, -0.2594],\n",
      "        [-0.0153, -0.2503],\n",
      "        [-0.0128, -0.2594],\n",
      "        [-0.0169, -0.2559],\n",
      "        [-0.0102, -0.3029],\n",
      "        [-0.0295, -0.2862],\n",
      "        [-0.0164, -0.3773],\n",
      "        [-0.0280, -0.3019],\n",
      "        [-0.0121, -0.3239],\n",
      "        [-0.0135, -0.3162],\n",
      "        [-0.0021, -0.3365],\n",
      "        [-0.0234, -0.2742],\n",
      "        [-0.0269, -0.2555],\n",
      "        [-0.0344, -0.2203],\n",
      "        [-0.0238, -0.2559],\n",
      "        [-0.0117, -0.2950],\n",
      "        [-0.0172, -0.2808],\n",
      "        [-0.0188, -0.2804]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0239, -0.2708],\n",
      "        [-0.0089, -0.3013],\n",
      "        [-0.0198, -0.2789],\n",
      "        [-0.0126, -0.2870],\n",
      "        [-0.0109, -0.2814],\n",
      "        [-0.0143, -0.2644],\n",
      "        [-0.0140, -0.2642],\n",
      "        [-0.0106, -0.2806],\n",
      "        [-0.0136, -0.2816],\n",
      "        [-0.0098, -0.2820],\n",
      "        [-0.0261, -0.2495]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0158, -0.2824],\n",
      "        [-0.0051, -0.3322],\n",
      "        [-0.0028, -0.3219],\n",
      "        [-0.0256, -0.2338],\n",
      "        [-0.0270, -0.3024],\n",
      "        [-0.0058, -0.3413],\n",
      "        [-0.0261, -0.2996],\n",
      "        [-0.0138, -0.2811],\n",
      "        [-0.0314, -0.2118],\n",
      "        [-0.0156, -0.3863],\n",
      "        [-0.0129, -0.3264],\n",
      "        [-0.0282, -0.2990],\n",
      "        [-0.0088, -0.3106],\n",
      "        [-0.0141, -0.2656],\n",
      "        [-0.0329, -0.1998],\n",
      "        [-0.0135, -0.3245],\n",
      "        [-0.0169, -0.3841],\n",
      "        [-0.0173, -0.2639],\n",
      "        [-0.0257, -0.2197],\n",
      "        [-0.0286, -0.2192],\n",
      "        [-0.0286, -0.2192],\n",
      "        [-0.0286, -0.2193],\n",
      "        [-0.0286, -0.2193],\n",
      "        [-0.0259, -0.2204],\n",
      "        [-0.0291, -0.2091],\n",
      "        [-0.0297, -0.2046],\n",
      "        [-0.0262, -0.2018]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0247, -0.2381],\n",
      "        [-0.0129, -0.2641],\n",
      "        [-0.0167, -0.2621],\n",
      "        [-0.0110, -0.2838],\n",
      "        [-0.0115, -0.2884],\n",
      "        [-0.0110, -0.2838],\n",
      "        [-0.0167, -0.2621],\n",
      "        [-0.0141, -0.2912],\n",
      "        [-0.0087, -0.3107],\n",
      "        [-0.0224, -0.2553],\n",
      "        [-0.0306, -0.2339],\n",
      "        [-0.0258, -0.2265],\n",
      "        [-0.0304, -0.2047],\n",
      "        [-0.0336, -0.1926],\n",
      "        [-0.0336, -0.1926],\n",
      "        [-0.0304, -0.2047]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0254, -0.2784],\n",
      "        [-0.0135, -0.2968],\n",
      "        [-0.0142, -0.3101],\n",
      "        [-0.0112, -0.3153],\n",
      "        [-0.0120, -0.3167],\n",
      "        [-0.0154, -0.3051],\n",
      "        [-0.0078, -0.3179],\n",
      "        [-0.0111, -0.3047],\n",
      "        [-0.0181, -0.2995],\n",
      "        [-0.0044, -0.3308],\n",
      "        [-0.0250, -0.2695],\n",
      "        [-0.0205, -0.2503],\n",
      "        [-0.0218, -0.2335],\n",
      "        [-0.0297, -0.2036],\n",
      "        [-0.0336, -0.1816],\n",
      "        [-0.0326, -0.1916],\n",
      "        [-0.0278, -0.2194]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0032, -0.3386],\n",
      "        [-0.0056, -0.3314],\n",
      "        [-0.0084, -0.3193],\n",
      "        [-0.0056, -0.3289],\n",
      "        [-0.0042, -0.3260],\n",
      "        [-0.0057, -0.3156],\n",
      "        [-0.0084, -0.3219],\n",
      "        [-0.0072, -0.3177],\n",
      "        [-0.0050, -0.3295],\n",
      "        [-0.0117, -0.3028],\n",
      "        [-0.0118, -0.3040],\n",
      "        [-0.0141, -0.2922],\n",
      "        [-0.0091, -0.2974],\n",
      "        [-0.0079, -0.3037],\n",
      "        [-0.0109, -0.2883],\n",
      "        [-0.0109, -0.2883],\n",
      "        [-0.0150, -0.2863],\n",
      "        [-0.0106, -0.2853],\n",
      "        [-0.0106, -0.2853],\n",
      "        [-0.0151, -0.2714],\n",
      "        [-0.0096, -0.2753],\n",
      "        [-0.0252, -0.2470]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0101, -0.2808],\n",
      "        [-0.0057, -0.3123],\n",
      "        [-0.0066, -0.2999],\n",
      "        [-0.0066, -0.2998],\n",
      "        [-0.0106, -0.2846],\n",
      "        [-0.0106, -0.2846],\n",
      "        [-0.0098, -0.2890],\n",
      "        [-0.0209, -0.2691],\n",
      "        [-0.0267, -0.2477],\n",
      "        [-0.0180, -0.2792],\n",
      "        [-0.0270, -0.2440],\n",
      "        [-0.0129, -0.2891],\n",
      "        [-0.0284, -0.2442],\n",
      "        [-0.0122, -0.2817],\n",
      "        [-0.0164, -0.2901],\n",
      "        [-0.0108, -0.2964],\n",
      "        [-0.0098, -0.3042],\n",
      "        [-0.0115, -0.2957],\n",
      "        [-0.0115, -0.3007],\n",
      "        [-0.0112, -0.3001],\n",
      "        [-0.0120, -0.2972],\n",
      "        [-0.0120, -0.2972],\n",
      "        [-0.0108, -0.2968],\n",
      "        [-0.0108, -0.2968],\n",
      "        [-0.0127, -0.2939],\n",
      "        [-0.0212, -0.2766],\n",
      "        [-0.0260, -0.2499],\n",
      "        [-0.0260, -0.2499],\n",
      "        [-0.0270, -0.2514]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0250, -0.2433],\n",
      "        [-0.0324, -0.2103],\n",
      "        [-0.0133, -0.2708],\n",
      "        [-0.0242, -0.2281],\n",
      "        [-0.0109, -0.2909],\n",
      "        [-0.0142, -0.2766],\n",
      "        [-0.0108, -0.2889],\n",
      "        [-0.0074, -0.3026],\n",
      "        [-0.0126, -0.2869],\n",
      "        [-0.0109, -0.2876],\n",
      "        [-0.0140, -0.2806],\n",
      "        [-0.0109, -0.2865],\n",
      "        [-0.0101, -0.2770],\n",
      "        [-0.0402, -0.1942],\n",
      "        [-0.0402, -0.1942],\n",
      "        [-0.0252, -0.2473]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0214, -0.2498],\n",
      "        [-0.0240, -0.2541],\n",
      "        [-0.0312, -0.2225],\n",
      "        [-0.0298, -0.2325],\n",
      "        [-0.0279, -0.2290],\n",
      "        [-0.0116, -0.2958],\n",
      "        [-0.0274, -0.2142],\n",
      "        [-0.0254, -0.2398],\n",
      "        [-0.0282, -0.2080],\n",
      "        [-0.0280, -0.2506],\n",
      "        [-0.0155, -0.2937],\n",
      "        [-0.0333, -0.1877],\n",
      "        [-0.0255, -0.2471],\n",
      "        [-0.0269, -0.2310],\n",
      "        [-0.0330, -0.1869],\n",
      "        [-0.0240, -0.2439],\n",
      "        [-0.0334, -0.1797],\n",
      "        [-0.0258, -0.2399],\n",
      "        [-0.0222, -0.2599],\n",
      "        [-0.0334, -0.1796],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0120, -0.2621],\n",
      "        [-0.0156, -0.2846],\n",
      "        [-0.0164, -0.2545],\n",
      "        [-0.0164, -0.2545],\n",
      "        [-0.0212, -0.2709],\n",
      "        [-0.0137, -0.2913],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0181, -0.2822],\n",
      "        [-0.0275, -0.2493],\n",
      "        [-0.0153, -0.2503],\n",
      "        [-0.0109, -0.3093],\n",
      "        [-0.0150, -0.2837],\n",
      "        [-0.0088, -0.3092],\n",
      "        [-0.0084, -0.3157],\n",
      "        [-0.0252, -0.2591],\n",
      "        [-0.0247, -0.2597],\n",
      "        [-0.0084, -0.3123],\n",
      "        [-0.0108, -0.2975],\n",
      "        [-0.0082, -0.3011],\n",
      "        [-0.0110, -0.2895],\n",
      "        [-0.0103, -0.2886],\n",
      "        [-0.0114, -0.2833],\n",
      "        [-0.0119, -0.2742],\n",
      "        [-0.0140, -0.2645],\n",
      "        [-0.0138, -0.2633]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0054, -0.3365],\n",
      "        [-0.0047, -0.3379],\n",
      "        [-0.0051, -0.3360],\n",
      "        [-0.0058, -0.3305],\n",
      "        [-0.0063, -0.3313],\n",
      "        [-0.0050, -0.3350],\n",
      "        [-0.0109, -0.3169],\n",
      "        [-0.0117, -0.3219],\n",
      "        [-0.0065, -0.3321],\n",
      "        [-0.0102, -0.3099],\n",
      "        [-0.0068, -0.3286],\n",
      "        [-0.0054, -0.3315],\n",
      "        [-0.0087, -0.3191],\n",
      "        [-0.0108, -0.3153],\n",
      "        [-0.0092, -0.3048],\n",
      "        [-0.0125, -0.3126],\n",
      "        [-0.0059, -0.3367],\n",
      "        [-0.0032, -0.3393],\n",
      "        [-0.0073, -0.3184],\n",
      "        [-0.0112, -0.3173],\n",
      "        [-0.0048, -0.3268],\n",
      "        [-0.0064, -0.3161],\n",
      "        [-0.0211, -0.2743],\n",
      "        [-0.0152, -0.2857],\n",
      "        [-0.0246, -0.2819],\n",
      "        [-0.0146, -0.3007],\n",
      "        [-0.0093, -0.3086],\n",
      "        [-0.0116, -0.2981],\n",
      "        [-0.0117, -0.3041],\n",
      "        [-0.0191, -0.2747],\n",
      "        [-0.0136, -0.2814],\n",
      "        [-0.0081, -0.3141],\n",
      "        [-0.0126, -0.2884],\n",
      "        [-0.0178, -0.2652],\n",
      "        [-0.0216, -0.2540],\n",
      "        [-0.0274, -0.2524],\n",
      "        [-0.0192, -0.2486],\n",
      "        [-0.0303, -0.2317],\n",
      "        [-0.0173, -0.2569],\n",
      "        [-0.0264, -0.2340],\n",
      "        [-0.0264, -0.2340],\n",
      "        [-0.0262, -0.2366],\n",
      "        [-0.0166, -0.2569],\n",
      "        [-0.0244, -0.2311],\n",
      "        [-0.0279, -0.2203],\n",
      "        [-0.0279, -0.2203],\n",
      "        [-0.0261, -0.2421],\n",
      "        [-0.0371, -0.2055],\n",
      "        [-0.0364, -0.2251],\n",
      "        [-0.0269, -0.2274],\n",
      "        [-0.0244, -0.2267],\n",
      "        [-0.0264, -0.2321],\n",
      "        [-0.0179, -0.2689],\n",
      "        [-0.0293, -0.2230],\n",
      "        [-0.0355, -0.2019],\n",
      "        [-0.0355, -0.1954],\n",
      "        [-0.0297, -0.2241],\n",
      "        [-0.0361, -0.2047],\n",
      "        [-0.0097, -0.2986],\n",
      "        [-0.0270, -0.2270],\n",
      "        [-0.0217, -0.2415],\n",
      "        [-0.0297, -0.1993],\n",
      "        [-0.0216, -0.2416],\n",
      "        [-0.0218, -0.2717],\n",
      "        [-0.0175, -0.2792],\n",
      "        [-0.0352, -0.2034],\n",
      "        [-0.0428, -0.1652],\n",
      "        [-0.0428, -0.1652]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0105, -0.3071],\n",
      "        [-0.0089, -0.2925],\n",
      "        [-0.0064, -0.3154],\n",
      "        [-0.0191, -0.2825],\n",
      "        [-0.0285, -0.2499],\n",
      "        [-0.0167, -0.2675],\n",
      "        [-0.0053, -0.3179],\n",
      "        [-0.0125, -0.2868],\n",
      "        [-0.0197, -0.2661],\n",
      "        [-0.0128, -0.2758],\n",
      "        [-0.0141, -0.2958],\n",
      "        [-0.0414, -0.2209],\n",
      "        [-0.0414, -0.2209],\n",
      "        [-0.0217, -0.2602],\n",
      "        [-0.0040, -0.3175],\n",
      "        [-0.0329, -0.2176]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0157, -0.4079],\n",
      "        [-0.0327, -0.3201],\n",
      "        [-0.0086, -0.2961],\n",
      "        [-0.0107, -0.2857],\n",
      "        [-0.0103, -0.2973],\n",
      "        [-0.0192, -0.2708],\n",
      "        [-0.0138, -0.2846],\n",
      "        [-0.0024, -0.3471],\n",
      "        [-0.0103, -0.3100],\n",
      "        [-0.0304, -0.2885],\n",
      "        [-0.0189, -0.2753],\n",
      "        [-0.0134, -0.2987],\n",
      "        [-0.0090, -0.2889],\n",
      "        [-0.0504, -0.3405],\n",
      "        [-0.0504, -0.3405],\n",
      "        [-0.0161, -0.2807],\n",
      "        [-0.0123, -0.3017],\n",
      "        [-0.0079, -0.3036],\n",
      "        [-0.0090, -0.2942],\n",
      "        [-0.0110, -0.2976],\n",
      "        [-0.0169, -0.2723],\n",
      "        [-0.0112, -0.2942],\n",
      "        [-0.0057, -0.3201],\n",
      "        [-0.0176, -0.3143],\n",
      "        [-0.0116, -0.2883],\n",
      "        [-0.0145, -0.2794],\n",
      "        [-0.0115, -0.2923],\n",
      "        [-0.0140, -0.2815],\n",
      "        [-0.0218, -0.2528],\n",
      "        [-0.0098, -0.2820],\n",
      "        [-0.0237, -0.2314],\n",
      "        [-0.0084, -0.3080],\n",
      "        [-0.0274, -0.2521],\n",
      "        [-0.0193, -0.2557],\n",
      "        [-0.0262, -0.2494],\n",
      "        [-0.0317, -0.1951],\n",
      "        [-0.0317, -0.1951],\n",
      "        [-0.0175, -0.2626],\n",
      "        [-0.0135, -0.2623],\n",
      "        [-0.0337, -0.1806],\n",
      "        [-0.0337, -0.1806]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0316, -0.2330],\n",
      "        [-0.0164, -0.2549],\n",
      "        [-0.0337, -0.2078],\n",
      "        [-0.0310, -0.2083],\n",
      "        [-0.0367, -0.2000],\n",
      "        [-0.0213, -0.2492],\n",
      "        [-0.0394, -0.2173],\n",
      "        [-0.0394, -0.2173],\n",
      "        [-0.0262, -0.2478],\n",
      "        [-0.0117, -0.2861],\n",
      "        [-0.0218, -0.2605],\n",
      "        [-0.0161, -0.2645],\n",
      "        [-0.0240, -0.2465],\n",
      "        [-0.0306, -0.2351],\n",
      "        [-0.0154, -0.2685],\n",
      "        [-0.0235, -0.2453],\n",
      "        [-0.0155, -0.2544],\n",
      "        [-0.0218, -0.2330],\n",
      "        [-0.0294, -0.2326],\n",
      "        [-0.0291, -0.2169],\n",
      "        [-0.0239, -0.2217]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0208, -0.2186],\n",
      "        [-0.0233, -0.2148],\n",
      "        [-0.0208, -0.2186],\n",
      "        [-0.0233, -0.2148]], device='cuda:0')\n",
      "outpu is  tensor([[-2.1890e-02, -3.8478e-01],\n",
      "        [-7.3630e-03, -3.6907e-01],\n",
      "        [-7.3630e-03, -3.6907e-01],\n",
      "        [-7.3630e-03, -3.6907e-01],\n",
      "        [-6.7019e-04, -3.4560e-01],\n",
      "        [-1.4426e-04, -3.4830e-01],\n",
      "        [-2.3338e-02, -3.4120e-01],\n",
      "        [-2.4955e-02, -3.0674e-01],\n",
      "        [-3.4563e-03, -3.3565e-01],\n",
      "        [-3.8821e-03, -3.3840e-01],\n",
      "        [-1.4488e-02, -3.0583e-01],\n",
      "        [-1.2813e-02, -2.9749e-01],\n",
      "        [-1.2286e-02, -2.9278e-01],\n",
      "        [-2.8380e-02, -3.0159e-01],\n",
      "        [-3.4356e-02, -3.1632e-01]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0039, -0.3327],\n",
      "        [-0.0117, -0.3282],\n",
      "        [-0.0324, -0.3182],\n",
      "        [-0.0112, -0.3113],\n",
      "        [-0.0195, -0.2648],\n",
      "        [-0.0167, -0.2887],\n",
      "        [-0.0102, -0.2959],\n",
      "        [-0.0046, -0.3439],\n",
      "        [-0.0046, -0.3439],\n",
      "        [-0.0115, -0.2832],\n",
      "        [-0.0067, -0.3681],\n",
      "        [-0.0067, -0.3681],\n",
      "        [-0.0067, -0.3681],\n",
      "        [-0.0153, -0.2728]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0317, -0.1964],\n",
      "        [-0.0284, -0.2047],\n",
      "        [-0.0276, -0.2218],\n",
      "        [-0.0180, -0.2454],\n",
      "        [-0.0134, -0.2777],\n",
      "        [-0.0276, -0.2218],\n",
      "        [-0.0284, -0.2047],\n",
      "        [-0.0132, -0.2739],\n",
      "        [-0.0129, -0.2758],\n",
      "        [-0.0168, -0.2761],\n",
      "        [-0.0066, -0.3184],\n",
      "        [-0.0333, -0.3136],\n",
      "        [-0.0062, -0.3663],\n",
      "        [-0.0062, -0.3663],\n",
      "        [-0.0062, -0.3663],\n",
      "        [-0.0139, -0.2939]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0146, -0.2672],\n",
      "        [-0.0103, -0.2841],\n",
      "        [-0.0144, -0.2773],\n",
      "        [-0.0252, -0.2359],\n",
      "        [-0.0122, -0.2751],\n",
      "        [-0.0156, -0.2655],\n",
      "        [-0.0130, -0.2725],\n",
      "        [-0.0223, -0.2405],\n",
      "        [-0.0350, -0.2202],\n",
      "        [-0.0334, -0.2012],\n",
      "        [-0.0338, -0.2024],\n",
      "        [-0.0298, -0.2124]], device='cuda:0')\n",
      "outpu is  tensor([[-1.4825e-02, -3.2055e-01],\n",
      "        [ 1.4381e-04, -3.6314e-01],\n",
      "        [-6.2895e-03, -3.3333e-01],\n",
      "        [-1.0759e-02, -3.3227e-01],\n",
      "        [-2.7083e-02, -3.1652e-01],\n",
      "        [-2.7083e-02, -3.1652e-01],\n",
      "        [-2.5802e-02, -3.0693e-01],\n",
      "        [-1.9393e-02, -2.9941e-01],\n",
      "        [-1.7933e-03, -3.5642e-01],\n",
      "        [-7.6858e-03, -3.4523e-01],\n",
      "        [-2.1040e-02, -3.9690e-01],\n",
      "        [-7.6858e-03, -3.4523e-01],\n",
      "        [-2.1040e-02, -3.9690e-01],\n",
      "        [-1.6196e-02, -3.6777e-01],\n",
      "        [-1.3964e-02, -3.2930e-01],\n",
      "        [-1.2668e-02, -3.3081e-01],\n",
      "        [-4.9178e-02, -2.3706e-01],\n",
      "        [-5.1791e-02, -3.1587e-01],\n",
      "        [-1.2616e-02, -3.3261e-01],\n",
      "        [-3.3484e-02, -3.1482e-01],\n",
      "        [-3.0722e-02, -2.4388e-01],\n",
      "        [-6.2131e-03, -3.6655e-01],\n",
      "        [-6.2131e-03, -3.6655e-01],\n",
      "        [-6.2131e-03, -3.6655e-01]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0143, -0.2977],\n",
      "        [-0.0055, -0.3295],\n",
      "        [-0.0088, -0.2916],\n",
      "        [-0.0095, -0.3033],\n",
      "        [-0.0320, -0.3136],\n",
      "        [-0.0161, -0.2880],\n",
      "        [-0.0125, -0.2741],\n",
      "        [-0.0125, -0.2741],\n",
      "        [-0.0117, -0.2922],\n",
      "        [-0.0160, -0.4061],\n",
      "        [-0.0132, -0.2615],\n",
      "        [-0.0132, -0.2615],\n",
      "        [-0.0305, -0.2920],\n",
      "        [-0.0499, -0.3394],\n",
      "        [-0.0499, -0.3394],\n",
      "        [-0.0153, -0.2508],\n",
      "        [-0.0081, -0.3105],\n",
      "        [-0.0081, -0.3105],\n",
      "        [-0.0199, -0.2613],\n",
      "        [-0.0199, -0.2613],\n",
      "        [-0.0131, -0.2646],\n",
      "        [-0.0247, -0.2381]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0247, -0.2674],\n",
      "        [-0.0128, -0.3064],\n",
      "        [-0.0334, -0.2687],\n",
      "        [-0.0231, -0.3630],\n",
      "        [-0.0303, -0.2931],\n",
      "        [-0.0113, -0.3334],\n",
      "        [-0.0267, -0.2850],\n",
      "        [-0.0457, -0.2342],\n",
      "        [-0.0169, -0.3014]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0153, -0.3014],\n",
      "        [-0.0168, -0.3017],\n",
      "        [-0.0137, -0.3146],\n",
      "        [-0.0186, -0.2791],\n",
      "        [-0.0228, -0.2592],\n",
      "        [-0.0166, -0.3029],\n",
      "        [-0.0156, -0.3065],\n",
      "        [-0.0176, -0.2931],\n",
      "        [-0.0057, -0.3342],\n",
      "        [-0.0163, -0.2905],\n",
      "        [-0.0319, -0.2144],\n",
      "        [-0.0180, -0.2644],\n",
      "        [-0.0307, -0.2154],\n",
      "        [-0.0166, -0.2969],\n",
      "        [-0.0287, -0.2315],\n",
      "        [-0.0088, -0.3101],\n",
      "        [-0.0315, -0.1958],\n",
      "        [-0.0284, -0.2230],\n",
      "        [-0.0323, -0.2045],\n",
      "        [-0.0144, -0.2959],\n",
      "        [-0.0398, -0.1937],\n",
      "        [-0.0398, -0.1937],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0428, -0.1636],\n",
      "        [-0.0212, -0.2696],\n",
      "        [-0.0152, -0.2941],\n",
      "        [-0.0197, -0.2705],\n",
      "        [-0.0304, -0.2360],\n",
      "        [-0.0148, -0.2829],\n",
      "        [-0.0230, -0.2521],\n",
      "        [-0.0094, -0.3003],\n",
      "        [-0.0232, -0.2605],\n",
      "        [-0.0358, -0.2228],\n",
      "        [-0.0175, -0.2980],\n",
      "        [-0.0123, -0.2849],\n",
      "        [-0.0293, -0.2675],\n",
      "        [-0.0190, -0.3305],\n",
      "        [-0.0162, -0.2982],\n",
      "        [-0.0131, -0.2769],\n",
      "        [-0.0487, -0.3066],\n",
      "        [-0.0151, -0.3428],\n",
      "        [-0.0133, -0.2797],\n",
      "        [ 0.0238, -0.4608]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0262, -0.2478],\n",
      "        [-0.0117, -0.2861],\n",
      "        [-0.0164, -0.2549],\n",
      "        [-0.0213, -0.2492],\n",
      "        [-0.0218, -0.2605],\n",
      "        [-0.0194, -0.2584],\n",
      "        [-0.0152, -0.2741],\n",
      "        [-0.0155, -0.2687],\n",
      "        [-0.0159, -0.2637],\n",
      "        [-0.0161, -0.2645],\n",
      "        [-0.0240, -0.2464],\n",
      "        [-0.0240, -0.2465],\n",
      "        [-0.0117, -0.2760],\n",
      "        [-0.0337, -0.2078],\n",
      "        [-0.0367, -0.2000],\n",
      "        [-0.0316, -0.2330],\n",
      "        [-0.0394, -0.2173],\n",
      "        [-0.0394, -0.2173],\n",
      "        [-0.0310, -0.2083],\n",
      "        [-0.0305, -0.2350],\n",
      "        [-0.0306, -0.2351]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0228, -0.3395],\n",
      "        [-0.0155, -0.2937],\n",
      "        [-0.0269, -0.2319],\n",
      "        [-0.0086, -0.3153],\n",
      "        [-0.0096, -0.2973],\n",
      "        [-0.0214, -0.2498],\n",
      "        [-0.0280, -0.2506],\n",
      "        [-0.0233, -0.2699],\n",
      "        [-0.0282, -0.2080],\n",
      "        [-0.0274, -0.2142],\n",
      "        [-0.0279, -0.2290],\n",
      "        [-0.0312, -0.2225],\n",
      "        [-0.0330, -0.1869],\n",
      "        [-0.0333, -0.1877],\n",
      "        [-0.0240, -0.2541],\n",
      "        [-0.0334, -0.1796],\n",
      "        [-0.0334, -0.1797],\n",
      "        [-0.0298, -0.2328],\n",
      "        [-0.0116, -0.2958],\n",
      "        [-0.0270, -0.2389],\n",
      "        [-0.0259, -0.2712],\n",
      "        [-0.0240, -0.2439],\n",
      "        [-0.0399, -0.2530],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0098, -0.3078],\n",
      "        [-0.0128, -0.2891],\n",
      "        [-0.0285, -0.2758],\n",
      "        [-0.0087, -0.2905],\n",
      "        [-0.0117, -0.2834],\n",
      "        [-0.0081, -0.3015],\n",
      "        [-0.0081, -0.3015],\n",
      "        [-0.0111, -0.2871],\n",
      "        [-0.0200, -0.2708],\n",
      "        [-0.0131, -0.2761],\n",
      "        [-0.0164, -0.2606],\n",
      "        [-0.0164, -0.2606],\n",
      "        [-0.0132, -0.2754],\n",
      "        [-0.0153, -0.2521]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0333, -0.3135],\n",
      "        [-0.0062, -0.3663],\n",
      "        [-0.0062, -0.3663],\n",
      "        [-0.0062, -0.3663],\n",
      "        [-0.0110, -0.2706],\n",
      "        [-0.0293, -0.2256],\n",
      "        [-0.0279, -0.2152],\n",
      "        [-0.0405, -0.1882],\n",
      "        [-0.0358, -0.1859],\n",
      "        [-0.0323, -0.1872],\n",
      "        [-0.0384, -0.1680],\n",
      "        [-0.0174, -0.2580],\n",
      "        [-0.0185, -0.2781],\n",
      "        [-0.0125, -0.2736],\n",
      "        [-0.0062, -0.3166],\n",
      "        [-0.0168, -0.2756]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0189, -0.2306],\n",
      "        [-0.0232, -0.2543],\n",
      "        [-0.0047, -0.2950],\n",
      "        [-0.0308, -0.2002],\n",
      "        [-0.0308, -0.2002],\n",
      "        [-0.0320, -0.1850],\n",
      "        [-0.0320, -0.1850]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0079, -0.3034],\n",
      "        [-0.0114, -0.2949],\n",
      "        [-0.0119, -0.2979],\n",
      "        [-0.0181, -0.2737],\n",
      "        [-0.0072, -0.3065],\n",
      "        [-0.0109, -0.2829],\n",
      "        [-0.0076, -0.3138],\n",
      "        [-0.0193, -0.2633],\n",
      "        [-0.0111, -0.2762],\n",
      "        [-0.0115, -0.2841],\n",
      "        [-0.0141, -0.2645],\n",
      "        [-0.0277, -0.2226],\n",
      "        [-0.0156, -0.2708],\n",
      "        [-0.0156, -0.2708],\n",
      "        [-0.0140, -0.2647],\n",
      "        [-0.0306, -0.2093],\n",
      "        [-0.0306, -0.2093],\n",
      "        [-0.0099, -0.2953],\n",
      "        [-0.0099, -0.2953],\n",
      "        [-0.0302, -0.2084],\n",
      "        [-0.0302, -0.2084],\n",
      "        [-0.0138, -0.2947],\n",
      "        [-0.0259, -0.2197],\n",
      "        [-0.0038, -0.3267],\n",
      "        [-0.0279, -0.2194],\n",
      "        [-0.0253, -0.2368],\n",
      "        [-0.0144, -0.2564],\n",
      "        [-0.0145, -0.2677],\n",
      "        [-0.0145, -0.2677],\n",
      "        [-0.0101, -0.2826],\n",
      "        [-0.0101, -0.2826],\n",
      "        [-0.0152, -0.2710],\n",
      "        [-0.0096, -0.2753],\n",
      "        [-0.0252, -0.2470]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0017, -0.3349],\n",
      "        [-0.0028, -0.3372],\n",
      "        [-0.0180, -0.2822],\n",
      "        [-0.0179, -0.2816],\n",
      "        [-0.0094, -0.3102],\n",
      "        [-0.0065, -0.3169],\n",
      "        [-0.0098, -0.3110],\n",
      "        [-0.0060, -0.3160],\n",
      "        [-0.0102, -0.2871],\n",
      "        [-0.0089, -0.2953],\n",
      "        [-0.0066, -0.3248],\n",
      "        [-0.0118, -0.2711],\n",
      "        [-0.0100, -0.2967],\n",
      "        [-0.0156, -0.2711],\n",
      "        [-0.0121, -0.2866],\n",
      "        [-0.0198, -0.2762],\n",
      "        [-0.0167, -0.2677],\n",
      "        [-0.0198, -0.2695],\n",
      "        [-0.0129, -0.2759],\n",
      "        [-0.0220, -0.2526],\n",
      "        [-0.0091, -0.3044]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0044, -0.3380],\n",
      "        [-0.0272, -0.3031],\n",
      "        [-0.0139, -0.3006],\n",
      "        [-0.0064, -0.3424],\n",
      "        [-0.0156, -0.3858],\n",
      "        [-0.0132, -0.3267],\n",
      "        [-0.0136, -0.3026],\n",
      "        [-0.0149, -0.2703],\n",
      "        [-0.0283, -0.2992],\n",
      "        [-0.0266, -0.2959],\n",
      "        [-0.0135, -0.3246],\n",
      "        [-0.0062, -0.3199],\n",
      "        [-0.0248, -0.2438],\n",
      "        [-0.0169, -0.3842],\n",
      "        [-0.0088, -0.3098],\n",
      "        [-0.0161, -0.2738],\n",
      "        [-0.0306, -0.2119],\n",
      "        [-0.0173, -0.2636],\n",
      "        [-0.0140, -0.2647],\n",
      "        [-0.0242, -0.2280],\n",
      "        [-0.0402, -0.1942],\n",
      "        [-0.0402, -0.1942]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0259, -0.2492],\n",
      "        [-0.0268, -0.2466],\n",
      "        [-0.0263, -0.2302],\n",
      "        [-0.0156, -0.2741],\n",
      "        [-0.0209, -0.2692],\n",
      "        [-0.0177, -0.2597],\n",
      "        [-0.0360, -0.2015],\n",
      "        [-0.0288, -0.2242],\n",
      "        [-0.0244, -0.2657],\n",
      "        [-0.0228, -0.2662],\n",
      "        [-0.0184, -0.2698],\n",
      "        [-0.0362, -0.2256],\n",
      "        [-0.0279, -0.2222],\n",
      "        [-0.0175, -0.2482],\n",
      "        [-0.0227, -0.2627],\n",
      "        [-0.0203, -0.2597],\n",
      "        [-0.0106, -0.2945],\n",
      "        [-0.0145, -0.2778],\n",
      "        [-0.0235, -0.2478],\n",
      "        [-0.0395, -0.1911],\n",
      "        [-0.0193, -0.2433],\n",
      "        [-0.0273, -0.2423],\n",
      "        [-0.0247, -0.2501],\n",
      "        [-0.0247, -0.2494],\n",
      "        [-0.0229, -0.2539],\n",
      "        [-0.0124, -0.2945],\n",
      "        [-0.0294, -0.2273],\n",
      "        [-0.0103, -0.2907],\n",
      "        [-0.0183, -0.2533],\n",
      "        [-0.0175, -0.2700],\n",
      "        [-0.0250, -0.2539],\n",
      "        [-0.0224, -0.2458],\n",
      "        [-0.0333, -0.2223],\n",
      "        [-0.0249, -0.2377],\n",
      "        [-0.0336, -0.1922],\n",
      "        [-0.0197, -0.2448],\n",
      "        [-0.0096, -0.2986],\n",
      "        [-0.0186, -0.2670],\n",
      "        [-0.0392, -0.2090],\n",
      "        [-0.0392, -0.2090],\n",
      "        [-0.0321, -0.2112],\n",
      "        [-0.0372, -0.2032],\n",
      "        [-0.0222, -0.2326],\n",
      "        [-0.0218, -0.2717],\n",
      "        [-0.0175, -0.2792],\n",
      "        [-0.0216, -0.2676],\n",
      "        [-0.0218, -0.2311],\n",
      "        [-0.0277, -0.2543],\n",
      "        [-0.0234, -0.2521],\n",
      "        [-0.0188, -0.2754],\n",
      "        [-0.0237, -0.2532],\n",
      "        [-0.0255, -0.2600],\n",
      "        [-0.0250, -0.2659],\n",
      "        [-0.0350, -0.2401],\n",
      "        [-0.0340, -0.2228],\n",
      "        [-0.0124, -0.2853],\n",
      "        [-0.0087, -0.3054],\n",
      "        [-0.0153, -0.2789],\n",
      "        [-0.0224, -0.2737],\n",
      "        [-0.0181, -0.2813],\n",
      "        [-0.0295, -0.2276],\n",
      "        [-0.0104, -0.2912],\n",
      "        [-0.0336, -0.1922]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0128, -0.2749],\n",
      "        [-0.0128, -0.2741],\n",
      "        [-0.0133, -0.2788],\n",
      "        [-0.0105, -0.2930],\n",
      "        [-0.0130, -0.2827],\n",
      "        [-0.0141, -0.2747],\n",
      "        [-0.0101, -0.2767],\n",
      "        [-0.0252, -0.2473],\n",
      "        [-0.0191, -0.2627],\n",
      "        [-0.0289, -0.2196],\n",
      "        [-0.0335, -0.1938],\n",
      "        [-0.0340, -0.1826],\n",
      "        [-0.0323, -0.1975],\n",
      "        [-0.0248, -0.2347],\n",
      "        [-0.0217, -0.2707],\n",
      "        [-0.0339, -0.2128],\n",
      "        [-0.0227, -0.2332],\n",
      "        [-0.0411, -0.1962],\n",
      "        [-0.0411, -0.1962]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0390, -0.1504],\n",
      "        [-0.0353, -0.1661],\n",
      "        [-0.0339, -0.1834],\n",
      "        [-0.0304, -0.2042],\n",
      "        [-0.0239, -0.2309],\n",
      "        [-0.0307, -0.2050],\n",
      "        [-0.0337, -0.1915],\n",
      "        [-0.0339, -0.1839],\n",
      "        [-0.0297, -0.2117],\n",
      "        [-0.0244, -0.2446],\n",
      "        [-0.0114, -0.2991],\n",
      "        [-0.0156, -0.2947],\n",
      "        [-0.0123, -0.3013],\n",
      "        [-0.0166, -0.2759],\n",
      "        [-0.0099, -0.2778],\n",
      "        [-0.0224, -0.2545],\n",
      "        [-0.0174, -0.2581],\n",
      "        [-0.0122, -0.2707],\n",
      "        [-0.0174, -0.2581],\n",
      "        [-0.0099, -0.2778],\n",
      "        [-0.0224, -0.2545]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0091, -0.3017],\n",
      "        [-0.0071, -0.3034],\n",
      "        [-0.0125, -0.2677],\n",
      "        [-0.0067, -0.3150],\n",
      "        [-0.0113, -0.2982],\n",
      "        [-0.0134, -0.2776],\n",
      "        [-0.0152, -0.2643],\n",
      "        [-0.0294, -0.2202],\n",
      "        [-0.0105, -0.2959],\n",
      "        [-0.0127, -0.2740],\n",
      "        [-0.0331, -0.1905],\n",
      "        [-0.0221, -0.2587],\n",
      "        [-0.0261, -0.2394],\n",
      "        [-0.0229, -0.2470],\n",
      "        [-0.0331, -0.2163],\n",
      "        [-0.0238, -0.2333],\n",
      "        [-0.0436, -0.1972],\n",
      "        [-0.0436, -0.1972],\n",
      "        [-0.0436, -0.1972]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0088, -0.3058],\n",
      "        [-0.0200, -0.2559],\n",
      "        [-0.0081, -0.3125],\n",
      "        [-0.0065, -0.3280],\n",
      "        [-0.0123, -0.2685],\n",
      "        [-0.0323, -0.2079],\n",
      "        [-0.0088, -0.3034],\n",
      "        [-0.0076, -0.3190],\n",
      "        [-0.0042, -0.3301],\n",
      "        [-0.0013, -0.3420],\n",
      "        [-0.0150, -0.2629],\n",
      "        [-0.0150, -0.2629],\n",
      "        [-0.0391, -0.1739],\n",
      "        [-0.0068, -0.3095],\n",
      "        [-0.0109, -0.2837],\n",
      "        [-0.0130, -0.2604],\n",
      "        [-0.0130, -0.2604],\n",
      "        [-0.0111, -0.2852],\n",
      "        [-0.0142, -0.2646],\n",
      "        [-0.0152, -0.2507],\n",
      "        [-0.0140, -0.2647]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0092, -0.3043],\n",
      "        [-0.0073, -0.3119],\n",
      "        [-0.0089, -0.3092],\n",
      "        [-0.0084, -0.3062],\n",
      "        [-0.0117, -0.2907],\n",
      "        [-0.0112, -0.2893],\n",
      "        [-0.0089, -0.2950],\n",
      "        [-0.0128, -0.2769],\n",
      "        [-0.0128, -0.2753],\n",
      "        [-0.0128, -0.2769],\n",
      "        [-0.0089, -0.2952],\n",
      "        [-0.0116, -0.2905],\n",
      "        [-0.0104, -0.2987],\n",
      "        [-0.0077, -0.3096],\n",
      "        [-0.0070, -0.3153],\n",
      "        [-0.0077, -0.3085],\n",
      "        [-0.0088, -0.3084],\n",
      "        [-0.0086, -0.3013],\n",
      "        [-0.0120, -0.2902],\n",
      "        [-0.0098, -0.2979],\n",
      "        [-0.0065, -0.3174],\n",
      "        [-0.0100, -0.3002]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0168, -0.2723],\n",
      "        [-0.0115, -0.3075],\n",
      "        [-0.0086, -0.3105],\n",
      "        [-0.0226, -0.2753],\n",
      "        [-0.0230, -0.2477],\n",
      "        [-0.0142, -0.2943],\n",
      "        [-0.0109, -0.3129],\n",
      "        [-0.0133, -0.2901],\n",
      "        [-0.0119, -0.2911],\n",
      "        [ 0.0012, -0.3379],\n",
      "        [-0.0012, -0.3366],\n",
      "        [-0.0175, -0.2797],\n",
      "        [-0.0067, -0.3142],\n",
      "        [-0.0205, -0.2665],\n",
      "        [-0.0226, -0.2700],\n",
      "        [-0.0054, -0.3205],\n",
      "        [-0.0151, -0.2895],\n",
      "        [-0.0240, -0.2707],\n",
      "        [-0.0160, -0.2881],\n",
      "        [-0.0183, -0.2756],\n",
      "        [-0.0204, -0.2863],\n",
      "        [-0.0270, -0.2532],\n",
      "        [-0.0207, -0.2723],\n",
      "        [-0.0263, -0.2464],\n",
      "        [-0.0271, -0.2484],\n",
      "        [-0.0198, -0.2728],\n",
      "        [-0.0289, -0.2615],\n",
      "        [-0.0153, -0.3004],\n",
      "        [-0.0245, -0.2639],\n",
      "        [-0.0222, -0.2721],\n",
      "        [-0.0314, -0.2520],\n",
      "        [-0.0141, -0.3049],\n",
      "        [-0.0211, -0.2726],\n",
      "        [-0.0147, -0.2759],\n",
      "        [-0.0345, -0.2413],\n",
      "        [-0.0345, -0.2413],\n",
      "        [-0.0282, -0.2516],\n",
      "        [-0.0167, -0.3014],\n",
      "        [-0.0128, -0.3108],\n",
      "        [-0.0104, -0.3006],\n",
      "        [-0.0140, -0.2995],\n",
      "        [-0.0084, -0.2951],\n",
      "        [-0.0201, -0.2743],\n",
      "        [-0.0218, -0.2722],\n",
      "        [-0.0275, -0.2498],\n",
      "        [-0.0132, -0.2731],\n",
      "        [-0.0132, -0.2731],\n",
      "        [-0.0305, -0.2481],\n",
      "        [-0.0233, -0.2388],\n",
      "        [-0.0134, -0.2617],\n",
      "        [-0.0134, -0.2617],\n",
      "        [-0.0152, -0.2509],\n",
      "        [-0.0434, -0.2001],\n",
      "        [-0.0434, -0.2001],\n",
      "        [-0.0434, -0.2001],\n",
      "        [-0.0113, -0.3086],\n",
      "        [-0.0205, -0.2551],\n",
      "        [-0.0436, -0.2092],\n",
      "        [-0.0436, -0.2092],\n",
      "        [-0.0436, -0.2092]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0143, -0.2744],\n",
      "        [-0.0294, -0.2345],\n",
      "        [-0.0220, -0.2552],\n",
      "        [-0.0133, -0.2782],\n",
      "        [-0.0133, -0.2782],\n",
      "        [-0.0297, -0.2145],\n",
      "        [-0.0182, -0.2707],\n",
      "        [-0.0325, -0.2082],\n",
      "        [-0.0133, -0.2721],\n",
      "        [-0.0133, -0.2721],\n",
      "        [-0.0133, -0.2721],\n",
      "        [-0.0133, -0.2721],\n",
      "        [-0.0314, -0.2025],\n",
      "        [-0.0397, -0.1874],\n",
      "        [-0.0097, -0.2988],\n",
      "        [-0.0133, -0.2617],\n",
      "        [-0.0133, -0.2617],\n",
      "        [-0.0133, -0.2617],\n",
      "        [-0.0133, -0.2617],\n",
      "        [-0.0338, -0.1910],\n",
      "        [-0.0152, -0.2510],\n",
      "        [-0.0152, -0.2510],\n",
      "        [-0.0175, -0.2792],\n",
      "        [-0.0381, -0.1742],\n",
      "        [-0.0218, -0.2717]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0146, -0.2842],\n",
      "        [-0.0104, -0.2933],\n",
      "        [-0.0092, -0.2969],\n",
      "        [-0.0126, -0.2751],\n",
      "        [-0.0137, -0.2634],\n",
      "        [-0.0141, -0.2643],\n",
      "        [-0.0109, -0.2824],\n",
      "        [-0.0097, -0.3103],\n",
      "        [-0.0069, -0.3156],\n",
      "        [-0.0065, -0.3211],\n",
      "        [-0.0249, -0.2367],\n",
      "        [-0.0304, -0.2166],\n",
      "        [-0.0306, -0.2092],\n",
      "        [-0.0252, -0.2179],\n",
      "        [-0.0306, -0.2092],\n",
      "        [-0.0304, -0.2166],\n",
      "        [-0.0321, -0.1986],\n",
      "        [-0.0343, -0.2020],\n",
      "        [-0.0292, -0.2146],\n",
      "        [-0.0200, -0.2499],\n",
      "        [-0.0129, -0.2709],\n",
      "        [-0.0129, -0.2709],\n",
      "        [-0.0139, -0.2779],\n",
      "        [-0.0101, -0.2963],\n",
      "        [-0.0137, -0.2949],\n",
      "        [-0.0101, -0.2963],\n",
      "        [-0.0139, -0.2779],\n",
      "        [-0.0038, -0.3267],\n",
      "        [-0.0139, -0.2779],\n",
      "        [-0.0101, -0.2963],\n",
      "        [-0.0137, -0.2949],\n",
      "        [-0.0101, -0.2963],\n",
      "        [-0.0139, -0.2779],\n",
      "        [-0.0038, -0.3267]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0078, -0.3918],\n",
      "        [-0.0203, -0.3627],\n",
      "        [-0.0203, -0.3627],\n",
      "        [-0.0203, -0.3627],\n",
      "        [-0.0662, -0.3386],\n",
      "        [ 0.0315, -0.4850],\n",
      "        [ 0.0459, -0.5229]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0292, -0.2817],\n",
      "        [-0.0158, -0.3661],\n",
      "        [-0.0084, -0.3031],\n",
      "        [-0.0164, -0.2605],\n",
      "        [-0.0153, -0.2521],\n",
      "        [-0.0164, -0.2605],\n",
      "        [-0.0084, -0.3031],\n",
      "        [-0.0452, -0.2516],\n",
      "        [-0.0356, -0.2673],\n",
      "        [-0.0228, -0.2754],\n",
      "        [-0.0118, -0.3098],\n",
      "        [-0.0106, -0.3131],\n",
      "        [-0.0106, -0.3131],\n",
      "        [-0.0118, -0.3098],\n",
      "        [-0.0102, -0.2931],\n",
      "        [-0.0102, -0.2931],\n",
      "        [-0.0130, -0.2738],\n",
      "        [-0.0132, -0.2617],\n",
      "        [-0.0154, -0.2509],\n",
      "        [-0.0132, -0.2617],\n",
      "        [-0.0130, -0.2738],\n",
      "        [-0.0130, -0.2738],\n",
      "        [-0.0132, -0.2617],\n",
      "        [-0.0154, -0.2509],\n",
      "        [-0.0132, -0.2617],\n",
      "        [-0.0130, -0.2738],\n",
      "        [-0.0107, -0.3146],\n",
      "        [-0.0107, -0.3146],\n",
      "        [-0.0515, -0.3153]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0306, -0.2921],\n",
      "        [-0.0161, -0.4070],\n",
      "        [-0.0082, -0.3121],\n",
      "        [-0.0082, -0.3121],\n",
      "        [-0.0310, -0.3191],\n",
      "        [-0.0499, -0.3396],\n",
      "        [-0.0499, -0.3396],\n",
      "        [-0.0179, -0.2692],\n",
      "        [-0.0179, -0.2692],\n",
      "        [-0.0018, -0.3364],\n",
      "        [-0.0116, -0.2747],\n",
      "        [-0.0149, -0.2927],\n",
      "        [-0.0149, -0.2927],\n",
      "        [-0.0186, -0.2620],\n",
      "        [-0.0121, -0.2801],\n",
      "        [-0.0121, -0.2801],\n",
      "        [-0.0144, -0.2752]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0061, -0.3124],\n",
      "        [-0.0081, -0.3068],\n",
      "        [-0.0114, -0.2874],\n",
      "        [-0.0140, -0.2592],\n",
      "        [-0.0250, -0.2226],\n",
      "        [-0.0315, -0.1912],\n",
      "        [-0.0341, -0.1688],\n",
      "        [-0.0350, -0.1602],\n",
      "        [-0.0353, -0.1629],\n",
      "        [-0.0391, -0.1496],\n",
      "        [-0.0113, -0.2873],\n",
      "        [-0.0106, -0.2881],\n",
      "        [-0.0106, -0.2915],\n",
      "        [-0.0110, -0.2890],\n",
      "        [-0.0100, -0.3002],\n",
      "        [-0.0058, -0.3171],\n",
      "        [-0.0047, -0.3220],\n",
      "        [-0.0063, -0.3203]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0256, -0.2327],\n",
      "        [-0.0316, -0.2101],\n",
      "        [-0.0114, -0.2802],\n",
      "        [-0.0367, -0.1894],\n",
      "        [-0.0134, -0.2801],\n",
      "        [-0.0134, -0.2801],\n",
      "        [-0.0235, -0.2254],\n",
      "        [-0.0125, -0.2685],\n",
      "        [-0.0110, -0.2803],\n",
      "        [-0.0125, -0.2685],\n",
      "        [-0.0110, -0.2803],\n",
      "        [-0.0403, -0.1938],\n",
      "        [-0.0403, -0.1938],\n",
      "        [-0.0240, -0.2462],\n",
      "        [-0.0146, -0.2629],\n",
      "        [-0.0141, -0.2642],\n",
      "        [-0.0240, -0.2462],\n",
      "        [-0.0146, -0.2629],\n",
      "        [-0.0141, -0.2642],\n",
      "        [-0.0137, -0.2622],\n",
      "        [-0.0137, -0.2622]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0118, -0.3006],\n",
      "        [-0.0071, -0.3161],\n",
      "        [-0.0118, -0.3006],\n",
      "        [-0.0078, -0.3051],\n",
      "        [-0.0118, -0.2905],\n",
      "        [-0.0112, -0.2893],\n",
      "        [-0.0089, -0.2950],\n",
      "        [-0.0128, -0.2769],\n",
      "        [-0.0128, -0.2753],\n",
      "        [-0.0128, -0.2769],\n",
      "        [-0.0089, -0.2950],\n",
      "        [-0.0112, -0.2893],\n",
      "        [-0.0118, -0.2905],\n",
      "        [-0.0078, -0.3051],\n",
      "        [-0.0083, -0.3097],\n",
      "        [-0.0075, -0.3080],\n",
      "        [-0.0138, -0.3228],\n",
      "        [-0.0040, -0.3429],\n",
      "        [-0.0040, -0.3429]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0128, -0.2827],\n",
      "        [-0.0216, -0.2609],\n",
      "        [-0.0128, -0.2827],\n",
      "        [-0.0057, -0.3260],\n",
      "        [-0.0259, -0.2986],\n",
      "        [-0.0193, -0.3871],\n",
      "        [-0.0099, -0.3094],\n",
      "        [-0.0220, -0.2781],\n",
      "        [-0.0157, -0.2764],\n",
      "        [-0.0156, -0.2715],\n",
      "        [-0.0156, -0.2715],\n",
      "        [-0.0157, -0.2764],\n",
      "        [-0.0099, -0.3094],\n",
      "        [-0.0220, -0.2781],\n",
      "        [-0.0259, -0.2986],\n",
      "        [-0.0193, -0.3871],\n",
      "        [-0.0057, -0.3260]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0148, -0.2704],\n",
      "        [-0.0207, -0.2656],\n",
      "        [-0.0121, -0.2704],\n",
      "        [-0.0132, -0.2711],\n",
      "        [-0.0229, -0.2508],\n",
      "        [-0.0176, -0.2767],\n",
      "        [-0.0243, -0.2498],\n",
      "        [-0.0151, -0.2632],\n",
      "        [-0.0138, -0.2630],\n",
      "        [-0.0282, -0.2337],\n",
      "        [-0.0176, -0.2796],\n",
      "        [-0.0136, -0.2622],\n",
      "        [-0.0236, -0.2502],\n",
      "        [-0.0131, -0.2904],\n",
      "        [-0.0258, -0.2406],\n",
      "        [-0.0331, -0.2172],\n",
      "        [-0.0120, -0.2622],\n",
      "        [-0.0266, -0.2338],\n",
      "        [-0.0164, -0.2545],\n",
      "        [-0.0164, -0.2545],\n",
      "        [-0.0311, -0.2243],\n",
      "        [-0.0308, -0.2167],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0233, -0.2430],\n",
      "        [-0.0153, -0.2503],\n",
      "        [-0.0225, -0.2616],\n",
      "        [-0.0285, -0.2291],\n",
      "        [-0.0287, -0.2409],\n",
      "        [-0.0120, -0.2962],\n",
      "        [-0.0301, -0.2234],\n",
      "        [-0.0232, -0.2447],\n",
      "        [-0.0280, -0.2507],\n",
      "        [-0.0155, -0.2940],\n",
      "        [-0.0272, -0.2427],\n",
      "        [-0.0240, -0.2439],\n",
      "        [-0.0108, -0.2772],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0443, -0.1998],\n",
      "        [-0.0175, -0.2581],\n",
      "        [-0.0164, -0.2701],\n",
      "        [-0.0128, -0.2715],\n",
      "        [-0.0099, -0.2830],\n",
      "        [-0.0146, -0.2669]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0284, -0.2318],\n",
      "        [-0.0190, -0.2608],\n",
      "        [-0.0308, -0.2325],\n",
      "        [-0.0186, -0.2450],\n",
      "        [-0.0381, -0.2049],\n",
      "        [-0.0143, -0.2709],\n",
      "        [-0.0135, -0.2785],\n",
      "        [-0.0142, -0.2861],\n",
      "        [-0.0078, -0.3131],\n",
      "        [-0.0142, -0.2861],\n",
      "        [-0.0135, -0.2785],\n",
      "        [-0.0330, -0.3131],\n",
      "        [-0.0061, -0.3661],\n",
      "        [-0.0061, -0.3661],\n",
      "        [-0.0061, -0.3661],\n",
      "        [-0.0283, -0.2327],\n",
      "        [-0.0371, -0.2035],\n",
      "        [-0.0298, -0.2292],\n",
      "        [-0.0264, -0.2349],\n",
      "        [-0.0233, -0.2393],\n",
      "        [-0.0348, -0.2232],\n",
      "        [-0.0272, -0.2361],\n",
      "        [-0.0272, -0.2361],\n",
      "        [-0.0293, -0.2238],\n",
      "        [-0.0270, -0.2364],\n",
      "        [-0.0178, -0.2610],\n",
      "        [-0.0270, -0.2364],\n",
      "        [-0.0293, -0.2238],\n",
      "        [-0.0117, -0.3061],\n",
      "        [-0.0138, -0.2953],\n",
      "        [-0.0033, -0.3328],\n",
      "        [-0.0081, -0.2980],\n",
      "        [-0.0208, -0.2720],\n",
      "        [-0.0142, -0.2922],\n",
      "        [-0.0075, -0.3018],\n",
      "        [-0.0142, -0.2922],\n",
      "        [-0.0081, -0.2980],\n",
      "        [-0.0208, -0.2720]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0089, -0.2937],\n",
      "        [-0.0114, -0.2900],\n",
      "        [-0.0093, -0.2800],\n",
      "        [-0.0315, -0.2003],\n",
      "        [-0.0094, -0.2867],\n",
      "        [-0.0254, -0.2341],\n",
      "        [-0.0256, -0.2438],\n",
      "        [-0.0303, -0.2120],\n",
      "        [-0.0307, -0.2159],\n",
      "        [-0.0305, -0.2002],\n",
      "        [-0.0130, -0.2760],\n",
      "        [-0.0114, -0.2836],\n",
      "        [-0.0108, -0.2825],\n",
      "        [-0.0126, -0.2759],\n",
      "        [-0.0121, -0.2740],\n",
      "        [-0.0420, -0.1730],\n",
      "        [-0.0420, -0.1730],\n",
      "        [-0.0141, -0.2644],\n",
      "        [-0.0138, -0.2634]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0122, -0.2871],\n",
      "        [-0.0107, -0.2823],\n",
      "        [-0.0164, -0.3034],\n",
      "        [-0.0130, -0.2730],\n",
      "        [-0.0168, -0.2823],\n",
      "        [-0.0156, -0.2644],\n",
      "        [-0.0050, -0.3478],\n",
      "        [-0.0137, -0.2631],\n",
      "        [-0.0117, -0.2981],\n",
      "        [-0.0137, -0.2622],\n",
      "        [-0.0270, -0.3029],\n",
      "        [-0.0270, -0.3029],\n",
      "        [-0.0103, -0.2894],\n",
      "        [-0.0127, -0.2955],\n",
      "        [-0.0098, -0.3157],\n",
      "        [-0.0197, -0.3892],\n",
      "        [-0.0098, -0.3157],\n",
      "        [-0.0197, -0.3892],\n",
      "        [-0.0217, -0.2746],\n",
      "        [-0.0203, -0.2756],\n",
      "        [-0.0088, -0.3041],\n",
      "        [-0.0183, -0.2807],\n",
      "        [-0.0182, -0.2799]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0276, -0.2292],\n",
      "        [-0.0248, -0.2611],\n",
      "        [-0.0335, -0.3143],\n",
      "        [-0.0335, -0.3143],\n",
      "        [-0.0199, -0.2620],\n",
      "        [-0.0068, -0.3257],\n",
      "        [-0.0068, -0.3257],\n",
      "        [-0.0181, -0.2661],\n",
      "        [-0.0124, -0.2833],\n",
      "        [-0.0187, -0.2985],\n",
      "        [-0.0175, -0.2885],\n",
      "        [-0.0175, -0.2885],\n",
      "        [-0.0170, -0.2563],\n",
      "        [-0.0220, -0.2598],\n",
      "        [-0.0144, -0.2710],\n",
      "        [-0.0062, -0.3665],\n",
      "        [-0.0062, -0.3665],\n",
      "        [-0.0062, -0.3665],\n",
      "        [-0.0062, -0.3665],\n",
      "        [-0.0062, -0.3665],\n",
      "        [-0.0062, -0.3665],\n",
      "        [-0.0137, -0.2782],\n",
      "        [-0.0137, -0.2782],\n",
      "        [-0.0307, -0.2207],\n",
      "        [-0.0137, -0.2949],\n",
      "        [-0.0306, -0.2235],\n",
      "        [-0.0101, -0.2963],\n",
      "        [-0.0101, -0.2963],\n",
      "        [-0.0038, -0.3267],\n",
      "        [-0.0297, -0.2357]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0100, -0.3024],\n",
      "        [-0.0123, -0.2975],\n",
      "        [-0.0132, -0.2748],\n",
      "        [-0.0137, -0.2637],\n",
      "        [-0.0141, -0.2646],\n",
      "        [-0.0117, -0.2831],\n",
      "        [-0.0069, -0.3209],\n",
      "        [-0.0152, -0.3010],\n",
      "        [-0.0176, -0.2600],\n",
      "        [-0.0031, -0.3400],\n",
      "        [-0.0258, -0.3054],\n",
      "        [-0.0052, -0.3359],\n",
      "        [-0.0070, -0.3314],\n",
      "        [-0.0303, -0.2883],\n",
      "        [-0.0169, -0.3138],\n",
      "        [-0.0159, -0.3761],\n",
      "        [-0.0272, -0.2346],\n",
      "        [-0.0296, -0.2147],\n",
      "        [-0.0255, -0.2276],\n",
      "        [-0.0372, -0.2037],\n",
      "        [-0.0296, -0.2147],\n",
      "        [-0.0272, -0.2346]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0119, -0.2825],\n",
      "        [-0.0224, -0.2533],\n",
      "        [-0.0123, -0.2934],\n",
      "        [-0.0096, -0.2926],\n",
      "        [-0.0117, -0.2842],\n",
      "        [-0.0130, -0.2765],\n",
      "        [-0.0143, -0.2748],\n",
      "        [-0.0095, -0.2920],\n",
      "        [-0.0141, -0.2693],\n",
      "        [-0.0165, -0.2760],\n",
      "        [-0.0287, -0.2190],\n",
      "        [-0.0337, -0.1887],\n",
      "        [-0.0240, -0.2579],\n",
      "        [-0.0259, -0.2407],\n",
      "        [-0.0350, -0.2230],\n",
      "        [-0.0231, -0.2454],\n",
      "        [-0.0368, -0.2172],\n",
      "        [-0.0294, -0.2616],\n",
      "        [-0.0354, -0.2210],\n",
      "        [-0.0456, -0.2744],\n",
      "        [-0.0130, -0.3912],\n",
      "        [-0.0413, -0.2457],\n",
      "        [-0.0528, -0.3347],\n",
      "        [-0.0528, -0.3347],\n",
      "        [-0.0284, -0.2338],\n",
      "        [-0.0284, -0.2338],\n",
      "        [-0.0377, -0.1916],\n",
      "        [-0.0377, -0.1916]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0203, -0.2691],\n",
      "        [-0.0291, -0.2424],\n",
      "        [-0.0201, -0.2681],\n",
      "        [-0.0154, -0.2875],\n",
      "        [-0.0072, -0.3063],\n",
      "        [-0.0157, -0.2802],\n",
      "        [-0.0115, -0.2721],\n",
      "        [-0.0139, -0.2896],\n",
      "        [-0.0063, -0.3135],\n",
      "        [-0.0202, -0.2798],\n",
      "        [-0.0317, -0.2329],\n",
      "        [-0.0200, -0.2490],\n",
      "        [-0.0267, -0.2369],\n",
      "        [-0.0217, -0.2581],\n",
      "        [-0.0112, -0.3021],\n",
      "        [-0.0281, -0.2166],\n",
      "        [-0.0318, -0.1885],\n",
      "        [-0.0361, -0.1626],\n",
      "        [-0.0353, -0.1632],\n",
      "        [-0.0391, -0.1496],\n",
      "        [-0.0353, -0.2192],\n",
      "        [-0.0380, -0.2303],\n",
      "        [-0.0380, -0.2303],\n",
      "        [-0.0232, -0.2486]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0188, -0.2964],\n",
      "        [-0.0125, -0.3100],\n",
      "        [-0.0199, -0.2735],\n",
      "        [-0.0036, -0.3319],\n",
      "        [-0.0131, -0.2923],\n",
      "        [-0.0106, -0.2997],\n",
      "        [-0.0048, -0.3392],\n",
      "        [-0.0291, -0.2424],\n",
      "        [-0.0239, -0.2733],\n",
      "        [-0.0265, -0.3018],\n",
      "        [-0.0155, -0.2823],\n",
      "        [-0.0309, -0.2453],\n",
      "        [-0.0176, -0.2885],\n",
      "        [-0.0161, -0.2875],\n",
      "        [-0.0281, -0.2986],\n",
      "        [-0.0371, -0.2053],\n",
      "        [-0.0110, -0.3044],\n",
      "        [-0.0091, -0.3126],\n",
      "        [-0.0196, -0.3893],\n",
      "        [-0.0144, -0.2662],\n",
      "        [-0.0094, -0.3183],\n",
      "        [-0.0169, -0.3841],\n",
      "        [-0.0208, -0.2786],\n",
      "        [-0.0177, -0.2638]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0138, -0.2961],\n",
      "        [-0.0099, -0.3200],\n",
      "        [-0.0281, -0.2986],\n",
      "        [-0.0169, -0.3842],\n",
      "        [-0.0037, -0.3378],\n",
      "        [-0.0119, -0.3028],\n",
      "        [-0.0089, -0.3037],\n",
      "        [-0.0138, -0.2813],\n",
      "        [-0.0246, -0.2322],\n",
      "        [-0.0098, -0.3027],\n",
      "        [-0.0096, -0.3039],\n",
      "        [-0.0107, -0.2903],\n",
      "        [-0.0115, -0.2883],\n",
      "        [-0.0102, -0.2975],\n",
      "        [-0.0138, -0.2951],\n",
      "        [-0.0038, -0.3267],\n",
      "        [-0.0102, -0.2975],\n",
      "        [-0.0115, -0.2883],\n",
      "        [-0.0300, -0.2163],\n",
      "        [-0.0307, -0.2093],\n",
      "        [-0.0259, -0.2198],\n",
      "        [-0.0277, -0.2198],\n",
      "        [-0.0270, -0.2340],\n",
      "        [-0.0174, -0.2526],\n",
      "        [-0.0307, -0.2093],\n",
      "        [-0.0300, -0.2163],\n",
      "        [-0.0284, -0.2243],\n",
      "        [-0.0296, -0.2278],\n",
      "        [-0.0191, -0.2567],\n",
      "        [-0.0184, -0.2763],\n",
      "        [-0.0045, -0.3108]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0153, -0.2503],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0165, -0.2545],\n",
      "        [-0.0119, -0.2613],\n",
      "        [-0.0165, -0.2545],\n",
      "        [-0.0129, -0.2593],\n",
      "        [-0.0275, -0.2314],\n",
      "        [-0.0281, -0.2258],\n",
      "        [-0.0231, -0.2437],\n",
      "        [-0.0375, -0.2019],\n",
      "        [-0.0357, -0.2194],\n",
      "        [-0.0178, -0.2708],\n",
      "        [-0.0367, -0.2384],\n",
      "        [-0.0360, -0.2301]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0138, -0.2539],\n",
      "        [-0.0248, -0.2395],\n",
      "        [-0.0160, -0.2535],\n",
      "        [-0.0129, -0.2591],\n",
      "        [-0.0153, -0.2503],\n",
      "        [-0.0129, -0.2591],\n",
      "        [-0.0160, -0.2535],\n",
      "        [-0.0248, -0.2530],\n",
      "        [-0.0115, -0.2918],\n",
      "        [-0.0107, -0.2927],\n",
      "        [-0.0112, -0.2821],\n",
      "        [-0.0143, -0.2646],\n",
      "        [-0.0140, -0.2644],\n",
      "        [-0.0109, -0.2818],\n",
      "        [-0.0117, -0.2894],\n",
      "        [-0.0093, -0.2800],\n",
      "        [-0.0139, -0.2929],\n",
      "        [-0.0256, -0.2436],\n",
      "        [-0.0254, -0.2332],\n",
      "        [-0.0331, -0.2027],\n",
      "        [-0.0282, -0.2028],\n",
      "        [-0.0307, -0.2156],\n",
      "        [-0.0347, -0.1765],\n",
      "        [-0.0353, -0.1718],\n",
      "        [-0.0390, -0.1513]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0055, -0.3168],\n",
      "        [-0.0083, -0.3184],\n",
      "        [-0.0076, -0.3161],\n",
      "        [-0.0114, -0.3015],\n",
      "        [-0.0050, -0.3301],\n",
      "        [-0.0057, -0.3155],\n",
      "        [-0.0071, -0.3134],\n",
      "        [-0.0079, -0.3036],\n",
      "        [-0.0069, -0.3150],\n",
      "        [-0.0141, -0.2922],\n",
      "        [-0.0035, -0.3386],\n",
      "        [-0.0118, -0.3040],\n",
      "        [-0.0150, -0.2863],\n",
      "        [-0.0108, -0.2906],\n",
      "        [-0.0107, -0.2878],\n",
      "        [-0.0106, -0.2852],\n",
      "        [-0.0151, -0.2714],\n",
      "        [-0.0106, -0.2852],\n",
      "        [-0.0107, -0.2878],\n",
      "        [-0.0096, -0.2753],\n",
      "        [-0.0252, -0.2470]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0070, -0.3210],\n",
      "        [-0.0140, -0.2592],\n",
      "        [-0.0106, -0.3006],\n",
      "        [-0.0081, -0.3142],\n",
      "        [-0.0057, -0.3195],\n",
      "        [-0.0081, -0.3108],\n",
      "        [-0.0057, -0.3198],\n",
      "        [-0.0081, -0.3108],\n",
      "        [-0.0082, -0.3078],\n",
      "        [-0.0115, -0.2876],\n",
      "        [-0.0102, -0.2980],\n",
      "        [-0.0115, -0.2887],\n",
      "        [-0.0090, -0.3103],\n",
      "        [-0.0102, -0.2985],\n",
      "        [-0.0071, -0.3078],\n",
      "        [-0.0122, -0.2913],\n",
      "        [-0.0250, -0.2224],\n",
      "        [-0.0313, -0.1906],\n",
      "        [-0.0356, -0.1625],\n",
      "        [-0.0352, -0.1632],\n",
      "        [-0.0391, -0.1496]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0117, -0.2760],\n",
      "        [-0.0213, -0.2492],\n",
      "        [-0.0367, -0.2000],\n",
      "        [-0.0310, -0.2083],\n",
      "        [-0.0262, -0.2478],\n",
      "        [-0.0337, -0.2078],\n",
      "        [-0.0164, -0.2549],\n",
      "        [-0.0394, -0.2173],\n",
      "        [-0.0394, -0.2173],\n",
      "        [-0.0117, -0.2861],\n",
      "        [-0.0316, -0.2330],\n",
      "        [-0.0218, -0.2605],\n",
      "        [-0.0161, -0.2645],\n",
      "        [-0.0306, -0.2351],\n",
      "        [-0.0240, -0.2465],\n",
      "        [-0.0155, -0.2687],\n",
      "        [-0.0240, -0.2464],\n",
      "        [-0.0159, -0.2637],\n",
      "        [-0.0305, -0.2350],\n",
      "        [-0.0194, -0.2584],\n",
      "        [-0.0152, -0.2741]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0087, -0.3039],\n",
      "        [-0.0097, -0.2870],\n",
      "        [-0.0111, -0.3153],\n",
      "        [-0.0098, -0.2958],\n",
      "        [-0.0121, -0.2738],\n",
      "        [-0.0121, -0.2738],\n",
      "        [-0.0100, -0.3068],\n",
      "        [-0.0037, -0.3463],\n",
      "        [-0.0143, -0.2797],\n",
      "        [-0.0133, -0.2615],\n",
      "        [-0.0133, -0.2615],\n",
      "        [-0.0138, -0.2755],\n",
      "        [-0.0151, -0.2509],\n",
      "        [-0.0207, -0.2634],\n",
      "        [-0.0124, -0.2942],\n",
      "        [-0.0285, -0.2356],\n",
      "        [-0.0125, -0.2973],\n",
      "        [-0.0121, -0.2965]], device='cuda:0')\n",
      "outpu is  tensor([[-8.0568e-03, -3.1245e-01],\n",
      "        [-7.0821e-03, -3.1011e-01],\n",
      "        [-9.6287e-03, -3.1265e-01],\n",
      "        [-1.4785e-02, -2.9648e-01],\n",
      "        [-1.1995e-02, -3.1009e-01],\n",
      "        [-8.8729e-03, -3.1477e-01],\n",
      "        [-8.1043e-03, -3.0334e-01],\n",
      "        [-8.5086e-03, -3.1539e-01],\n",
      "        [-6.2410e-03, -3.2342e-01],\n",
      "        [-1.4217e-02, -2.9070e-01],\n",
      "        [-1.5738e-02, -2.9221e-01],\n",
      "        [-1.3979e-02, -3.0428e-01],\n",
      "        [-1.5366e-02, -2.7060e-01],\n",
      "        [-1.5906e-02, -2.6055e-01],\n",
      "        [-1.8489e-02, -2.9895e-01],\n",
      "        [-8.8541e-03, -3.0334e-01],\n",
      "        [-8.2706e-03, -3.0985e-01],\n",
      "        [-2.0287e-02, -2.8561e-01],\n",
      "        [-9.2587e-03, -3.0641e-01],\n",
      "        [-2.5975e-02, -2.1852e-01],\n",
      "        [-4.8749e-03, -3.1942e-01],\n",
      "        [-2.8301e-02, -2.1262e-01],\n",
      "        [-1.4579e-03, -3.3434e-01],\n",
      "        [-8.9620e-03, -3.0817e-01],\n",
      "        [-2.9132e-02, -2.1567e-01],\n",
      "        [-2.9132e-02, -2.1567e-01],\n",
      "        [-2.8893e-02, -2.2432e-01],\n",
      "        [-2.8893e-02, -2.2432e-01],\n",
      "        [-4.2342e-05, -3.3687e-01],\n",
      "        [-8.7470e-03, -3.0795e-01],\n",
      "        [-1.1271e-03, -3.3279e-01],\n",
      "        [-1.0339e-02, -2.9855e-01],\n",
      "        [-2.0520e-02, -2.8634e-01],\n",
      "        [-1.2218e-02, -2.9182e-01],\n",
      "        [-3.1284e-02, -2.2648e-01],\n",
      "        [-2.9120e-02, -2.2696e-01],\n",
      "        [-2.9951e-02, -2.0339e-01],\n",
      "        [-2.9951e-02, -2.0339e-01],\n",
      "        [-3.5505e-02, -1.9614e-01],\n",
      "        [-3.3379e-02, -1.9267e-01],\n",
      "        [-3.3462e-02, -1.8979e-01],\n",
      "        [-3.3462e-02, -1.8979e-01],\n",
      "        [-3.4390e-02, -1.7257e-01]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0167, -0.2773],\n",
      "        [-0.0166, -0.2766],\n",
      "        [-0.0320, -0.1762],\n",
      "        [-0.0357, -0.1609],\n",
      "        [-0.0310, -0.1884],\n",
      "        [-0.0353, -0.1630],\n",
      "        [-0.0254, -0.2042],\n",
      "        [-0.0391, -0.1496],\n",
      "        [-0.0311, -0.2001],\n",
      "        [-0.0324, -0.1913],\n",
      "        [-0.0224, -0.2167],\n",
      "        [-0.0279, -0.2108],\n",
      "        [-0.0280, -0.2244],\n",
      "        [-0.0253, -0.2044],\n",
      "        [-0.0279, -0.2108],\n",
      "        [-0.0229, -0.2182],\n",
      "        [-0.0224, -0.2167],\n",
      "        [-0.0278, -0.2109],\n",
      "        [-0.0229, -0.2182],\n",
      "        [-0.0229, -0.2182],\n",
      "        [-0.0229, -0.2182],\n",
      "        [-0.0103, -0.2846]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0080, -0.3091],\n",
      "        [-0.0094, -0.3158],\n",
      "        [-0.0148, -0.2965],\n",
      "        [-0.0141, -0.2968],\n",
      "        [-0.0139, -0.2981],\n",
      "        [-0.0043, -0.3403],\n",
      "        [-0.0063, -0.3132],\n",
      "        [-0.0088, -0.3052],\n",
      "        [-0.0099, -0.3201],\n",
      "        [-0.0090, -0.2927],\n",
      "        [-0.0108, -0.3041],\n",
      "        [-0.0281, -0.2987],\n",
      "        [-0.0207, -0.2849],\n",
      "        [-0.0111, -0.3123],\n",
      "        [-0.0131, -0.3051],\n",
      "        [-0.0205, -0.2749],\n",
      "        [-0.0130, -0.2737],\n",
      "        [-0.0130, -0.2737],\n",
      "        [-0.0169, -0.3842],\n",
      "        [-0.0134, -0.2617],\n",
      "        [-0.0134, -0.2617],\n",
      "        [-0.0152, -0.2509]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0079, -0.3078],\n",
      "        [-0.0083, -0.3015],\n",
      "        [-0.0077, -0.3033],\n",
      "        [-0.0103, -0.2966],\n",
      "        [-0.0090, -0.2974],\n",
      "        [-0.0111, -0.2838],\n",
      "        [-0.0119, -0.3001],\n",
      "        [-0.0135, -0.2780],\n",
      "        [-0.0118, -0.2845],\n",
      "        [-0.0096, -0.2810],\n",
      "        [-0.0127, -0.2753],\n",
      "        [-0.0142, -0.2645],\n",
      "        [-0.0129, -0.2765],\n",
      "        [-0.0256, -0.2438],\n",
      "        [-0.0136, -0.2636],\n",
      "        [-0.0254, -0.2332],\n",
      "        [-0.0331, -0.2031],\n",
      "        [-0.0307, -0.2156],\n",
      "        [-0.0289, -0.2063],\n",
      "        [-0.0290, -0.2085],\n",
      "        [-0.0248, -0.2344],\n",
      "        [-0.0123, -0.2675],\n",
      "        [-0.0107, -0.2876],\n",
      "        [-0.0135, -0.2814],\n",
      "        [-0.0107, -0.2812],\n",
      "        [-0.0105, -0.2805],\n",
      "        [-0.0097, -0.2819],\n",
      "        [-0.0140, -0.2642],\n",
      "        [-0.0140, -0.2640],\n",
      "        [-0.0261, -0.2494]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0340, -0.1700],\n",
      "        [-0.0315, -0.1775],\n",
      "        [-0.0273, -0.1796]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0061, -0.3224],\n",
      "        [-0.0054, -0.3264],\n",
      "        [-0.0070, -0.3182],\n",
      "        [-0.0106, -0.3019],\n",
      "        [-0.0076, -0.3131],\n",
      "        [-0.0106, -0.3133],\n",
      "        [-0.0086, -0.3133],\n",
      "        [-0.0104, -0.3101],\n",
      "        [-0.0118, -0.2902],\n",
      "        [-0.0102, -0.2990],\n",
      "        [-0.0099, -0.3006],\n",
      "        [-0.0080, -0.3054],\n",
      "        [-0.0109, -0.2990],\n",
      "        [-0.0116, -0.3280],\n",
      "        [-0.0254, -0.2334],\n",
      "        [-0.0113, -0.2892],\n",
      "        [-0.0140, -0.2808],\n",
      "        [-0.0047, -0.3438],\n",
      "        [-0.0047, -0.3438],\n",
      "        [-0.0316, -0.2097],\n",
      "        [-0.0108, -0.2867],\n",
      "        [-0.0101, -0.2770],\n",
      "        [-0.0366, -0.1894],\n",
      "        [-0.0252, -0.2473],\n",
      "        [-0.0236, -0.2254],\n",
      "        [-0.0403, -0.1938],\n",
      "        [-0.0403, -0.1938]], device='cuda:0')\n",
      "outpu is  tensor([[-8.6556e-03, -3.1716e-01],\n",
      "        [-9.8500e-03, -3.1759e-01],\n",
      "        [-1.6239e-04, -3.6064e-01],\n",
      "        [-2.4342e-02, -3.2067e-01],\n",
      "        [ 7.7146e-04, -3.5751e-01],\n",
      "        [-1.3691e-02, -2.9994e-01],\n",
      "        [-2.0325e-02, -2.4886e-01],\n",
      "        [-3.2718e-02, -2.0097e-01],\n",
      "        [-3.5695e-02, -1.6815e-01],\n",
      "        [-2.4326e-02, -2.6513e-01],\n",
      "        [-2.3679e-02, -2.4488e-01],\n",
      "        [-4.4223e-02, -1.9997e-01],\n",
      "        [-4.4223e-02, -1.9997e-01],\n",
      "        [-2.4471e-02, -4.0496e-01],\n",
      "        [-4.4223e-02, -1.9997e-01]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0155, -0.2640],\n",
      "        [-0.0319, -0.2075],\n",
      "        [-0.0319, -0.2075],\n",
      "        [-0.0322, -0.1878],\n",
      "        [-0.0322, -0.1878],\n",
      "        [-0.0335, -0.2826],\n",
      "        [-0.0061, -0.3566],\n",
      "        [-0.0038, -0.3531],\n",
      "        [-0.0611, -0.2694]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0061, -0.3124],\n",
      "        [-0.0081, -0.3066],\n",
      "        [-0.0110, -0.2867],\n",
      "        [-0.0168, -0.2488],\n",
      "        [-0.0270, -0.2186],\n",
      "        [-0.0324, -0.1924],\n",
      "        [-0.0113, -0.2871],\n",
      "        [-0.0106, -0.2881],\n",
      "        [-0.0106, -0.2915],\n",
      "        [-0.0110, -0.2890],\n",
      "        [-0.0100, -0.3002],\n",
      "        [-0.0058, -0.3171],\n",
      "        [-0.0047, -0.3220],\n",
      "        [-0.0063, -0.3203]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0119, -0.3022],\n",
      "        [-0.0162, -0.3183],\n",
      "        [-0.0307, -0.2826],\n",
      "        [-0.0233, -0.3561],\n",
      "        [-0.0307, -0.2676],\n",
      "        [-0.0249, -0.2723],\n",
      "        [-0.0325, -0.2331],\n",
      "        [-0.0210, -0.2645],\n",
      "        [-0.0200, -0.2838],\n",
      "        [-0.0064, -0.3183],\n",
      "        [-0.0269, -0.2586],\n",
      "        [-0.0268, -0.2967],\n",
      "        [-0.0190, -0.3862],\n",
      "        [-0.0088, -0.3113],\n",
      "        [-0.0177, -0.2634],\n",
      "        [-0.0139, -0.2649],\n",
      "        [-0.0170, -0.2730],\n",
      "        [-0.0156, -0.2953],\n",
      "        [-0.0068, -0.3132],\n",
      "        [-0.0125, -0.2844],\n",
      "        [-0.0288, -0.2478]], device='cuda:0')\n",
      "outpu is  tensor([[-0.0057, -0.3124],\n",
      "        [-0.0167, -0.2907],\n",
      "        [-0.0202, -0.2745],\n",
      "        [-0.0104, -0.2820],\n",
      "        [-0.0182, -0.2802],\n",
      "        [-0.0250, -0.2606],\n",
      "        [-0.0270, -0.2525],\n",
      "        [-0.0121, -0.2951],\n",
      "        [-0.0108, -0.2963],\n",
      "        [-0.0235, -0.2694],\n",
      "        [-0.0120, -0.2941],\n",
      "        [-0.0100, -0.3051],\n",
      "        [-0.0117, -0.2969],\n",
      "        [-0.0117, -0.2969],\n",
      "        [-0.0138, -0.2840],\n",
      "        [-0.0100, -0.3048],\n",
      "        [-0.0114, -0.3009],\n",
      "        [-0.0129, -0.2926],\n",
      "        [-0.0129, -0.2926],\n",
      "        [-0.0247, -0.2668],\n",
      "        [-0.0115, -0.3008],\n",
      "        [-0.0066, -0.2999],\n",
      "        [-0.0103, -0.2839],\n",
      "        [-0.0067, -0.3115],\n",
      "        [-0.0103, -0.2839],\n",
      "        [-0.0185, -0.2681],\n",
      "        [-0.0230, -0.2592],\n",
      "        [-0.0066, -0.2999],\n",
      "        [-0.0212, -0.2766],\n",
      "        [-0.0261, -0.2497],\n",
      "        [-0.0069, -0.3175],\n",
      "        [-0.0261, -0.2497],\n",
      "        [-0.0224, -0.2634],\n",
      "        [-0.0241, -0.2489],\n",
      "        [-0.0244, -0.2523],\n",
      "        [-0.0255, -0.2570],\n",
      "        [-0.0299, -0.2496],\n",
      "        [-0.0232, -0.2479],\n",
      "        [-0.0159, -0.2835],\n",
      "        [-0.0174, -0.2785],\n",
      "        [-0.0134, -0.3055],\n",
      "        [-0.0282, -0.2867],\n",
      "        [-0.0137, -0.3109],\n",
      "        [-0.0246, -0.3589],\n",
      "        [-0.0238, -0.3076],\n",
      "        [-0.0328, -0.2738]], device='cuda:0')\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "[0.42238814 0.43434313 0.43434313 0.43370032 0.4339702  0.4339702\n",
      " 0.43397024 0.43397024 0.39874405 0.39874405 0.39874405 0.43193185\n",
      " 0.43193185 0.43193185 0.43193185 0.4363289  0.4363289  0.4339778\n",
      " 0.4339778  0.44477865 0.44477865 0.42717856 0.4314442  0.42932424\n",
      " 0.43237814 0.42857885 0.43270835 0.4263877  0.42152733 0.43641335\n",
      " 0.43058413 0.43470314 0.448295   0.4322423  0.43174878 0.43174878\n",
      " 0.4286777  0.4286777  0.43009117 0.45804343 0.4645363  0.4599822\n",
      " 0.46681422 0.4199606  0.449067   0.44398472 0.45142892 0.4543115\n",
      " 0.4467414  0.45020905 0.45382395 0.45495707 0.45403537 0.44440684\n",
      " 0.44753468 0.45020425 0.45577615 0.45653367 0.462421   0.4468879\n",
      " 0.4559139  0.44814757 0.4525977  0.4527224  0.45470864 0.43169472\n",
      " 0.45446455 0.4547866  0.43530843 0.43515214 0.4517989  0.45408472\n",
      " 0.4377366  0.4298617  0.43071944 0.4439202  0.44113496 0.43454796\n",
      " 0.42835775 0.4310322  0.42892784 0.43365106 0.436222   0.43051252\n",
      " 0.43127272 0.43799666 0.43803367 0.4378159  0.43258142 0.41722256\n",
      " 0.41973522 0.42630133 0.4252612  0.42625195 0.43114564 0.425639\n",
      " 0.4320859  0.4369013  0.42997292 0.43316045 0.43275622 0.43236682\n",
      " 0.43770212 0.44215694 0.44031256 0.4378431  0.43759778 0.43835494\n",
      " 0.42704824 0.42860577 0.4287313  0.42897025 0.42573616 0.42868426\n",
      " 0.4258987  0.429373   0.43030384 0.42875648 0.4314181  0.43539283\n",
      " 0.4378573  0.4337504  0.43371463 0.4446856  0.4290263  0.4269794\n",
      " 0.43075058 0.43246672 0.42381683 0.4322969  0.43153727 0.43153727\n",
      " 0.437692   0.4242279  0.42101336 0.43768612 0.43662766 0.43662766\n",
      " 0.42333484 0.4230019  0.4343011  0.4399619  0.43320385 0.44332585\n",
      " 0.43517292 0.45305032 0.42664894 0.44932687 0.43146443 0.46585009\n",
      " 0.46585009 0.42910838 0.42920703 0.46188346 0.4676208  0.4722058\n",
      " 0.43759942 0.4386994  0.4465671  0.44704348 0.44796082 0.4409523\n",
      " 0.44756028 0.43524095 0.44702402 0.4384189  0.4401172  0.4367214\n",
      " 0.42951766 0.45278552 0.43311316 0.45075437 0.45123234 0.43201023\n",
      " 0.44767848 0.43635705 0.44824505 0.42963123 0.44834816 0.43664712\n",
      " 0.42942858 0.44671762 0.44120127 0.42175794 0.4418455  0.43999755\n",
      " 0.42175794 0.44237825 0.44873384 0.44881395 0.4451715  0.4538849\n",
      " 0.4504787  0.44796968 0.442378   0.45052233 0.45221415 0.43538156\n",
      " 0.43836793 0.43064    0.4618112  0.44864082 0.43774778 0.44108203\n",
      " 0.445298   0.43588388 0.4340308  0.433067   0.42635873 0.45191512\n",
      " 0.45191512 0.44809374 0.44809374 0.42912498 0.42406744 0.42921138\n",
      " 0.42732862 0.45432875 0.45432875 0.45428708 0.45428708 0.4602555\n",
      " 0.4602555  0.4602441  0.4602441  0.4398386  0.43300202 0.42960846\n",
      " 0.44631207 0.43193534 0.44432467 0.43806598 0.43088132 0.4530417\n",
      " 0.44475532 0.4436941  0.42544603 0.44232035 0.4577779  0.46232626\n",
      " 0.43328008 0.45308968 0.43701023 0.45778105 0.4550896  0.4336139\n",
      " 0.44440886 0.46583834 0.46583834 0.43544078 0.42580456 0.46659416\n",
      " 0.45533553 0.4398034  0.42544028 0.44073436 0.44930637 0.4620899\n",
      " 0.4343036  0.45485896 0.43081897 0.43361446 0.44441357 0.45906052\n",
      " 0.43557754 0.4314321  0.4398297  0.425477   0.46984285 0.46984285\n",
      " 0.4415511  0.44447574 0.4343421  0.45485896 0.43153414 0.45490035\n",
      " 0.4351688  0.4444561  0.45906052 0.4356249  0.43093833 0.45907593\n",
      " 0.43717918 0.4254783  0.46984282 0.46984282 0.4420269  0.46984282\n",
      " 0.46984282 0.43789777 0.44901913 0.4336688  0.45422512 0.4348132\n",
      " 0.44580424 0.43436828 0.42549908 0.46592927 0.46592927 0.4424085\n",
      " 0.43116885 0.45482758 0.44158646 0.4444522  0.44038948 0.45303622\n",
      " 0.45556542 0.43160805 0.45488292 0.45608556 0.43105894 0.45907593\n",
      " 0.46984285 0.46984285 0.4316463  0.42476898 0.43516684 0.43224207\n",
      " 0.4264364  0.4169656  0.40966606 0.41566423 0.42995906 0.4156563\n",
      " 0.42561    0.4326698  0.43119478 0.43934014 0.43957323 0.42367476\n",
      " 0.4212504  0.42715105 0.42477122 0.43177179 0.42254272 0.4226756\n",
      " 0.42586222 0.43126515 0.44453382 0.42648864 0.4275761  0.42913532\n",
      " 0.45348662 0.4385837  0.44359553 0.40932962 0.43564275 0.4398364\n",
      " 0.4301801  0.43162647 0.43748394 0.44810617 0.4348078  0.4374889\n",
      " 0.43588054 0.4255563  0.43329427 0.42056632 0.40939105 0.4267708\n",
      " 0.43208504 0.43773624 0.4379553  0.43484128 0.43060744 0.43102565\n",
      " 0.42794815 0.42284554 0.42134145 0.42230102 0.4221638  0.4258539\n",
      " 0.43364024 0.43368188 0.44468558 0.4313393  0.42846686 0.42735314\n",
      " 0.41810888 0.4289977  0.41060016 0.41060016 0.41060016 0.42357194\n",
      " 0.41999322 0.4209228  0.42176488 0.4312965  0.4341358  0.43224913\n",
      " 0.43224913 0.44520277 0.42530006 0.43896145 0.43896145 0.45438403\n",
      " 0.45791727 0.43753418 0.4499068  0.44682926 0.45876712 0.45876712\n",
      " 0.46119696 0.46119696 0.46557298 0.43508998 0.434857   0.43715566\n",
      " 0.42907634 0.43188426 0.42821687 0.4308083  0.43556207 0.4381879\n",
      " 0.44131157 0.4381879  0.43556207 0.42832357 0.42674008 0.4243775\n",
      " 0.4268369  0.42311317 0.4244589  0.42858583 0.43307847 0.44219914\n",
      " 0.43405575 0.44547608 0.44988957 0.43545383 0.42727372 0.45243785\n",
      " 0.44956282 0.4527988  0.42976275 0.4448888  0.43066868 0.45476747\n",
      " 0.45248643 0.4307869  0.43204314 0.46248838 0.44396442 0.43207455\n",
      " 0.4443275  0.46709257 0.43587136 0.45229375 0.4443275  0.4356426\n",
      " 0.42733467 0.45291543 0.42981225 0.4477015  0.43069023 0.43078694\n",
      " 0.43204314 0.43207455 0.4443275  0.4443275  0.46128637 0.45430148\n",
      " 0.43999374 0.4338308  0.43248498 0.43690598 0.4352897  0.43714866\n",
      " 0.4446334  0.44436315 0.4386044  0.4340849  0.43209887 0.4366791\n",
      " 0.4379311  0.4366791  0.43209887 0.43318117 0.43998796 0.42164582\n",
      " 0.43221402 0.41836753 0.43197757 0.41117048 0.41525626 0.42703617\n",
      " 0.43211707 0.4278794  0.42639497 0.4401649  0.43214422 0.42885494\n",
      " 0.42954355 0.43367076 0.44590795 0.4392444  0.43013382 0.43129408\n",
      " 0.43366805 0.4472185  0.45245925 0.44468558 0.45046243 0.4532447\n",
      " 0.45349512 0.45072246 0.45514894 0.4500656  0.45296806 0.4244426\n",
      " 0.42893216 0.4397198  0.41579908 0.4323027  0.41241577 0.42119944\n",
      " 0.4193267  0.4251557  0.42278764 0.4230859  0.42350692 0.42722812\n",
      " 0.4284318  0.4288274  0.42974716 0.426419   0.43180615 0.43744156\n",
      " 0.44414198 0.4536851  0.4378483  0.43504554 0.4344503  0.42953667\n",
      " 0.43321967 0.42965418 0.4188461  0.43160486 0.4188692  0.42964014\n",
      " 0.42539728 0.43780994 0.41406816 0.43278664 0.43433738 0.42759934\n",
      " 0.4352868  0.43390018 0.43134153 0.43390018 0.4352868  0.43421966\n",
      " 0.43183538 0.43402463 0.43183538 0.43421966 0.43341497 0.4387113\n",
      " 0.44502407 0.45142317 0.45214915 0.45884836 0.46124035 0.46557298\n",
      " 0.46124035 0.45884836 0.42964676 0.44406724 0.4477772  0.4543171\n",
      " 0.4300029  0.44023532 0.44612324 0.45388758 0.45577574 0.45593238\n",
      " 0.45150232 0.4510084  0.44466385 0.4448098  0.4372171  0.44098222\n",
      " 0.45856842 0.4403582  0.45368716 0.4511957  0.4478314  0.46241733\n",
      " 0.43153083 0.4342604  0.4428636  0.45941013 0.45570153 0.45570153\n",
      " 0.46149144 0.4184348  0.4229036  0.42023015 0.419261   0.4231609\n",
      " 0.41959098 0.4277352  0.41985673 0.41694802 0.43090227 0.42746156\n",
      " 0.42305338 0.42656657 0.42227453 0.4289046  0.4326044  0.43485257\n",
      " 0.43485257 0.4382597  0.4382597  0.44133162 0.4240695  0.42839968\n",
      " 0.4311369  0.4168975  0.42929384 0.42337242 0.42983213 0.43022993\n",
      " 0.43275684 0.43533355 0.43533355 0.43269494 0.4304853  0.42860758\n",
      " 0.43875474 0.4231941  0.40923816 0.43816972 0.43816972 0.43101054\n",
      " 0.44139913 0.42402947 0.42358148 0.41942516 0.41701102 0.42308354\n",
      " 0.42317575 0.43090227 0.42660162 0.42797488 0.4227821  0.42348158\n",
      " 0.43057954 0.43122795 0.43382445 0.43127242 0.43382445 0.43122795\n",
      " 0.4326044  0.42746156 0.43341497 0.42354268 0.4253569  0.42521715\n",
      " 0.42623466 0.4287804  0.4289032  0.42893738 0.42833504 0.42812678\n",
      " 0.4284496  0.43073216 0.43073696 0.4309237  0.43436366 0.43436366\n",
      " 0.4323866  0.43463936 0.43475243 0.4377462  0.43786398 0.4326372\n",
      " 0.4420883  0.43453097 0.42953628 0.4453852  0.44763154 0.43139428\n",
      " 0.4432785  0.42859462 0.4521479  0.4494306  0.44905204 0.43257597\n",
      " 0.43476507 0.4518011  0.44233438 0.4378235  0.43783498 0.45781714\n",
      " 0.44781178 0.4345028  0.4556072  0.44931313 0.43279377 0.4243749\n",
      " 0.44563717 0.4451896  0.44012645 0.43375513 0.43139783 0.43162015\n",
      " 0.43304998 0.44176894 0.45142007 0.450217   0.44618586 0.43816307\n",
      " 0.45279044 0.45083866 0.45117998 0.44629297 0.45295182 0.4491929\n",
      " 0.43836734 0.4476318  0.4359035  0.43237308 0.43478945 0.43370107\n",
      " 0.42909214 0.4225941  0.43849584 0.43110058 0.4311485  0.42785722\n",
      " 0.41732562 0.43806183 0.42489323 0.4245751  0.4325213  0.43479478\n",
      " 0.43479478 0.42878735 0.4288977  0.42383587 0.42525274 0.4235511\n",
      " 0.41893855 0.42493182 0.411832   0.4180689  0.42507753 0.4359165\n",
      " 0.42571586 0.4300313  0.42892244 0.41512686 0.42393562 0.40782917\n",
      " 0.43531868 0.45317256 0.43993834 0.45317256 0.4394416  0.43239537\n",
      " 0.43439165 0.43574244 0.43439165 0.43239537 0.43694136 0.4389482\n",
      " 0.44519326 0.4496178  0.44225734 0.4443615  0.43949112 0.4358751\n",
      " 0.4485404  0.4505571  0.44354323 0.4448418  0.43173024 0.43732646\n",
      " 0.43623617 0.44368586 0.4508967  0.45100605 0.44870555 0.4540964\n",
      " 0.4418252  0.45771727 0.46222746 0.45710674 0.43118802 0.4256052\n",
      " 0.42517358 0.42931816 0.4318487  0.43399006 0.4277688  0.42245248\n",
      " 0.4344786  0.43937027 0.44369465 0.44161418 0.43388176 0.43993202\n",
      " 0.4426992  0.44110352 0.44019067 0.44139478 0.44513288 0.44502404\n",
      " 0.45818368 0.45818368 0.45818368 0.44581282 0.4359489  0.44587624\n",
      " 0.44716683 0.44466984 0.4453698  0.4489401  0.4543007  0.45543975\n",
      " 0.46048513 0.46048513 0.4187056  0.42394915 0.4313419  0.4248881\n",
      " 0.4387364  0.43748257 0.4333386  0.40206468 0.41863307 0.43081674\n",
      " 0.42555872 0.42555872 0.42343366 0.42304054 0.41665775 0.43166375\n",
      " 0.42325807 0.4179403  0.41154945 0.42125055 0.43626133 0.42643985\n",
      " 0.42225018 0.42494577 0.42603877 0.42761722 0.4323641  0.4289626\n",
      " 0.42141223 0.42569298 0.43410158 0.43356264 0.4316787  0.4316787\n",
      " 0.4292238  0.43602273 0.4399185  0.43160993 0.4389536  0.4389536\n",
      " 0.43850031 0.44643575 0.4534675  0.4534675  0.4375369  0.44682926\n",
      " 0.4441429  0.43265104 0.4309158  0.4289857  0.44403738 0.41758135\n",
      " 0.4288666  0.43273517 0.44132987 0.43227082 0.41139337 0.41708374\n",
      " 0.43876714 0.4221538  0.4221538  0.42679077 0.44712728 0.43426043\n",
      " 0.44410396 0.42305505 0.42978716 0.4252678  0.42383397 0.41673902\n",
      " 0.43276152 0.40919894 0.42825124 0.43003613 0.4264459  0.4275162\n",
      " 0.43675426 0.4252577  0.4238717  0.43431368 0.42696258 0.41809598\n",
      " 0.4333003  0.43143702 0.43739936 0.42471763 0.43880856 0.40855893\n",
      " 0.422383   0.42221183 0.42996565 0.42677578 0.42286363 0.42288873\n",
      " 0.4274525  0.4272613  0.42060536 0.42668554 0.4333941  0.43771747\n",
      " 0.44218025 0.45255733 0.44606897 0.4509605  0.45550078 0.4544984\n",
      " 0.4477709  0.45382062 0.4550411  0.4541432  0.45138967 0.4508839\n",
      " 0.44720647 0.44915056 0.4565499  0.46245208 0.4468154  0.45192397\n",
      " 0.44814757 0.452572   0.4503678  0.45469546 0.43169472 0.4543704\n",
      " 0.4547866  0.43530843 0.43515214 0.4517725  0.45408472 0.3882665\n",
      " 0.3882665  0.377874   0.377874   0.4262154  0.43078655 0.43207613\n",
      " 0.4443275  0.43312886 0.4323111  0.44441256 0.42915446 0.4307871\n",
      " 0.42760092 0.423542   0.42262167 0.41985878 0.42228824 0.42298225\n",
      " 0.4201613  0.42216986 0.42041075 0.4226134  0.43135464 0.43070066\n",
      " 0.44420308 0.4233399  0.4276094  0.4251737  0.4447786  0.4339778\n",
      " 0.43639743 0.4322532  0.4369419  0.4376467  0.4369419  0.4322532\n",
      " 0.4513424  0.45429054 0.46337557 0.45749626 0.46085525 0.42283404\n",
      " 0.42772684 0.41916472 0.4358267  0.41916472 0.42772684 0.3843148\n",
      " 0.4202826  0.42993465 0.428999   0.43362054 0.42992663 0.436785\n",
      " 0.43120897 0.44182056 0.4314406  0.42414826 0.4287157  0.4266234\n",
      " 0.42284024 0.42360136 0.4279899  0.4325134  0.4377251  0.43775892\n",
      " 0.433297   0.43627504 0.4388118  0.45290387 0.45290387 0.4344552\n",
      " 0.43818098 0.43843466 0.44140637 0.43843466 0.43818098 0.4373607\n",
      " 0.4344552  0.438181   0.43843466 0.44140637 0.43843466 0.438181\n",
      " 0.44286227 0.44917703 0.45418873 0.45510882 0.45326596 0.44789588\n",
      " 0.45510882 0.45326596 0.44577852 0.44377315 0.43161243 0.43251452\n",
      " 0.43562397 0.43173504 0.4294773  0.43665415 0.43266323 0.4445114\n",
      " 0.43685338 0.4486576  0.44689652 0.42313147 0.4268369  0.42840227\n",
      " 0.4243775  0.42676532 0.4244589  0.42858583 0.43082574 0.43082574\n",
      " 0.43556207 0.43556207 0.43556204 0.43556204 0.4381879  0.4381879\n",
      " 0.4381879  0.4381879  0.44131157 0.44131157 0.44077674 0.43797675\n",
      " 0.44922325 0.45067504 0.44503096 0.45373586 0.44647336 0.43558943\n",
      " 0.4589871  0.44077674 0.43871182 0.44150326 0.43871182 0.44058207\n",
      " 0.43868217 0.44150326 0.43868217 0.44058207 0.43413514 0.43429646\n",
      " 0.43866378 0.446912   0.43214938 0.43563932 0.43563932 0.4350414\n",
      " 0.45744488 0.4574896  0.43168342 0.43825194 0.43825194 0.44052923\n",
      " 0.44052923 0.4477125  0.45039982 0.4299011  0.44131157 0.43866485\n",
      " 0.43866485 0.4613194  0.4613194  0.46033016 0.44150326 0.42914462\n",
      " 0.42914462 0.43088603 0.4311707  0.4311707  0.43088606 0.43483782\n",
      " 0.43791416 0.4377462  0.43247324 0.43247324 0.4377462  0.43791416\n",
      " 0.43483782 0.42829663 0.43028155 0.42589372 0.42322034 0.42360213\n",
      " 0.4237579  0.42800212 0.4236262  0.42577955 0.42624012 0.42348695\n",
      " 0.43840507 0.4347995  0.44068104 0.4386979  0.44150326 0.4386979\n",
      " 0.44068104 0.43042406 0.4080302  0.4112404  0.43042406 0.4080302\n",
      " 0.42390218 0.4364307  0.42390218 0.4227802  0.42065707 0.42896947\n",
      " 0.42627996 0.4313749  0.42980206 0.42939088 0.41718942 0.4318159\n",
      " 0.44443393 0.42317307 0.43001676 0.4327697  0.45320863 0.40923893\n",
      " 0.46339157 0.46334678 0.45901543 0.4589244  0.4565618  0.45920134\n",
      " 0.45920134 0.46219704 0.46219704 0.46005568 0.45527247 0.4438657\n",
      " 0.4458059  0.43002254 0.4471971  0.44879156 0.4578268  0.43428817\n",
      " 0.4349501  0.45414752 0.43261164 0.4503916  0.42650884 0.4599075\n",
      " 0.45478243 0.4295665  0.46241733 0.45639375 0.43491182 0.45299983\n",
      " 0.45738062 0.44339618 0.42401052 0.42588627 0.4314322  0.43904346\n",
      " 0.4508813  0.46182328 0.4675138  0.47218543 0.4314488  0.4310507\n",
      " 0.43023556 0.43093935 0.42794815 0.42280743 0.42134145 0.42212102\n",
      " 0.43823665 0.44548896 0.43244517 0.43071312 0.43507096 0.4350345\n",
      " 0.4380939  0.43484354 0.4328602  0.45219588 0.45222846 0.4611267\n",
      " 0.4611267  0.46337098 0.47138718 0.46337098 0.47138718 0.42693982\n",
      " 0.4357551  0.42583248 0.43308982 0.4304995  0.4296208  0.42047456\n",
      " 0.42041323 0.4290979  0.42849806 0.4283654  0.4259545  0.4290535\n",
      " 0.4237636  0.42927915 0.44207472 0.43793055 0.42869303 0.43143702\n",
      " 0.40855893 0.41805854 0.4288245  0.4333003  0.43739936 0.43880856\n",
      " 0.42471763 0.41559502 0.4279973  0.4170385  0.4244397  0.43425363\n",
      " 0.4268993  0.41882068 0.43979478 0.44676673 0.46165097 0.41139293\n",
      " 0.42664063 0.43663302 0.42745924 0.42520195 0.43920192 0.45065632\n",
      " 0.46260518 0.46260518 0.42903507 0.42354155 0.43920192 0.45065632\n",
      " 0.46260518 0.46260518 0.43570498 0.43499845 0.43570492 0.42946947\n",
      " 0.42896566 0.4282867  0.4264951  0.42598364 0.4318307  0.43191025\n",
      " 0.44426674 0.43047896 0.44407585 0.43028635 0.44398728 0.44721833\n",
      " 0.4502868  0.44145933 0.43141282 0.42744634 0.42651224 0.4285052\n",
      " 0.42882943 0.4222667  0.43274212 0.42268485 0.43221164 0.44441256\n",
      " 0.443098   0.43281293 0.4440988  0.4413273  0.4220928  0.4225485\n",
      " 0.4246045  0.4252381  0.42964885 0.42499426 0.42841205 0.42771\n",
      " 0.42274272 0.42134145 0.4219256  0.4273643  0.42872915 0.42796043\n",
      " 0.43058172 0.44409168 0.444351   0.43220112 0.43132186 0.43360487\n",
      " 0.4211678  0.43465155 0.42996323 0.4294122  0.43555275 0.40915284\n",
      " 0.43285534 0.4309639  0.4133581  0.4280422  0.42667493 0.41766232\n",
      " 0.42809853 0.42938134 0.43082297 0.42850122 0.42085886 0.4397215\n",
      " 0.4227973  0.4227973  0.4307922  0.44418764 0.43121812 0.4262615\n",
      " 0.43267512 0.4326388  0.4328741  0.42382535 0.4456576  0.4377446\n",
      " 0.43765658 0.42129463 0.44779924 0.4513703  0.4537868  0.45450673\n",
      " 0.4478468  0.46166605 0.46166605 0.46166605 0.428389   0.4237792\n",
      " 0.43090788 0.43087146 0.42170632 0.43167478 0.4311188  0.4421832\n",
      " 0.43459874 0.4428     0.42437172 0.42166418 0.4341639  0.44066516\n",
      " 0.43146056 0.42944422 0.4314956  0.41289455 0.45289767 0.4345138\n",
      " 0.4416869  0.43151072 0.42989084 0.4592299  0.4340202  0.41051316\n",
      " 0.41051316 0.41051316 0.45683473 0.43375462 0.4446856  0.44194362\n",
      " 0.44523138 0.4364791  0.44876468 0.45123836 0.444284   0.43308192\n",
      " 0.45596775 0.44173303 0.44678688 0.42235848 0.4285383  0.45471513\n",
      " 0.45316058 0.45774376 0.42558554 0.41878682 0.4588194  0.46630648\n",
      " 0.43626088 0.4182544  0.44372746 0.43991053 0.45184678 0.44807285\n",
      " 0.45432284 0.42944056 0.45406944 0.46002293 0.4427349  0.4289223\n",
      " 0.42366612 0.46277165 0.4352628  0.4536507  0.4437253  0.44538718\n",
      " 0.43714854 0.45298964 0.43905604 0.44831458 0.44751212 0.4599076\n",
      " 0.45093244 0.4494953  0.45811376 0.44957736 0.45053622 0.4522813\n",
      " 0.45805523 0.4503817  0.45585087 0.4495281  0.4418674  0.44961685\n",
      " 0.45321348 0.45107535 0.44852507 0.4408165  0.45075613 0.4491649\n",
      " 0.4525964  0.43867406 0.44903934 0.44863376 0.4472304  0.4417937\n",
      " 0.44402096 0.44891533 0.43143284 0.4341137  0.44069996 0.44931576\n",
      " 0.44912407 0.4487034  0.4454699  0.43132573 0.43754512 0.44506407\n",
      " 0.4447705  0.431728   0.43620774 0.4371723  0.43418053 0.43418053\n",
      " 0.4489093  0.45210704 0.4327715  0.43312863 0.4327715  0.43312863\n",
      " 0.44833758 0.45843446 0.43924338 0.43565434 0.43773562 0.43565434\n",
      " 0.43773562 0.4645716  0.43782255 0.43782255 0.4599822  0.46681422\n",
      " 0.43523607 0.440526   0.43866986 0.44150326 0.43866986 0.440526\n",
      " 0.42735234 0.43619257 0.41074422 0.4319684  0.42266688 0.42489937\n",
      " 0.4171711  0.4376323  0.44310448 0.45365945 0.4422481  0.4296579\n",
      " 0.4344963  0.4349712  0.43857065 0.42743728 0.43558964 0.43182018\n",
      " 0.43278262 0.4377786  0.43778878 0.43292597 0.43339676 0.4323647\n",
      " 0.44439667 0.433761   0.418966   0.42088088 0.44813615 0.43157136\n",
      " 0.41691092 0.43203372 0.433556   0.4550376  0.40837255 0.42227444\n",
      " 0.43271038 0.4251218  0.43746153 0.4583634  0.42288107 0.4092381\n",
      " 0.43867165 0.45164225 0.45247322 0.45247322 0.45245135 0.45245135\n",
      " 0.45152935 0.45513982 0.45640454 0.45620078 0.44682926 0.4375342\n",
      " 0.43896145 0.4322165  0.43121457 0.4322165  0.43896145 0.4311535\n",
      " 0.4250666  0.44201645 0.44933772 0.44999585 0.45652118 0.46032378\n",
      " 0.46032378 0.45652118 0.43707588 0.4296548  0.4265836  0.42456967\n",
      " 0.42440733 0.4280638  0.42310092 0.4271251  0.43012294 0.41909388\n",
      " 0.43918312 0.44278738 0.44727877 0.45664024 0.46306515 0.460323\n",
      " 0.45224875 0.41694802 0.419261   0.4229036  0.41985673 0.42023015\n",
      " 0.42316088 0.42227447 0.42299253 0.41959098 0.4277352  0.42746156\n",
      " 0.43090227 0.42841935 0.42656657 0.4310897  0.4310897  0.4326044\n",
      " 0.43176788 0.43176788 0.43626675 0.4339778  0.44477865 0.432722\n",
      " 0.4239485  0.42719042 0.42722002 0.43193227 0.43193227 0.43066958\n",
      " 0.4382639  0.44497386 0.43506718 0.44595852 0.4313767  0.44624606\n",
      " 0.4330255  0.43199182 0.42907095 0.42691174 0.4294078  0.42818514\n",
      " 0.42828912 0.42918167 0.42918167 0.4289792  0.4289792  0.43014058\n",
      " 0.43650368 0.44426674 0.44426674 0.44413936 0.4456437  0.4556413\n",
      " 0.43599707 0.44920185 0.43045044 0.4347815  0.4309033  0.42671612\n",
      " 0.43183115 0.4312579  0.4337494  0.43152142 0.43366805 0.4615788\n",
      " 0.4615788  0.4446856  0.44314164 0.44272223 0.45234087 0.44950742\n",
      " 0.4499146  0.42942402 0.45343235 0.44659388 0.45515737 0.44459325\n",
      " 0.43088672 0.4614915  0.44483414 0.44914874 0.4615876  0.44523638\n",
      " 0.46348214 0.44670084 0.44085464 0.46351373 0.46121377 0.46121377\n",
      " 0.46121377 0.43779424 0.43315792 0.44075295 0.44075295 0.43789697\n",
      " 0.43104377 0.4387118  0.4387118  0.43434387 0.44477418 0.44150326\n",
      " 0.42593688 0.43322748 0.42545745 0.4237671  0.44179025 0.4415163\n",
      " 0.4245952  0.42881733 0.42729014 0.43083307 0.43086126 0.43244836\n",
      " 0.43480423 0.43768755 0.43795964 0.41797516 0.41745043 0.41799948\n",
      " 0.4195279  0.41944534 0.41824716 0.42407653 0.42304713 0.41931972\n",
      " 0.4256394  0.42022553 0.41919193 0.42300993 0.4244711  0.42663336\n",
      " 0.42553732 0.41805592 0.41675857 0.42285135 0.42408156 0.4201929\n",
      " 0.4231901  0.43705502 0.4327642  0.43602663 0.4289481  0.42573103\n",
      " 0.428862   0.42740774 0.43642482 0.4334508  0.42409316 0.43147534\n",
      " 0.43847582 0.4421695  0.4439922  0.44289994 0.44980884 0.44036925\n",
      " 0.4482764  0.4482764  0.44758064 0.4402009  0.44850412 0.4520565\n",
      " 0.4520565  0.44620427 0.45799476 0.4529772  0.4500573  0.44961107\n",
      " 0.4487576  0.4375697  0.4517248  0.45848957 0.46012518 0.45156613\n",
      " 0.45797127 0.42826164 0.45017877 0.44525355 0.4577125  0.44520664\n",
      " 0.43785384 0.4349461  0.4580531  0.46944457 0.46944457 0.42638227\n",
      " 0.42956206 0.42338067 0.4345321  0.4448697  0.43762654 0.42249358\n",
      " 0.43184468 0.43870488 0.434621   0.43002746 0.4552394  0.4552394\n",
      " 0.44066566 0.42225745 0.45394537 0.4031821  0.42865002 0.42862782\n",
      " 0.43167764 0.42873508 0.43742803 0.43271595 0.41465268 0.42561167\n",
      " 0.4358295  0.43624845 0.42915514 0.43046272 0.42798027 0.42798027\n",
      " 0.4342323  0.42816144 0.42660385 0.42917764 0.42882016 0.43649638\n",
      " 0.42971778 0.42203188 0.4263516  0.43126628 0.43415412 0.4302381\n",
      " 0.43352738 0.44248942 0.43237084 0.44826624 0.4256505  0.44406477\n",
      " 0.44115576 0.444416   0.4592386  0.4592386  0.439029   0.43812084\n",
      " 0.46333244 0.46333244 0.44983315 0.44066998 0.4565848  0.45579082\n",
      " 0.45924976 0.4432852  0.45565832 0.45565832 0.44484013 0.43183297\n",
      " 0.4406111  0.4382216  0.44459292 0.44904253 0.43705904 0.4447618\n",
      " 0.44055107 0.4473824  0.4493596  0.45317376 0.45070326 0.45071086\n",
      " 0.4522753  0.45071086 0.4522753  0.4102602  0.4105469  0.4105469\n",
      " 0.4105469  0.41461366 0.41382894 0.42119658 0.43001556 0.4177076\n",
      " 0.4171426  0.4276747  0.42930645 0.43033272 0.43211815 0.42997345\n",
      " 0.41854176 0.42152837 0.42903283 0.4255174  0.43898538 0.43243346\n",
      " 0.4290401  0.41598386 0.41598386 0.43250108 0.4106176  0.4106176\n",
      " 0.4106176  0.43597016 0.4589124  0.45605397 0.4516142  0.44339013\n",
      " 0.4343131  0.4516142  0.45605397 0.4351926  0.43465307 0.4355315\n",
      " 0.42269102 0.43037865 0.4109196  0.4109196  0.4109196  0.43045777\n",
      " 0.4371777  0.4319788  0.43465346 0.44753456 0.43464962 0.43783662\n",
      " 0.43546715 0.44566122 0.4538344  0.45814642 0.4579571  0.45448786\n",
      " 0.42415932 0.410165   0.41896126 0.42030656 0.42814165 0.42814168\n",
      " 0.4301766  0.43044996 0.41226035 0.4164071  0.4071255  0.4164071\n",
      " 0.4071255  0.41299963 0.42181244 0.42112967 0.45316672 0.43436152\n",
      " 0.42067692 0.4301253  0.44691023 0.41087866 0.41087866 0.41087866\n",
      " 0.42963135 0.41971382 0.4297753  0.4270736  0.4300784  0.43244112\n",
      " 0.43498263 0.43498263 0.4303298  0.40370187 0.43824467 0.43824467\n",
      " 0.43499163 0.42812878 0.42812878 0.44139007 0.42498234 0.42498234\n",
      " 0.43995228 0.43995228 0.43744394 0.4468293  0.439617   0.42712343\n",
      " 0.44143692 0.41584563 0.43468317 0.4201654  0.43580306 0.45301497\n",
      " 0.42935723 0.42896724 0.4292489  0.42533356 0.43524206 0.44118577\n",
      " 0.42890993 0.42778167 0.43156335 0.4186213  0.4318971  0.45449665\n",
      " 0.4387199  0.45395145 0.43038043 0.4494703  0.4252626  0.45901093\n",
      " 0.45151895 0.4570598  0.43007696 0.4615824  0.4615824  0.46984285\n",
      " 0.46984285 0.43821502 0.4307233  0.4376145  0.44878355 0.43337026\n",
      " 0.44297957 0.427776   0.4409586  0.45337197 0.43032673 0.43228292\n",
      " 0.44070932 0.4227616  0.42995158 0.43441728 0.4358947  0.4188036\n",
      " 0.43378854 0.38117397 0.44484013 0.4318329  0.44067    0.4432852\n",
      " 0.4406111  0.440552   0.43561465 0.43702918 0.4383618  0.4382216\n",
      " 0.44461122 0.44459292 0.43429554 0.4565848  0.45924976 0.44983315\n",
      " 0.45565832 0.45565832 0.45579082 0.44906864 0.44904253 0.42147496\n",
      " 0.43088672 0.4489438  0.42392126 0.42857435 0.44314164 0.44459325\n",
      " 0.43865705 0.45515737 0.45343235 0.4499146  0.45234087 0.4615876\n",
      " 0.4614915  0.44272223 0.46351373 0.46348214 0.44942424 0.429424\n",
      " 0.44720626 0.43897063 0.44523638 0.4469262  0.46121377 0.46121377\n",
      " 0.46121377 0.42604774 0.43135065 0.43851107 0.43000802 0.4325038\n",
      " 0.427175   0.427175   0.43143523 0.4376117  0.434634   0.43925083\n",
      " 0.43925083 0.43482167 0.44109404 0.4303987  0.4109196  0.4109196\n",
      " 0.4109196  0.43545955 0.45107123 0.45331377 0.46314198 0.46255478\n",
      " 0.46136302 0.4676388  0.440154   0.43546766 0.43509442 0.42303053\n",
      " 0.4356482  0.44728217 0.44248545 0.427939   0.4577424  0.4577424\n",
      " 0.46181986 0.46181986 0.42666376 0.42960525 0.4289963  0.43644804\n",
      " 0.42573228 0.43241507 0.42403808 0.4393011  0.4341181  0.43228543\n",
      " 0.43771613 0.4514397  0.43654606 0.43654606 0.43764928 0.45544422\n",
      " 0.45544422 0.42914084 0.42914084 0.4555817  0.4555817  0.43023944\n",
      " 0.45169735 0.4199606  0.45226893 0.44734225 0.4398107  0.4370317\n",
      " 0.4370317  0.43230954 0.43230954 0.43639746 0.4339778  0.44477865\n",
      " 0.41745645 0.41716322 0.43432277 0.43446997 0.42535222 0.42302847\n",
      " 0.425259   0.4231068  0.43123043 0.42888936 0.42111284 0.4355289\n",
      " 0.4288289  0.43647644 0.43180913 0.4362519  0.43759272 0.43789533\n",
      " 0.43462896 0.442593   0.4267175  0.4173522  0.43146577 0.42879972\n",
      " 0.41679162 0.40850744 0.42225415 0.42825162 0.43648687 0.43269622\n",
      " 0.433102   0.4228498  0.42220995 0.44545195 0.40919894 0.42531484\n",
      " 0.43591353 0.4548175  0.43873304 0.43764505 0.4492175  0.4615974\n",
      " 0.4615974  0.44440347 0.44527358 0.44920206 0.43573254 0.4382332\n",
      " 0.43979356 0.45870832 0.45131516 0.43994403 0.43943658 0.43748906\n",
      " 0.45279846 0.45159197 0.44257548 0.44029906 0.4404184  0.4294874\n",
      " 0.43453097 0.44415623 0.4621634  0.44424385 0.44647458 0.44387814\n",
      " 0.44407254 0.4425052  0.4299504  0.45069957 0.43036357 0.44152567\n",
      " 0.4372132  0.4430389  0.4443668  0.45288232 0.44698232 0.46043658\n",
      " 0.44396487 0.42824826 0.43823537 0.45764187 0.45764187 0.45534408\n",
      " 0.45858562 0.4475886  0.43784693 0.43494034 0.43881512 0.4478718\n",
      " 0.44359937 0.44309428 0.43620133 0.44286975 0.44165587 0.44004515\n",
      " 0.44890505 0.4529388  0.4321873  0.426353   0.4344834  0.43749866\n",
      " 0.4345656  0.45064783 0.43025926 0.46043658 0.4348461  0.4350298\n",
      " 0.43400133 0.42984542 0.43297854 0.43521127 0.43373588 0.4446856\n",
      " 0.4393881  0.45245928 0.46001136 0.46291834 0.4587862  0.4477024\n",
      " 0.438058   0.4554114  0.44756076 0.4612956  0.4612956  0.4721844\n",
      " 0.46735117 0.4626999  0.45666137 0.44843253 0.4565285  0.4606297\n",
      " 0.4625764  0.45463213 0.4451723  0.4285655  0.43068668 0.42822778\n",
      " 0.43553466 0.43341103 0.44222698 0.44012648 0.43574327 0.44012648\n",
      " 0.43341103 0.44222704 0.42737502 0.42646646 0.43656307 0.42353266\n",
      " 0.4287726  0.43432778 0.43802905 0.45243195 0.42914933 0.435024\n",
      " 0.46073776 0.44113126 0.44687325 0.4442139  0.45430854 0.447805\n",
      " 0.46166608 0.46166608 0.46166608 0.42630413 0.44130605 0.42449734\n",
      " 0.4202989  0.43629587 0.45620784 0.4268773  0.42277828 0.4192423\n",
      " 0.41564208 0.43833476 0.43833476 0.4663581  0.4248871  0.4322334\n",
      " 0.438469   0.438469   0.43190232 0.4377194  0.44140637 0.43764693\n",
      " 0.42675614 0.424422   0.42549258 0.426083   0.43069473 0.4309237\n",
      " 0.42893738 0.43436366 0.43475243 0.43436366 0.4289032  0.430737\n",
      " 0.42842546 0.42508045 0.42350635 0.4253569  0.42565078 0.42733642\n",
      " 0.43090785 0.42847914 0.42289925 0.42796272 0.43647128 0.42654014\n",
      " 0.42508143 0.43714765 0.4440663  0.43042406 0.42507148 0.43123242\n",
      " 0.4306636  0.4160374  0.41691864 0.4348184  0.42370978 0.4388091\n",
      " 0.43846747 0.42186204 0.43182188 0.43863392 0.43238488 0.43601573\n",
      " 0.43390584 0.44369546 0.43742594 0.44520086 0.4449047  0.437087\n",
      " 0.4421015  0.42922556 0.44042155 0.43784165 0.44508746 0.4278015\n",
      " 0.43747452 0.4350647  0.44849485 0.44849485 0.44438758 0.42929667\n",
      " 0.42604718 0.42794922 0.429111   0.42881668 0.43677163 0.43771055\n",
      " 0.4446416  0.43539867 0.43539867 0.44581002 0.44634163 0.43825293\n",
      " 0.43825293 0.4413446  0.46091682 0.46091682 0.46091682 0.42623278\n",
      " 0.44161493 0.4586794  0.4586794  0.4586794  0.43533906 0.44890425\n",
      " 0.44194534 0.4341715  0.4341715  0.45392224 0.43720895 0.45617133\n",
      " 0.43564108 0.43564108 0.43564108 0.43564108 0.45734257 0.463132\n",
      " 0.4282079  0.43822682 0.43822682 0.43822682 0.43822682 0.46079668\n",
      " 0.44131157 0.44131157 0.4349461  0.46601555 0.43785384 0.43299496\n",
      " 0.42972282 0.42856422 0.43473294 0.4378821  0.43776977 0.43253326\n",
      " 0.42541808 0.42342973 0.4219899  0.44724408 0.45357755 0.45547715\n",
      " 0.45197803 0.45547715 0.45357755 0.45847055 0.45815516 0.45377368\n",
      " 0.442773   0.43586755 0.43586755 0.43437895 0.42892128 0.4301643\n",
      " 0.42892128 0.43437895 0.4199606  0.43437892 0.42892128 0.4301643\n",
      " 0.42892128 0.43437892 0.4199606  0.40516034 0.4152116  0.4152116\n",
      " 0.4152116  0.43231937 0.37366706 0.3615211  0.43721607 0.4133209\n",
      " 0.42685437 0.43926772 0.44109404 0.43926772 0.42685437 0.44856977\n",
      " 0.4423413  0.4371875  0.42604792 0.42496026 0.4249603  0.42604792\n",
      " 0.4297329  0.4297329  0.4351516  0.43819535 0.44139913 0.43819535\n",
      " 0.4351516  0.43515158 0.43819535 0.44139913 0.43819535 0.43515158\n",
      " 0.4246212  0.4246212  0.43441674 0.43497404 0.40351567 0.4246086\n",
      " 0.4246086  0.42846432 0.42808646 0.42808646 0.43751132 0.43751132\n",
      " 0.4171089  0.4346096  0.4309978  0.4309978  0.43945614 0.4333928\n",
      " 0.4333928  0.43517542 0.42401052 0.42588627 0.4314322  0.4389972\n",
      " 0.4507628  0.46013772 0.4663788  0.46873558 0.46815205 0.47239414\n",
      " 0.43144882 0.4310507  0.4302356  0.43093938 0.42794812 0.42280743\n",
      " 0.42134145 0.42212105 0.4484186  0.4554929  0.4331921  0.4618983\n",
      " 0.43371242 0.43371242 0.44970074 0.43635413 0.433062   0.43635413\n",
      " 0.433062   0.46170375 0.46170375 0.44467688 0.43823877 0.437808\n",
      " 0.44467688 0.43823877 0.437808   0.438181   0.438181   0.42830822\n",
      " 0.42334634 0.42830822 0.42623922 0.430779   0.4309237  0.4289533\n",
      " 0.43436366 0.43475243 0.43436366 0.4289533  0.4309237  0.430779\n",
      " 0.42623925 0.42522344 0.4254383  0.42335388 0.41608164 0.41608164\n",
      " 0.43292567 0.440454   0.43292567 0.42059082 0.43223655 0.4090735\n",
      " 0.42568946 0.43630952 0.43519154 0.43638077 0.43638077 0.43519154\n",
      " 0.42568946 0.43630952 0.43223655 0.40907347 0.42059082 0.4364628\n",
      " 0.4390627  0.43578818 0.4358826  0.44327667 0.43558615 0.44386232\n",
      " 0.4382821  0.438016   0.448808   0.43488884 0.43815452 0.44359338\n",
      " 0.43109965 0.44650266 0.4541081  0.43778586 0.44840127 0.44075355\n",
      " 0.44075355 0.45186314 0.45365322 0.43871182 0.43871182 0.44528246\n",
      " 0.44150326 0.44050342 0.45002085 0.44714496 0.42941043 0.45181873\n",
      " 0.4448702  0.4445626  0.43083185 0.44633433 0.44523638 0.43380016\n",
      " 0.46121377 0.46121377 0.46121377 0.4401234  0.43691576 0.4356834\n",
      " 0.4321594  0.4372783  0.44932973 0.4398591  0.4497339  0.4436418\n",
      " 0.45839506 0.43620804 0.43414107 0.43244228 0.42427045 0.43244228\n",
      " 0.43414107 0.43043858 0.4109632  0.4109632  0.4109632  0.44908443\n",
      " 0.45849264 0.4503124  0.44805244 0.446202   0.4530315  0.4479637\n",
      " 0.44797492 0.4515165  0.44783515 0.43949327 0.44783515 0.4515165\n",
      " 0.42690957 0.4300698  0.41835314 0.4280276  0.43753222 0.43092987\n",
      " 0.42695305 0.43092984 0.4280276  0.43753222 0.42927378 0.4308081\n",
      " 0.43271893 0.4578791  0.43110606 0.448015   0.44568273 0.45467684\n",
      " 0.45384437 0.45767814 0.43461925 0.43237588 0.432499   0.43454745\n",
      " 0.43489563 0.46730226 0.46730226 0.437764   0.43791416 0.43169978\n",
      " 0.43251932 0.42872745 0.43535358 0.43400255 0.43811536 0.4151098\n",
      " 0.4379555  0.42887717 0.43818575 0.4314429  0.43144286 0.43068105\n",
      " 0.4297445  0.42411655 0.4086662  0.42411655 0.40866625 0.43712196\n",
      " 0.4365341  0.42670262 0.43478236 0.4349397  0.44976977 0.4412066\n",
      " 0.43026248 0.43026248 0.43976152 0.4209566  0.42095658 0.4383061\n",
      " 0.4326843  0.43049806 0.43267104 0.43267104 0.4404676  0.44084635\n",
      " 0.43620476 0.41087866 0.41087866 0.41087866 0.41087866 0.41087866\n",
      " 0.41087866 0.43426907 0.43426907 0.45265558 0.4301643  0.45191717\n",
      " 0.42893425 0.42893425 0.4199606  0.44869715 0.42741257 0.42916968\n",
      " 0.4349839  0.43783867 0.43771708 0.43256932 0.42212808 0.4290135\n",
      " 0.43969008 0.4165524  0.43055606 0.4180664  0.41960642 0.4358465\n",
      " 0.42630598 0.41091463 0.4483293  0.45386758 0.44964373 0.45848146\n",
      " 0.45386758 0.4483293  0.4327468  0.4425377  0.43018985 0.42972785\n",
      " 0.4322948  0.43449873 0.43524903 0.42982996 0.43654826 0.4354725\n",
      " 0.45258498 0.4613402  0.44178662 0.44648418 0.45312557 0.44463965\n",
      " 0.45502776 0.44220382 0.45372337 0.4430583  0.4065733  0.44906422\n",
      " 0.42998266 0.42998266 0.4488299  0.4488299  0.46160048 0.46160048\n",
      " 0.43812135 0.44687113 0.4383004  0.4323877  0.42576966 0.43424296\n",
      " 0.435213   0.43150252 0.4238103  0.43544948 0.44987506 0.4430028\n",
      " 0.44764197 0.44118887 0.42778894 0.45300233 0.46088472 0.4684246\n",
      " 0.46806854 0.47239414 0.45416144 0.45205852 0.45205852 0.44388118\n",
      " 0.4310244  0.42616597 0.43693805 0.41864875 0.4306568  0.42820516\n",
      " 0.4171842  0.44686335 0.4379862  0.4316138  0.43369424 0.4466068\n",
      " 0.43267956 0.43255916 0.43278426 0.4580664  0.42716122 0.4247114\n",
      " 0.40861106 0.43738064 0.42339557 0.40920895 0.43589997 0.43878824\n",
      " 0.42989412 0.42309177 0.43278322 0.40920058 0.4172446  0.42777488\n",
      " 0.42684335 0.43353304 0.44828802 0.42727426 0.42693943 0.43054503\n",
      " 0.43125248 0.4286681  0.43013594 0.4199606  0.4286681  0.43125248\n",
      " 0.45356286 0.45546338 0.45167857 0.45212147 0.44842494 0.44146395\n",
      " 0.45546338 0.45356286 0.45118797 0.45059755 0.4408811  0.43588775\n",
      " 0.4240265  0.44150326 0.4387118  0.44077674 0.4379767  0.44077674\n",
      " 0.4387118  0.44922158 0.45074898 0.44506148 0.4589963  0.4542049\n",
      " 0.4370925  0.44973224 0.451632   0.4402588  0.44652396 0.44089273\n",
      " 0.43876156 0.44150326 0.43876156 0.44089273 0.44319245 0.4303679\n",
      " 0.42998108 0.4326878  0.43774492 0.43773556 0.43268767 0.431009\n",
      " 0.43272507 0.43071583 0.44571486 0.44821674 0.45768943 0.4564647\n",
      " 0.45390618 0.46460342 0.46593183 0.47194454 0.4227821  0.42308354\n",
      " 0.42348164 0.42797488 0.41942516 0.42317578 0.42402947 0.42660156\n",
      " 0.42358145 0.43090227 0.41701105 0.42746156 0.43260437 0.43050557\n",
      " 0.43117082 0.4317912  0.43626675 0.4317912  0.43117082 0.4339778\n",
      " 0.44477865 0.42214566 0.4389972  0.42799434 0.42407456 0.4221851\n",
      " 0.42491183 0.42210877 0.42491183 0.42565832 0.43139872 0.42853004\n",
      " 0.43113145 0.42524093 0.42841306 0.42539325 0.43068403 0.4508007\n",
      " 0.46025804 0.468336   0.46805272 0.47239414 0.43429554 0.4432852\n",
      " 0.45924976 0.45579082 0.44484016 0.4565848  0.44066998 0.45565832\n",
      " 0.45565832 0.43183297 0.44983315 0.4406111  0.4382216  0.44904253\n",
      " 0.44459292 0.43702918 0.44461122 0.4383618  0.44906864 0.440552\n",
      " 0.43561465 0.4267305  0.43112382 0.42453688 0.42898518 0.43496096\n",
      " 0.43496096 0.42635724 0.415185   0.434046   0.43828112 0.43828112\n",
      " 0.43496415 0.44133162 0.43964177 0.430021   0.44840622 0.42927453\n",
      " 0.429367   0.42448494 0.42481682 0.4248187  0.43003923 0.42602322\n",
      " 0.4241155  0.4267236  0.42387655 0.42136303 0.43131664 0.43131915\n",
      " 0.42792973 0.43653482 0.43914318 0.4303405  0.426905   0.4251717\n",
      " 0.43405455 0.42625377 0.45201242 0.42200574 0.4540499  0.4175393\n",
      " 0.42575037 0.45350006 0.45350006 0.45129874 0.45129874 0.41658083\n",
      " 0.42575336 0.4178356  0.4284431  0.43393463 0.43055063 0.45135587\n",
      " 0.45069972 0.45674807 0.45674807 0.45992836 0.46026176 0.46099782\n",
      " 0.46099782 0.4655099  0.4352212  0.43537828 0.4640061  0.46873847\n",
      " 0.46073213 0.4681216  0.45541635 0.47239414 0.4578414  0.46035865\n",
      " 0.45157433 0.45439976 0.45105708 0.45533276 0.45439976 0.45134202\n",
      " 0.45157433 0.45434344 0.45134202 0.45134202 0.45134202 0.43185124\n",
      " 0.42528436 0.42397544 0.43003613 0.42978716 0.42942995 0.4167632\n",
      " 0.4238717  0.4264459  0.42305502 0.42954    0.42719802 0.43276152\n",
      " 0.43434864 0.4252577  0.4275162  0.43675426 0.4351838  0.4351838\n",
      " 0.40919894 0.4382335  0.4382335  0.4413446  0.42558372 0.42720222\n",
      " 0.4266386  0.4289296  0.42837787 0.43226084 0.42844772 0.43426096\n",
      " 0.4322407  0.43257028 0.43472835 0.43775457 0.43447745 0.44568056\n",
      " 0.43783498 0.44821674 0.45759737 0.45390618 0.45578593 0.45524865\n",
      " 0.44778046 0.4365523  0.43121406 0.43342072 0.43277428 0.43290424\n",
      " 0.432357   0.4377716  0.43782315 0.44441256 0.46606416 0.4635532\n",
      " 0.46198884 0.42157677 0.4204108  0.4228129  0.4276931  0.42420596\n",
      " 0.42490104 0.42440864 0.42562425 0.43085155 0.42828926 0.4278214\n",
      " 0.42619455 0.42846963 0.42156    0.44819626 0.43095216 0.43369356\n",
      " 0.41601148 0.41601148 0.4555974  0.4314671  0.43366805 0.46188322\n",
      " 0.4446856  0.449703   0.46170375 0.46170375 0.42348018 0.42366567\n",
      " 0.4108435  0.4264562  0.4113756  0.42892197 0.44311395 0.4580358\n",
      " 0.46693364 0.4400885  0.44492474 0.4611406  0.4611406  0.40600914\n",
      " 0.4611406  0.43819496 0.45621997 0.45621997 0.46117115 0.46117115\n",
      " 0.4380594  0.41324952 0.4135529  0.4481176  0.42401052 0.4259229\n",
      " 0.43151572 0.44224307 0.45225725 0.4600812  0.43148515 0.43105072\n",
      " 0.4302356  0.43093935 0.42794815 0.42280743 0.42134145 0.42212105\n",
      " 0.42793533 0.42505854 0.43735445 0.4175696  0.44103563 0.438459\n",
      " 0.45002326 0.43942145 0.43440855 0.42266792 0.44232434 0.4329182\n",
      " 0.40920407 0.42494598 0.43888974 0.43758485 0.43634465 0.4305204\n",
      " 0.42400134 0.43242893 0.44548315 0.4239199  0.43191203 0.43675718\n",
      " 0.43251953 0.43488625 0.44136915 0.4438805  0.42973194 0.42909884\n",
      " 0.43883014 0.42993236 0.42675528 0.42917845 0.42917845 0.43286023\n",
      " 0.4268435  0.42814073 0.43052143 0.43052146 0.43978494 0.42815557\n",
      " 0.42719042 0.4320105  0.42437318 0.4320105  0.4379239  0.44123375\n",
      " 0.42719045 0.43650368 0.4443275  0.42296    0.4443275  0.44005224\n",
      " 0.44405138 0.44326985 0.44237238 0.44530684 0.44404575 0.4334856\n",
      " 0.43511403 0.4274792  0.43573263 0.42625517 0.41719288 0.4295099\n",
      " 0.4400441 ]\n",
      "ACC: 0.902730899048788         Top2: 0.4338235294117647         AUC: 0.6810175485248988        MCC: nan selectivity 1.0 recall 0.0         g_mean 0.0 balanced acc 0.5 f1score 0.0         precision score 0.0 jaccard score 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2616487/721503128.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mcc = up / down\n",
      "/home/jgl/anaconda3/envs/pytorch/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=np.inf)\n",
    "test(tune_model, \"cuda\", tune_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC: 0.902730899048788         Top2: 0.4411764705882353         AUC: 0.6885801628540853  \n",
    "      MCC: nan     selectivity 1.0       recall 0.0         g_mean 0.0     balanced acc 0.5 f1score 0.0  \n",
    "             precision score 0.0     jaccard score 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae2bdcb5ffd42edc58b1d6fb8428ae1d2700e79a4fc0c0139ea5d98047639f54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
